[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m whatever Gotham needs me to be.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"zh","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://szthanatos.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m whatever Gotham needs me to be.","tags":null,"title":"Lex Wayne","type":"authors"},{"authors":["sz"],"categories":null,"content":"施工ing\u0026hellip;\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"zh","lastmod":-62135596800,"objectID":"e82475504794dbc9e1d724238b8546f1","permalink":"https://szthanatos.github.io/authors/sz/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/sz/","section":"authors","summary":"施工ing\u0026hellip;","tags":null,"title":"苏展","type":"authors"},{"authors":null,"categories":null,"content":"关于Kafka，看完你就知道他们都在逼逼什么了。\n","date":1547538052,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1547538052,"objectID":"4b903f59e77b20dc804f8bb6d71441b2","permalink":"https://szthanatos.github.io/topic/kafka/","publishdate":"2019-01-15T15:40:52+08:00","relpermalink":"/topic/kafka/","section":"topic","summary":"关于Kafka，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"关于Docker，看完你就知道他们都在逼逼什么了。\n","date":1544342124,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1536451200,"objectID":"31c005a75ad173ed9241ca0781db762e","permalink":"https://szthanatos.github.io/topic/docker/","publishdate":"2018-12-09T15:55:24+08:00","relpermalink":"/topic/docker/","section":"topic","summary":"关于Docker，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"","date":1526614970,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1560666892,"objectID":"9aac42af5621e08eafcc0c2bfaf288e8","permalink":"https://szthanatos.github.io/topic/redis/","publishdate":"2018-05-18T11:42:50+08:00","relpermalink":"/topic/redis/","section":"topic","summary":"关于Redis，看完你就知道他们都在逼逼什么了。","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":" 环境说明    当前版本 发布日期 下载地址     2.0 2018-07-30 官方2.0.0镜像    安装步骤 注意： 文中以 {} 包裹起来的内容需要自己替换，并非直接使用\n0. 环境准备    基础环境 说明     Java Java版本应该在8(jdk1.8)或以上，以更好的支持G1回收   硬件参数 CPU: 英特尔至强E5-2650 v4 * 2 (共计24核)\nMem: DDR4内存-32GB * 8\nSto: 2000GB * 8 raid 0   文件路径 /home/tools/kafka_2.11-2.0.0/   数据存放位置 /home/sdb/kafka-logs,/home/sdc/kafka-logs,\n/home/sdd/kafka-logs,/home/sde/kafka-logs,\n/home/sdf/kafka-logs,/home/sdg/kafka-logs,\n/home/sdh/kafka-logs,/home/sdi/kafka-logs   zookeeper集群位置 10.10.20.83:2181,10.10.20.84:2181,10.10.20.85:2181    1. 下载安装 下载最新版本Kafka，解压到指定目录，无需其他操作即完成安装。\ntar -xzf kafka_2.11-2.0.0.tgz -C /home/tools cd kafka_2.11-2.0.0  2. 配置集群参数 修改config/server.properties\n基本参数如下：\n# broker唯一id，值为不重复正整数 broker.id={n: int} # 服务监听地址 listeners=PLAINTEXT://{your.host}:9092 # 日志存放位置列表，以逗号隔开 log.dirs={data.storage.list} # zookeeper地址列表，以逗号隔开 zookeeper.connect={zookeeper.server.list}  优化参数配置如下：\n# 消息处理线程数，建议数量为cpu核数加1 num.network.threads=25 # 磁盘IO的线程数,建议为cpu核数2倍，最大不超过3倍 num.io.threads=48 # 拉取线程数，影响follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大 num.replica.fetchers=2 # 分区数量配置，根据业务情况修改 num.partitions=16 # 消息日志备份数，默认是1 default.replication.factor=2 # 刷盘(写入文件到磁盘)间隔消息数，建议设为10000 log.flush.interval.messages=10000 # 刷盘间隔毫秒数，建议1秒(1000) log.flush.interval.ms=1000 # 日志保留小时数 log.retention.hours=48 # 段文件大小，过小会产生很多小文件降低性能，过大会影响快速回收磁盘空间以及Kafka重启后的载入速度 og.segment.bytes=1073741824 # 最大字节数，默认1M，可以调到5M以上 replica.fetch.max.bytes=5242880 # 可接受数据大小，受限于java int类型的取值范围,超出后会报OOM异常 socket.request.max.bytes=2147483600 # 日志传输时候的压缩格式，可选择lz4, snappy, gzip,不压缩。建议打开压缩，可以提高传输性能 compression.type=snappy # 是否允许通过管理工具删除topic，默认是false delete.topic.enable=true # 是否允许程序自动创建Topic auto.create.topics.enable=false  3. 配置日志参数 修改config/log4j.properties的jog4j参数，提高Kafka操作日志（和数据日志区分）的日志级别，以降低日志输出相关资源占用。具体可更改配置如下：\n# Kafka2.0默认只有controller是TRACE级别，可以改为INFO，其他INFO级别可以适当提升为WARN # zookeeper日志级别， log4j.logger.org.I0Itec.zkclient.ZkClient=INFO log4j.logger.org.apache.zookeeper=INFO # 主日志级别 log4j.logger.kafka=INFO log4j.logger.org.apache.kafka=INFO # request日志级别，只有当需要调试时才有必要输出 log4j.logger.kafka.request.logger=WARN, requestAppender log4j.additivity.kafka.request.logger=false # 需要调试时解除以下三行注释，并将RequestChannel$设为TRACE # log4j.logger.kafka.network.Processor=TRACE, requestAppender # log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender # log4j.additivity.kafka.server.KafkaApis=false log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender log4j.additivity.kafka.network.RequestChannel$=false # controller日志级别，默认为TRACE log4j.logger.kafka.controller=INFO, controllerAppender log4j.additivity.kafka.controller=false # 日志清理的日志级别 log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender log4j.additivity.kafka.log.LogCleaner=false log4j.logger.state.change.logger=TRACE, stateChangeAppender log4j.additivity.state.change.logger=false # 登陆认证的日志级别 log4j.logger.kafka.authorizer.logger=INFO, authorizerAppender log4j.additivity.kafka.authorizer.logger=false  4. 配置JVM参数 Warning：谨慎调试\n在bin/kafka-server-start.sh文件中调整参数如下：\n# 在base_dir之后配置参数 base_dir=$(dirname $0) export KAFKA_HEAP_OPTS=\u0026quot;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80\u0026quot;  ps： 虽然看起来很激进，但是以上配置参照的是LinkIn高峰时期最繁忙的集群:\n60 brokers 50k partitions (replication factor 2) 800k messages/sec in 300 MB/sec inbound, 1 GB/sec+ outbound  这个配置的集群实现了90%的GC中断时间不超过21毫秒，每秒钟新生代GC次数不超过一次\nps2： 上述环境的Java版本为JDK 1.8 u5\n5. 配置Linux参数 Warning：谨慎调试\n# 调整系统所有进程一共可以打开的最大文件数： echo 'fs.file-max = 1024000' \u0026gt;\u0026gt; /etc/sysctl.conf  以及/etc/security/limits.conf末尾增加：\n# 设置当前user以及由它启动的进程的资源限制 {user} soft nofile 1024000 {user} hard nofile 1024000  增大socket buffer size，以提高吞吐性能\necho 212992 \u0026gt;\u0026gt; /proc/sys/net/core/wmem_max echo 212992 \u0026gt;\u0026gt; /proc/sys/net/core/rmem_max  Kafka2.0官方安装指南 Quick Start\n","date":1544062186,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544062186,"objectID":"8906f5bc4c52e993b12567b4405f72b6","permalink":"https://szthanatos.github.io/topic/kafka/install/","publishdate":"2018-12-06T10:09:46+08:00","relpermalink":"/topic/kafka/install/","section":"topic","summary":"环境说明 当前版本 发布日期 下载地址 2.0 2018-07-30 官方2.0.0镜像 安装步骤 注意： 文中以 {} 包裹起来的内容需要自己替换，并非直接使用 0. 环境准备 基础环境 说明 Java","tags":null,"title":"Kafka -01- 安装配置","type":"docs"},{"authors":null,"categories":null,"content":" Docker简介 什么是Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，并于2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护，后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。\nDocker 最初是在 Ubuntu 12.04 上以Go 语言 进行开发实现的, Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持(换句话说不支持CentOS6.5以下)。\nDocker 是一种 容器化技术 ，类似虚拟机的概念，但不同的是传统虚拟机是在虚拟硬件的基础上，完整模拟一整个操作系统，而Docker是以单个应用（容器）为单位进行虚拟。\nDocker特点 Docker具有以下特点：\n 文件系统隔离 ：每个进程容器运行在完全独立的根文件系统里。 资源隔离 ：可以使用cgroup为每个进程容器分配不同的系统资源，例如CPU和内存。 网络隔离 ：每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和IP地址。 写时复制 ：采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。 日志记录 ：Docker将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。 变更管理 ：容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。 交互式Shell ：Docker可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互shell。  为什么要使用Docker    特性 容器 虚拟机     启动 秒级 分钟级   硬盘使用 一般为 MB 一般为 GB   性能 接近原生 弱于原生   系统支持量 单机支持上千个容器 一般几十个     更高效的利用系统资源 ：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 ：Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。 一致的运行环境 ： Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 ：对DevOps人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment)系统进行自动部署。 更轻松的迁移 ：由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。  基本概念 Docker 包括三个基本概念\n 镜像（Image） 容器（Container） 仓库（Repository）  理解了这三个概念，就理解了 Docker 的整个生命周期。\n镜像 操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu 16.04 最小系统的 root 文件系统。\nDocker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。\n分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\n容器的实质是进程 ，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。\n前面讲过镜像使用的是分层存储，容器也是如此。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层， 我们可以称这个为容器运行时读写而准备的存储层为 容器存储层 。\n容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此， 任何保存于容器存储层的信息都会随容器删除而丢失 。\n按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。 所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录 ，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n仓库 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker提供注册服务器(Docker Registry)来实现这样的服务。\n一个Docker Registry中可以包含多个 仓库 （Repository）；每个仓库可以包含多个 标签 （Tag）；每个标签对应一个镜像。\n通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 \u0026lt;仓库名\u0026gt;:\u0026lt;标签\u0026gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。\n以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。\n仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。\n类似git 和GitHub，官方提供Docker Hub，作为默认的 Registry。用户也可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。\n生命周期 结合上面的概念，这里有一张图比较好的概括了整个Docker工作的生命周期（以及主要命令）。 安装配置 这里仅以CentOS 安装 Docker CE 举例说明。详见Docker 官方 CentOS 安装文档\n准备工作 系统要求 Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。\n 警告：切勿在没有配置 Docker YUM 源的情况下直接使用 yum 命令安装 Docker.\n 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本：\nsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine  使用脚本安装（非生产环境） 对于个人测试，可以使用这个脚本自动化安装Docker：\ncurl -fsSL get.docker.com -o get-docker.sh sh get-docker.sh  但是，需要注意， 这个脚本可能扰乱你的系统配置、安装及大量的（你可能用不到的）依赖，并且只能安装最新（可能未经充分测试的）版本的Docker ， 所以不推荐在生产环境中使用。\n使用 yum 安装 安装依赖包：\nsudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2  添加 yum 软件源：\n# 中国科学技术大学开源软件镜像源 sudo yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo # 官方源 # sudo yum-config-manager \\ # --add-repo \\ # https://download.docker.com/linux/centos/docker-ce.repo  更新 yum 软件源缓存，并安装 docker-ce。\nsudo yum makecache fast sudo yum install docker-ce  离线安装 以docker-ce-18.03.1为例：\n 在https://download.docker.com/linux/centos/7/x86_64/stable/Packages/这里找到对应rpm包 执行安装命令：rpm -ivh docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm 由于安装环境不同，可能会发现缺少一些相关依赖包（eg: libcgroup、libtool-ltdl、container-selinux）前往https://pkgs.org/或https://buildlogs.centos.org/下载对应依赖包，依次安装即可  启动 Docker CE sudo systemctl enable docker sudo systemctl start docker  建立 Docker 用户组 默认情况下，docker命令需要root权限，为了避免每次输入命令都要加sudo，可以将用户加入 docker 用户组：\nsudo groupadd docker sudo usermod -aG docker $USER  退出当前终端并重新登录，进行如下测试。\n测试 Docker 是否安装正确 执行\ndocker run hello-world  Docker会从官方仓库下载hello-world镜像并启动，如果一切正常的话会看到类似如下提示：\nUnable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world ca4f61b1923c: Pull complete Digest: sha256:be0cd392e45be79ffeffa6b05338b98ebb16c87b255f48e297ec7f98e123905c Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/  镜像加速 鉴于国内网络问题，建议使用Docker中国或者其他国内镜像源。\n修改（或新增）/etc/docker/daemon.json文件，添加:\n{ \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://registry.docker-cn.com\u0026quot;] }  之后重启Docker使配置生效。\n常用Docker操作 # 查看docker版本 docker version # 显示docker系统的信息 docker info # 日志信息 docker logs # 故障检查 service docker status # 启动关闭docker sudo service docker start|stop  使用镜像 基本操作 以redis为例，我们从Docker Hub上获取官方镜像到本地：\ndocker pull redis  ps1： 由于redis是官方源（Official），否则应该写完整的两段式仓库名 \u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;，例如bitnami/redis。\nps2： 此处没有指定镜像版本，默认会拉取redis:lastest镜像，指定版本应该写成例如：redis:5.0-rc5\n查看已经下载的镜像：\ndocker image ls # 会有类似如下显示 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB ......  更细节的显示可以使用docker image ls --format \u0026quot;{{.ID}}: {{.Repository}}\u0026quot;直接列出镜像ID和仓库名,\n或者使用docker image ls --format \u0026quot;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\u0026quot; 以表格等距显示.\n如果要删除某个镜像的话，可以使用docker image rm {IMAGE ID}|{REPOSITORY}命令，不要过先确保没有容器在使用这个镜像。\nDockerfile 除了引用制作好的镜像，我们也可以基于现有镜像定制新的镜像。定制所用的脚本文件就是 Dockerfile。\nDockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction) ，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n我们新建一个空白文件，命名为 dockerfile，再文件中写入如下内容：\nFROM redis RUN mkdir redis WORKDIR redis COPY ./redis.conf /etc/ CMD [\u0026quot;redis-server\u0026quot;, \u0026quot;/etc/redis.conf\u0026quot;]  我们依次解释上面每一行：\n FROM 就是指定 基础镜像 ,一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。如果不以任何镜像为基础，那应该用FROM scratch作为起始指令。 RUN 是Dockerfile的核心指令，用于执行一条命令，由于Dockerfile 每一条指令都会新建一层，所以应该尽量将执行的内容写在一行（多行内容可以通过在末尾加\\以表示未结束），它有两种写法：  shell 格式：RUN \u0026lt;命令\u0026gt;，就像直接在命令行中输入的命令一样。 exec 格式：RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]，这更像是函数调用中的格式。  WORKDIR 表示指定当前工作目录，相当于cd命令。 COPY 即复制文件到容器中，在这里是把redis.conf文件复制到容器的/etc目录下。 CMD 是启动程序的命令，写法和RUN相同，一般推荐使用exec格式。  常用Docker指令列表如下：\n   指令 含义 用法     FROM 指定基础镜像 FROM \u0026lt;基础镜像\u0026gt;   RUN 执行指令 RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]   COPY 复制文件 COPY [\u0026quot;\u0026lt;源路径1\u0026gt;\u0026quot;,... \u0026quot;\u0026lt;目标路径\u0026gt;\u0026quot;]   ADD 更高级的复制文件 ADD \u0026quot;\u0026lt;压缩文件\u0026gt;\u0026quot;   CMD 容器启动命令 CMD [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;...]   ENTRYPOINT 入口点 ENTRYPOINT [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]   ENV 设置环境变量 ENV \u0026lt;key1\u0026gt;=\u0026lt;value1\u0026gt; \u0026lt;key2\u0026gt;=\u0026lt;value2\u0026gt;...   ARG 构建参数 ARG \u0026lt;参数名\u0026gt;[=\u0026lt;默认值\u0026gt;]   VOLUME 定义匿名卷 VOLUME [\u0026quot;\u0026lt;路径1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;路径2\u0026gt;\u0026quot;...]   EXPOSE 暴露端口 EXPOSE \u0026lt;端口1\u0026gt; [\u0026lt;端口2\u0026gt;...]   WORKDIR 指定工作目录 WORKDIR \u0026lt;工作目录路径\u0026gt;   USER 指定当前用户 USER \u0026lt;用户名\u0026gt;   HEALTHCHECK 健康检查 `HEALTHCHECK NONE   ONBUILD 构建下级镜像 ONBUILD \u0026lt;其它指令\u0026gt;   MAINTAINER 指定作者 ONBUILD \u0026lt;作者\u0026gt;    更多指令及用法请参照官方文档\n如上，我们完成了一个使用自己配置文件的redis镜像的准备工作，之后依据这个Dockerfile进行构建：\ndocker build -t redis_test:v0.1 . # 会有类似如下输出： Sending build context to Docker daemon 2.048 kB Step 1 : FROM redis ... ... Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c  docker build的用法为：\ndocker build [选项] \u0026lt;上下文路径/URL/-\u0026gt;  最后，可以使用docker push将你自己构建的镜像上传到仓库中，详细用法见官方文档 push\n容器操作 容器启停 我们可以用这样的方式从之前的镜像启动一个容器：\ndocker run -d --name some-redis redis  docker run的用法为docker run [选项] 镜像 [命令] [参数...]，其中：\n--name 指定容器的名称， -d 指定后台运行，其他常用参数包括-i 交互式操作，-t 使用终端（it一般同时使用），--rm 容器退出后随之将其删除，完整参数列表可以通过--help或者在线文档 docker run查看\n由于我们是在后台运行，使用docker container ls来查看容器相关情况，如果要查看停止的进程，后面需要增加参数-a：\ndocker container ls # 会看到类似如下内容 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77b2dc01fe0f redis:v2 redis-server redis.conf 'while tr 2 minutes ago Up 1 minute agitated_wright  使用docker container stop来结束容器的运行：\ndocker container stop 77b2dc01fe0f  类似的，使用docker container start | restart | stop可以控制容器的启停， 使用docker container rm 来删除指定容器。\n数据管理 之前提到过，随着容器的销毁，容器内的数据也会一同丢失。为了保存数据，Docker提供了两种方式（还有一种tmpfs mountsb不常用到）：\n方式1：数据卷（推荐） 数据卷 volume 是一个可供一个或多个容器使用的特殊目录，它不依赖于Unix文件系统，也拥有独立于容器的生命周期。\n创建一个数据卷:\ndocker volume create my-vol  查看数据卷及具体信息：\n# 查看所有的数据卷 docker volume ls # 会看到类似如下内容 local my-vol # ----------------------------------- # 查看具体卷的信息 docker volume inspect my-vol # 会看到类似如下内容 [ { \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Labels\u0026quot;: {}, \u0026quot;Mountpoint\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Options\u0026quot;: {}, \u0026quot;Scope\u0026quot;: \u0026quot;local\u0026quot; } ]  在用 docker run 的时候，增加 --mount 参数来使用数据卷,还是以启动redis为例，这里我们启动redis并且开启aof持久化：\ndocker run -d \\ --name redis \\ --mount source=my-vol,target=/data \\ # -v my-vol:/data \\ redis \\ redis-server --appendonly yes  在这里redis产生的数据（/data目录下）被挂载到数据卷my-vol中。\n我们也可以使用-v或者--volume语法，但是官方建议尽量使用--mount。\n同样使用inspect语法，我们可以查看redis容器的信息：\ndocker inspect redis # 会看到类似如下内容 \u0026quot;Mounts\u0026quot;: [ { \u0026quot;Type\u0026quot;: \u0026quot;volume\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Source\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Destination\u0026quot;: \u0026quot;/data\u0026quot;, \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Mode\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;RW\u0026quot;: true, \u0026quot;Propagation\u0026quot;: \u0026quot;\u0026quot; } ],  方式2：绑定主机目录 我们也可以直接将容器的数据挂载 bind mount到宿主机的目录或文件 （而非由Docker创建的数据卷）,以当前目录$(pwd)为例：\ndocker run -d \\ --name redis \\ --mount type=bind,source=\u0026quot;$(pwd)\u0026quot;/target,target=/data \\ redis \\ redis-server --appendonly yes  挂载单独文件的方法类似。\n需要注意，本地目录必须存在，否则会报错。\n区别 Volumes是由Docker创建和管理，存储在宿主机固定位置（在linux上是/var/lib/docker/volumes/）。 非Docker应用程序不能改动这一位置的数据。 一个数据卷可以同时被挂载到几个容器中。即使没有正在运行的容器使用这个数据卷，它依然不会清除。可以通过docker volume prune清除不再使用的数据卷。\nBind mounts的数据可以存放在宿主机的任何地方。 非Docker应用程序可以改变这些数据。\n使用网络 端口映射 docker run的时候使用-P(\u0026ndash;publish-all)参数，随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n或者使用-p ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort(\u0026ndash;publish)来指定具体端口映射：\ndocker run -d \\ --name some-redis \\ -p 6379:6379 \\ -p 127.0.0.1::16379/udp -p 127.0.0.1:80:80 redis  这里我们分别将容器的6379端口映射到宿主机 任意ip的6379端口 ，容器的16379 udp端口映射到宿主机的 任意端口 ，容器的80端口映射到宿主机 对应的80端口 。\n使用docker port 可以查看对应容器的全部端口映射。\n容器互联 简单的容器互联可以通过--link 实现，但是 官方未来可能会删除这个参数 ，所以不展开。\n最新的方式是搭建docker网络实现容器互联，先创建一个新的 Docker 网络：\ndocker network create -d bridge my-net  这里的-d 参数指定网络类型，常用的只有bridge，其他的可能会在Swarm用到,如果不知道Swarm是什么就不用在意。\n以redis客户端/服务端为例，分别在启动的时候将之加入my-net网络：\ndocker run -d \\ --name redis-server \\ --network my-net \\ redis docker run -it \\ --rm \\ --name redis-client \\ --network my-net \\ redis redis-cli -h redis-server  可以看到成功进入redis-cli客户端，我们可以尝试info/keys *或者其他命令查看redis服务端运行情况。\n延申 容器编排 面临一组容器配合使用的情况，例如一个包括负载均衡——网站后台——数据库的Web系统，我们可以使用Docker提供的Compose完成统一配置管理。它将提供相同功能的容器定义为服务service——以方便复用；将完整的容器组合组成项目project以方便统一管理。所有的配置通过一个yml文件即可实现。\nNvidia Docker 对使用GPU的容器，Docker提供Nvidia Docker以发挥GPU的运算性能。\n基本要求如下：\n GNU/Linux x86_64 with kernel version \u0026gt; 3.10 Docker \u0026gt;= 1.12 NVIDIA GPU with Architecture \u0026gt; Fermi (2.1) NVIDIA drivers ~= 361.93 (untested on older versions)  详细安装使用见官方项目Wiki\n","date":1544019442,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544019442,"objectID":"2a21c6713191c46e684013e469dfa8c0","permalink":"https://szthanatos.github.io/topic/docker/basis/","publishdate":"2018-12-05T22:17:22+08:00","relpermalink":"/topic/docker/basis/","section":"topic","summary":"Docker简介 什么是Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，并于2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代","tags":null,"title":"Docker -01- 基本概念","type":"docs"},{"authors":null,"categories":null,"content":" 简介  Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。\n —— Redis官方介绍\n版本    软件 版本 更新日期 备注     Redis 4.0.11 2018-08-03 必装   Ruby 2.5.1 2018-03-28 可选,集群执行rb脚本的节点安装即可   rubygem 2.7.7 2018-05-18 同上   gem-redis 4.0.2 2018-08-13 同上    安装  以CentOS 7为例 从上述链接下载redis文件 安装环境依赖yum install -y gcc gcc-c++ tcl tar -xvzf {redis.tar.gz}解压 进入redis目录，执行make \u0026amp;\u0026amp; make install进行安装\n如果make出错，通过make test检查：\n 尝试只用单核运行：taskset -c 1 sudo make test 更改tests/integration/replication-psync.tcl文件,把对应报错的那段代码中的 after 100改成after 500  完成单节点安装\n  配置 默认配置文件为位于redis目录下的redis.conf\n最小配置 一个最小的redis.conf配置如下：\n# 节点监听的端口号 port {your_port} # 是否以进程守护方式(后台)运行 daemonize yes # 允许访问的IP地址，设置为0.0.0.0的时候可以从任意IP访问redis，多个ip用逗号隔开 bind {your_ip} # 工作目录，数据存放位置 dir {your_dir} # 进程文件名称，固定为redis_监听的端口号.pid pidfile /var/run/redis_{your_port}.pid  完成以上配置即可启动单节点redis。\n集群配置 集群需要在redis.conf中配置以下部分：\n# 以集群模式启动 cluster-enabled yes # 集群配置存放的文件名，一般为node-端口号.conf cluster-config-file nodes-{port}.conf # 集群超时 cluster-node-timeout 15000 # 是否启用aof方式持久化，建议开启 appendonly yes  启动 防火墙 redis需要使用指定端口号以及指定端口号+10000进行通讯，以6379端口为例，如果开启了防火墙，需要执行：\nfirewall-cmd --zone=public --add-port=6379/tcp --permanent firewall-cmd --zone=public --add-port=16379/tcp --permanent firewall-cmd --reload  单结点启动 执行\nredis-server {dir}/redis.conf  启动redis\n集群启动 ruby环境 redis集群是通过Ruby编写的脚本进行联通的（但不需要在每隔节点都执行），所以集群中起码一个节点，应该具备ruby环境、rubygem包管理软件、rubygem中的redis包。\nruby环境搭建过程如下：\n yum安装ruby环境及包\nyum -y install ruby ruby-devel rubygems  修改ruby源，使用国内镜像\ngem sources --add https://gems.ruby-china.org/ --remove https://rubygems.org/ # 如果修改失败将https换为http重试 gem sources --add http://gems.ruby-china.org/ --remove http://rubygems.org/  检查源列表，确保只有gems.ruby-china.org\ngem sources -l  安装ruby的redis包：\ngem install redis   联通集群  启动所有节点上的redis服务 进入redis安装路径下src文件夹，执行集群命令：\n# --replicas 1 表示主从复制比例为 1:1，即一个主节点对应一个从节点 ./redis-trib.rb create --replicas 1 {node1_ip:port} {node2_ip:port} ...  默认会自动分配主从节点，确认的话输入yes完成集群的创建\n  检查集群状态 # -c 表示连接的是集群 redis-cli -c -h {ip} -p {port} # 查看集群节点 \u0026gt; cluster nodes # 查看集群信息 \u0026gt; cluster info  相关命令 除了使用rb脚本，其实可以直接在redis节点上通过命令操作集群，个人更推荐这个做法。\n主要用到的是\n 谨慎使用rb脚本对redis进行修复，从来没修复成功过\u0026hellip;\n它还会把你的哈希槽按顺序平均分配到所有节点上，本来可能是A节点管理0-6000，B节点6001-12000\u0026hellip;fix完了之后就成了A节点：1，3，5，7\u0026hellip;终端都被坑到无法阅读了。\n  附注 离线安装redis环境 离线情况需要本地下载如下rpm包(版本号以最新为准):\ncpp-4.8.5-16.el7.x86_64.rpm gcc-4.8.5-16.el7.x86_64.rpm gcc-c++-4.8.5-16.el7.x86_64.rpm glibc-2.17-196.el7.i686.rpm glibc-2.17-196.el7.x86_64.rpm glibc-common-2.17-196.el7.x86_64.rpm glibc-devel-2.17-196.el7.x86_64.rpm glibc-headers-2.17-196.el7.x86_64.rpm libgcc-4.8.5-16.el7.i686.rpm libgcc-4.8.5-16.el7.x86_64.rpm libgomp-4.8.5-16.el7.i686.rpm libgomp-4.8.5-16.el7.x86_64.rpm libstdc++-4.8.5-16.el7.i686.rpm libstdc++-4.8.5-16.el7.x86_64.rpm libstdc++-devel-4.8.5-16.el7.i686.rpm libstdc++-devel-4.8.5-16.el7.x86_64.rpm nspr-4.13.1-1.0.el7_3.x86_64.rpm nss-softokn-freebl-3.28.3-8.el7_4.i686.rpm nss-softokn-freebl-3.28.3-8.el7_4.x86_64.rpm tcl-8.5.13-8.el7.i686.rpm tcl-8.5.13-8.el7.x86_64.rpm  如果gem安装redis包时，提示ruby版本太低  卸载yum过时的ruby环境\nyum remove ruby ruby-devel rubygems  下载ruby源码\n 解压，编译安装:\ntar -zxvf {latest_ruby.tar.gz} cd {latest_ruby} ./configure make make install  下载gem源码\n 解压，安装：\ntar -zxvf {latest_rubygem.tgz} cd {latest_rubygem} ruby setup.rb  重新gem install redis或者离线下载gem-redis的包，本地安装\n  ","date":1535618448,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1535618448,"objectID":"43096142d61e488e10e428722849ddff","permalink":"https://szthanatos.github.io/topic/redis/install/","publishdate":"2018-08-30T16:40:48+08:00","relpermalink":"/topic/redis/install/","section":"topic","summary":"简介 Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（stri","tags":null,"title":"Redis单机\u0026集群安装","type":"docs"},{"authors":null,"categories":null,"content":" 环境说明     版本号 发布日期     当前版本 0.11.0.1 2017-09-14   最新版本 2.0 2018-07-30    配置文件路径： \u0026gt; /home/tools/kafka_2.12-0.11.0.1/config/\n目标需求： 在Kafka集群不停机不停止服务的情况下进行升级改造。\n可能存在的风险 轻微警报  consumer可能出现偏移量提交失败而造成重复消费 broker提示\u0026rsquo;NotLeaderForPartitionException\u0026rsquo;异常 由于节点下线，可能造成临时性能问题   严重警报 严格按照步骤升级，暂未捕捉到严重问题相关信息\n升级步骤（滚动升级）  限定通讯协议版本：\n配置broker上的server.properties文件：\ninter.broker.protocol.version = 0.11.0  依次更新代码并重启borker：\n一次关闭一个broker，更新源码，重启\n 更新通讯协议版本：\n完成所有broker节点的源码更新后,升级协议（方法同上）：\ninter.broker.protocol.version = 2.0  再次依次重启broker：\n同上，一次重启一个\n  ps： 如果修改过消息格式版本(log.message.format.version)，则需要在上面步骤中，同步配置：\nlog.message.format.version=当前版本/要升级的版本  替代方案（离线升级） 关闭所有broker，更新代码并重新启动。默认情况下，自动以新协议开始。\nKafka2.0官方升级指南 upgrade\n","date":1544339992,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544339992,"objectID":"526c33a705e30098d5aac5e54a4db62c","permalink":"https://szthanatos.github.io/topic/kafka/update/","publishdate":"2018-12-09T15:19:52+08:00","relpermalink":"/topic/kafka/update/","section":"topic","summary":"环境说明 版本号 发布日期 当前版本 0.11.0.1 2017-09-14 最新版本 2.0 2018-07-30 配置文件路径： \u0026gt; /home/tools/kafka_2.12-0.11.0.1/config/ 目标需求： 在Kafka集群不停机不停止服务的情况下进行升级改造。 可能存在的风","tags":null,"title":"Kafka -02- 滚动升级","type":"docs"},{"authors":null,"categories":null,"content":"","date":1544061966,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544061966,"objectID":"1f86e46c235768ad9250f893cd0dedeb","permalink":"https://szthanatos.github.io/topic/docker/ecology/","publishdate":"2018-12-06T10:06:06+08:00","relpermalink":"/topic/docker/ecology/","section":"topic","summary":"","tags":null,"title":"Docker -02- 进阶生态","type":"docs"},{"authors":null,"categories":null,"content":" 集群信息 节点信息 集群节点相关信息可以通过cluster nodes命令获取：\n127.0.0.1:6379\u0026gt; cluster nodes 5022fa41642195d74200fd512c08653dc12609e7 172.17.0.2:6380@16380 master - 0 1552814467000 2 connected 5461-10922 730d05ee4da3147d0885c6d47437465c94409f74 172.17.0.2:6383@16383 slave 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 0 1552814468555 5 connected 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 172.17.0.2:6379@16379 myself,master - 0 1552814468000 1 connected 0-5460 cf0be45c6a05c0d332b7356a7f57de95b32c3a71 172.17.0.2:6384@16384 slave 5022fa41642195d74200fd512c08653dc12609e7 0 1552814468654 6 connected 55d264b148ce35903928964ac017d682fc803eab 172.17.0.2:6381@16381 master - 0 1552814468000 3 connected 10923-16383 1a60baf4c2254b2e3a37cf6215d42b316ffdccc7 172.17.0.2:6382@16382 slave 55d264b148ce35903928964ac017d682fc803eab 0 1552814468000 4 connected 127.0.0.1:6379\u0026gt;  可以看到，每一行即是一个节点的信息，以第一行为例，每个字段的含义分别是：\n   字段 含义     502\u0026hellip;\u0026hellip;9e7 node_id，节点标识   172.17.0.2:6380@16380 IP端口   master 身份，一般就是myself/master/slave，其他fail?/handshake/noaddr/noflags   - 对应主节点的node_id(如果你是从节点的话，否则就是-)   0 0表示没有待发送的ping，否则是要发送ping的时间戳   1552814467000 收到上一个pong命令的时间戳   2 权重   connected 状态，connectedordisconnected   5461-10922 哈希槽，连续的哈希槽用-连接，离散的用,隔开    状态信息 集群信息通过cluster info获取：\n127.0.0.1:6379\u0026gt; cluster info # 集群状态 cluster_state:ok # 已分配的哈希槽数量，不是16384就有问题了 cluster_slots_assigned:16384 # 正确的哈希槽数量，如果有哈希槽分配到了离线的节点上就不是这个数字了 cluster_slots_ok:16384 # 临时错误哈希槽数，比如网络波动但节点还是正常的，那就是pfail，节点确认离线了就是fail cluster_slots_pfail:0 cluster_slots_fail:0 # 集群节点数 cluster_known_nodes:6 # 集群规模 cluster_size:3 # 当前最大权重 cluster_current_epoch:6 # 本节点的权重 cluster_my_epoch:1 # 集群建立至今发送/接受的ping/pong/meet消息数 cluster_stats_messages_ping_sent:1554 cluster_stats_messages_pong_sent:1558 cluster_stats_messages_sent:3112 cluster_stats_messages_ping_received:1553 cluster_stats_messages_pong_received:1554 cluster_stats_messages_meet_received:5 cluster_stats_messages_received:3112 127.0.0.1:6379\u0026gt;  集群操作 就不挨个详述了，写了个速查表如下，全部命令详见redis官方文档。\n   命令 含义     信息    cluster info 返回集群基本信息   cluster nodes 返回全部节点   控制    cluster count-failure-reports \u0026lt;node_id\u0026gt; 返回节点的错误报告数   cluster failover [FORCE/TAKEOVER] 在从节点上执行，测试故障转移   cluster set-config-epoch \u0026lt;config-epoch\u0026gt; 为新节点设置权重   cluster saveconfig 将节点的配置文件保存到硬盘里面   cluster reset [HARD/SOFT] 重置没有key的当前节点(所以应该先flushall)   cluster readonly 将从节点置为可读(默认情况下，指向从节点的连接会被转向主节点)   cluster readwrite 将从节点置为读写(相当于还原为readonly之前的状态)   节点    cluster meet \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; 将节点加入集群作为主节点   cluster replicate \u0026lt;node_id\u0026gt; 将当前节点作为的从节点加入集群   cluster replicas \u0026lt;node_id\u0026gt; redis5.0开始支持，列出指定主节点的从节点   cluster slaves \u0026lt;node_id\u0026gt; 不再建议被使用，基本同replicas   cluster replicaof \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; redis5.0开始支持，将当前节点置为指定节点的从节点   cluster slaveof \u0026lt;ip\u0026gt; \u0026lt;port\u0026gt; 不再建议被使用，基本同replicaof   cluster forget \u0026lt;node_id\u0026gt; 从集群中移除节点（前提是没给他分配哈希槽/内容）   哈希槽    cluster addslots \u0026lt;slot\u0026gt;,... 将一个或多个哈希槽添加到当前节点   cluster delslots \u0026lt;slot\u0026gt;,... 从当前节点移除哈希槽   cluster flushslots 清空当前节点的哈希槽   cluster setslot \u0026lt;slot\u0026gt; node \u0026lt;node_id\u0026gt; 将未分配的哈希槽分配给指定节点   cluster setslot \u0026lt;slot\u0026gt; migrating \u0026lt;node_id\u0026gt; 将本节点的哈希槽合并到指定节点   cluster setslot \u0026lt;slot\u0026gt; importing \u0026lt;node_id\u0026gt; 从指定节点引入哈希槽到本节点   cluster setslot \u0026lt;slot\u0026gt; stable 取消哈希槽的移动，_主要是修复redis-trib fix引发的问题←←   cluster flushslots 清空当前节点的哈希槽   cluster flushslots 清空当前节点的哈希槽   键    cluster keyslot \u0026lt;key\u0026gt; 计算key应该被放在哪个槽   cluster countkeysinslot \u0026lt;slot\u0026gt; 返回哈希槽中key的数量   cluster getkeysinslot \u0026lt;slot\u0026gt; \u0026lt;count\u0026gt; 从哈希槽中返回指定数量个key     ps1：从redis5.0起，slave关键字将被replicate取代，相关命令也会逐步被替代    ps2：readonly这个额外说一下，默认情况下，redis的从节点不处理客户端请求，只负责同步主节点的数据，设置readonly之后，指向从节点的读请求会被执行，这样相当于为主节点分担了读的压力(也算是scale了)，但是还是存在两个限制：\n 写请求还是会转移给主节点； 要读的key的哈希槽不属于这个节点，请求一样会被转移；    ","date":1535635578,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1535635578,"objectID":"e2b50f07969cdb2f2779862a6a6cd456","permalink":"https://szthanatos.github.io/topic/redis/cluster_command/","publishdate":"2018-08-30T21:26:18+08:00","relpermalink":"/topic/redis/cluster_command/","section":"topic","summary":"集群信息 节点信息 集群节点相关信息可以通过cluster nodes命令获取： 127.0.0.1:6379\u0026gt; cluster nodes 5022fa41642195d74200fd512c08653dc12609e7 172.17.0.2:6380@16380 master - 0 1552814467000 2 connected 5461-10922 730d05ee4da3147d0885c6d47437465c94409f74 172.17.0.2:6383@16383 slave 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 0 1552814468555 5 connected 25a2a1d8c96e9473d4cb3c8b0077d3b7b07dd5c0 172.17.0.2:6379@16379 myself,master - 0 1552814468000 1 connected 0-5460 cf0be45c6a05c0d332b7356a7f57de95b32c3a71 172.17.0.2:6384@16384 slave 5022fa41642195d74200fd512c08653dc12609e7","tags":null,"title":"Redis集群相关命令","type":"docs"},{"authors":null,"categories":null,"content":"redis性能优化可以从设计，使用，运维三个层面上着手：\n 设计  结构：合理选择数据类型 负载：保证数据在空间上均匀分布  使用，  操作：保证操作在时间上均匀分布 策略：优化资源利用  运维  监控：持续关注执行效率和性能指标 部署：物理层面的调优   下面具体的谈一下几个tips。\n","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"36e1c917a5262404bb6edc1074a4fda8","permalink":"https://szthanatos.github.io/topic/redis/improve-00/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/improve-00/","section":"topic","summary":"redis性能优化可以从设计，使用，运维三个层面上着手： 设计 结构：合理选择数据类型 负载：保证数据在空间上均匀分布 使用， 操作：保证操作在时间上","tags":null,"title":"优化指南","type":"docs"},{"authors":null,"categories":null,"content":"各种情况下的解决办法。\n","date":1535618448,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1535618448,"objectID":"69487901e59753a5dd235fedcddc1ae3","permalink":"https://szthanatos.github.io/topic/redis/error/","publishdate":"2018-08-30T16:40:48+08:00","relpermalink":"/topic/redis/error/","section":"topic","summary":"各种情况下的解决办法。","tags":null,"title":"问题处理","type":"docs"},{"authors":[],"categories":[],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n介绍 RancherOS是Rancher推出的一个轻量级的Linux内核操作系统，专为容器环境而设计。\n按官网的说法，它具有如下特性：\n   官方说法 瞎翻译     Minimalist OS 极简系统 ——当前版本(v1.5.4)镜像也只有146M，还内置了各类虚拟机工具和N个版本的Docker环境   Comprehensive System Services 综合系统服务——所有的系统服务都可以通过Compose文件声明和启动   Improved Security 更安全——没有额外的工具/代码，所有应用都跑在容器里，当然更安全   Up-to-Date Version of Docker \u0026amp; Linux 集成最新的Docker\u0026amp;Linux发行版——装完系统直接就有Docker用，还是最新的，美滋滋   Automated OS Configuration 自动化系统配置——使用cloud-init工具解析cloud-config文件，统一管理系统级的所有配置，比如网络，docker源\u0026hellip;   24x7 Enterprise-level Support 不解释\u0026hellip;    简单的来说，当我们开始使用容器化的方式来管理应用和服务的时候，我们自然而然的会发现，我们对操作系统其实没什么需求了 ——环境依赖和工具链由镜像提供，GUI界面或者浏览器毫无作用，系统内置的各种工具也就是启动一个容器的事\u0026hellip;\n把这些七七八八的都去掉，最后剩下：一个Linux内核 + Docker环境 + 精简但是统一的配置管理 = RancherOS\nRancherOS的架构也非常简单，除了内核，就是两个Docker。\n一个系统级的Docker(system-docker)接管了系统的绝大部分功能，比如在一般Linux上你会用systemctl restart重启服务，在这里就是用system-docker restart重启一个容器了。\n用户级别的Docker也作为一个服务运行在system-docker之上，也就是我们一般意义上跑应用的docker，正常使用。\n安装  在RancherOS Gitlab页面下载对应版本镜像。 新建虚拟机，加载ISO镜像，默认会以rancher用户身份进入一个运行在内存之上的临时RancherOS，所以建虚拟机的时候内存可以适当大一点，比如2G 新建/上传一个cloud-config.yml文件，主要内容就是写入你的ssh公钥，因为RancherOS安装之后就只能通过ssh+公钥的方式登陆(是的，你在虚拟机控制台都进不去)，一个最简单的示例如下：\n# cloud-config ssh_authorized_keys: - ssh-rsa AAA...  没有其他配置了的话，\nsudo ros config valicate -i cloud-config.yml校验没有格式错误，\nsudo ros install -c cloud-config.yml -d /dev/sda将RancherOS安装到硬盘。\n一路只有2个选项，是否要安装？Y，是否要重启？N，因为重启比你卸载光驱还快\u0026hellip;直接就又进入一个新的临时RancherOS了\u0026hellip;\n 手动sudo poweroff，卸载光驱，重启，看到熟悉的牛头LOGO，恭喜完成~\n   如果一定要为rancher设置一个密码的话，将安装命令替换为：\nsudo ros install -c cloud-config.yml -d /dev/sda --append=rancher.password=密码\n   我遇到的一个情况，在Vmware上安装时，临时RancherOS默认没有网， 需要手动配置网卡：\n修改/etc/network/interfaces文件，在末尾添加：\nauto eth0 iface eth0 inet static # IP address xxx.xxx.xxx.xxx # 子网掩码 netmask xxx.xxx.xxx.xxx # 广播地址(可选) broadcast xxx.xxx.xxx.xxx # 所在网段(可选) network xxx.xxx.xxx.xxx # 网关 gateway xxx.xxx.xxx.xxx # dns服务器 dns-nameservers xxx.xxx.xxx.xxx  配置好执行sudo ifup eth0即可连上网络。\n  使用 整个RancherOS自底向上分三个层面进行管理\n   层面 工具 管理     系统管理 ros cloud-config.yml   服务管理 system-docker 类Compose文件   应用管理 docker 直接run    ros ros是对系统进行管理的工具，所以必须要以root权限执行，具体用法可以help看一下：\n$ sudo ros help NAME: ros - Control and configure RancherOS built: '2019-08-22T07:44:10Z' USAGE: ros [global options] command [command options] [arguments...] VERSION: v1.5.4 AUTHOR(S): Rancher Labs, Inc. COMMANDS: config, c configure settings # 配置管理 console manage which console container is used # 切换命令行 engine manage which Docker engine is used # 切换Docker版本 service, s # 系统服务管理 os operating system upgrade/downgrade # 内核管理 tls setup tls configuration # tls管理 install install RancherOS to disk # 安装系统 help, h Shows a list of commands or help for one command GLOBAL OPTIONS: --help, -h show help --version, -v print the version  ros config $ ros config NAME: ros config - configure settings USAGE: ros config command [arguments...] COMMANDS: get get value # 获取配置 set set a value # 设定配置 images List Docker images for a configuration from a file # 没用过 generate Generate a configuration file from a template # 没用过 export export configuration # 输出配置，比直接看cloud-config.yml全面 merge merge configuration from stdin # 合并配置文件 syslinux edit Syslinux boot global.cfg # 没用过 validate validate configuration from stdin # 校验配置文件格式  所有面向系统的设置都是通过ros config进行管理的，默认的配置存放在/var/lib/rancher/conf/cloud-config.yml中。未记录的配置修改都会在重启后失效(是的，sudo passwd也不能让你下次直接用户名密码登陆，不过有别的办法)\n简单的修改配置可以直接执行ros config set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;，比如\nros config set rancher.docker.tls true；\n多个值写成列表，比如\nros config set rancher.network.dns.nameservers \u0026quot;['8.8.8.8','8.8.4.4']\u0026quot;；\n复杂一点的可以写一个小的yml，然后执行ros config merge -i \u0026lt;文件\u0026gt;进行合并， 理论上也可以手动添加到/var/lib/rancher/conf/cloud-config.yml中。 但是个人不推荐这样做，因为现在版本的cloud-config.yml和ros config export输出的不是一回事，待研究。\nros service $ ros service NAME: ros service - USAGE: ros service command [command options] [arguments...] COMMANDS: enable turn on an service # 启用服务 disable turn off an service # 禁止服务 list list services and state # 服务列表 delete delete a service # 删除服务 build Build or rebuild services # 构建/重构服务 create Create services # 创建服务 up Create and start containers # 创建并启动服务 start Start services # 启动服务 logs View output from containers # 查看服务日志 restart Restart services # 重启服务 stop Stop services # 停止服务 rm Delete services # 删除服务及镜像 pull Pulls service images # pull服务镜像 kill Kill containers # 杀死服务容器 ps List containers # 列出服务容器 OPTIONS: --tls Use TLS; implied by --tlsverify --tlsverify Use TLS and verify the remote [$DOCKER_TLS_VERIFY] --tlscacert value Trust certs signed only by this CA --tlscert value Path to TLS certificate file --tlskey value Path to TLS key file --configdir value Path to docker config dir, default ${HOME}/.docker --verbose, --debug --help, -h show help  控制的是随系统启动的服务，用法包括声明文件的写法基本和Docker Compose一样，把它理解成Docker Compose的替代品就对了。\n别的命令不解释了\u0026hellip;\n系统服务 $ ros s list disabled amazon-ecs-agent disabled container-cron disabled open-iscsi disabled zfs disabled kernel-extras disabled kernel-headers disabled kernel-headers-system-docker enabled open-vm-tools disabled hyperv-vm-tools disabled qemu-guest-agent disabled rancher-server disabled rancher-server-stable disabled amazon-metadata disabled volume-cifs disabled volume-efs disabled volume-nfs disabled modem-manager disabled waagent disabled virtualbox-tools disabled pingan-amc  上面说到系统级的服务都是用ros s控制启停，而想要自定义一个系统级的服务的话:\n 用Docker Compose语法编写服务的xxx.yml文件，一般存放到/var/lib/rancher/conf/ ros service enable /var/lib/rancher/conf/xxx.yml 启用该服务 ros service up \u0026lt;serviceName\u0026gt;启动服务，如果一个Compose里定义了多个服务，那么需要 ros service up \u0026lt;serviceName1\u0026gt; \u0026lt;serviceName2\u0026gt; \u0026lt;serviceName3\u0026gt; ...来同时启动  docker 没啥好说的\u0026hellip;Just use it.\ncloud-config 额外说一下这个cloud-config。\n现有的公有云/虚拟化厂商大多支持cloud-init工具进行系统配置初始化(某种意义上的事实标准)。cloud-config就是为cloud-init服务的。RancherOS在system-docker中运行了一个cloud-init容器，它会在启动时查找可能位置上的cloud-config文件并依此配置系统配置项。\ncloud-config的语法格式就是标准的YAML语法，一个我在用的、比较完整的cloud-config的示例如下：\n 使用时请删除掉中文注释\u0026hellip;给别人演示的时候懒得删注释结果validate没问题，但是配置就是不生效\u0026hellip;   # 主机名 hostname: ros-test # 系统配置 rancher: # 替换控制台为alpine，也可以是ubuntu/centos/debian... console: alpine # 初始Docker源 bootstrap_docker: registry_mirror: \u0026quot;https://docker.mirrors.ustc.edu.cn/\u0026quot; # 系统Docker源 system_docker: registry_mirror: \u0026quot;https://docker.mirrors.ustc.edu.cn/\u0026quot; # 用户Docker源 docker: registry_mirror: \u0026quot;https://docker.mirrors.ustc.edu.cn/\u0026quot; # 网络 network: interfaces: eth0: # IP要是CIDR格式，要是和子网掩码对不上就上不了网 address: 192.168.0.1/24 # netmask: 255.255.255.0 # broadcast: 192.168.0.255 gateway: 192.168.0.254 mtu: 1500 dhcp: false dns: nameservers: - 114.114.114.114 - 8.8.8.8 # # 扩容现有磁盘不要用fdisk，除非你想把系统格式化了，用这个就能调整磁盘大小 # resize_device: /dev/sda # 可登录的机器公钥 ssh_authorized_keys: - ssh-rsa ... - ssh-rsa ... # # 挂载新磁盘 # mounts: # - [\u0026quot;/dev/vdb\u0026quot;, \u0026quot;/mnt/s\u0026quot;, \u0026quot;ext4\u0026quot;, \u0026quot;\u0026quot;] # 写文件 write_files: # 修改apk使用国内镜像 - path: /etc/apk/repositories permissions: \u0026quot;0755\u0026quot; owner: root content: | https://mirrors.ustc.edu.cn/alpine/latest-stable/main https://mirrors.ustc.edu.cn/alpine/latest-stable/community # 设置CST时区 - path: /etc/profile permissions: \u0026quot;0755\u0026quot; owner: root content: | export CHARSET=UTF-8 export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin export PAGER=less # 显示样式 export PS1=\u0026quot;\\[\\e[37m\\][\\[\\e[32m\\]\\u\\[\\e[37m\\]@\\h \\[\\e[36m\\]\\w\\[\\e[0m\\]]\\\\$ \u0026quot; # 时区 export TZ='CST-8' umask 022 for script in /etc/profile.d/*.sh ; do if [ -r $script ] ; then . $script fi done # 确保ssh连接时会读取.bashrc - path: /home/rancher/.bash_profile permissions: \u0026quot;0755\u0026quot; owner: rancher content: | # If the shell is interactive and .bashrc exists, get the aliases and functions if [[ $- == *i* \u0026amp;\u0026amp; -f ~/.bashrc ]]; then . ~/.bashrc fi # 配置.bashrc - path: /home/rancher/.bashrc permissions: \u0026quot;0755\u0026quot; owner: rancher content: | # .bashrc # User specific aliases and functions alias d=\u0026quot;docker \u0026quot; alias di=\u0026quot;docker image\u0026quot; alias dc=\u0026quot;docker container\u0026quot; alias dv=\u0026quot;docker volumn\u0026quot; alias dn=\u0026quot;docker netwrok\u0026quot; # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # 启动时执行命令 runcmd: # # 两种写法 # - [touch, /home/rancher/test1] # - echo \u0026quot;test\u0026quot; \u0026gt; /home/rancher/test2 # 开机更新apk源 - apk update # 启动定时任务服务 - crond  ","date":1567323590,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1567323590,"objectID":"9069bd3a6e93ed1c918cdd04192ab2c0","permalink":"https://szthanatos.github.io/post/rancheros/","publishdate":"2019-09-01T15:39:50+08:00","relpermalink":"/post/rancheros/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 介绍 RancherOS是Rancher推出的一个轻量级的Linux内核操作系统，专为容器环境而设计。 按官网的说法，它具有如下特性： 官方","tags":["os","rancher"],"title":"RancherOS初步使用小结","type":"post"},{"authors":null,"categories":null,"content":" 报错信息  Error: Connection reset by peer\n 原因 读写操作发生在连接断开后。\n解决办法  用info/cluster info命令检查连接数是否过多 检查redis-server是否正确监听配置文件 检查配置文件中bind部分，如果是bind 127.0.0.1则只允许本地访问 检查配置文件中protected-mode部分是否为no 重启redis-server  ","date":1560697601,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1560697601,"objectID":"cc3ccad3ab9881e5de1c2308b16360f7","permalink":"https://szthanatos.github.io/topic/redis/error-connection_reset/","publishdate":"2019-06-16T23:06:41+08:00","relpermalink":"/topic/redis/error-connection_reset/","section":"topic","summary":"报错信息 Error: Connection reset by peer 原因 读写操作发生在连接断开后。 解决办法 用info/cluster info命令检查连接数是否过多 检查redis-server","tags":null,"title":"解决 Error connection reset by peer","type":"docs"},{"authors":null,"categories":null,"content":" 操作 批量操作 传统数据库也存在批量操作效率高于单次操作的情况，但是redis由于执行效率更高，批量操作带来的提升也更夸张。举个不是很恰当的例子，还是按redis每秒能处理10k请求来算——\n假设客户端和服务端不在同一机器，网络通信存在额外1ms延时：\n   操作 时间     1000次get 1000 * 1 + 1000 * 0.01 = 1010 (ms)   10次100个键值对的mget 10 * (1 * 1 + 100 * 0.01) = 20 (ms)   1次1000个键值对的mget 1 * 1 + 1000 * 0.01 = 11 (ms)    如果一条条去执行，这时redis每秒只能处理1000 / 1.01 ≈ 990次请求，只发挥了实际计算力的0.99%。\nMulti-action vs Pipeline vs Transaction 批量操作有3种实现方式：\nMulti-action\n也就是m开头的命令，比如mget\n优点：\n 效率是最高的，因为它只需要解析一条命令  缺点：\n 只能做一件事 一次操作的key太多的话会导致redis实例的响应能力等比下降 不具有原子性，存在部分成功部分失败的情况  Pipeline\n管道式的操作\n优点：\n 可以处理多类数据 可以将大量命令分解为多个包依次发送执行 使用灵活  缺点：\n 不保证事务，其他客户端发送的命令可能在pipeline执行期间被执行 不具有原子性，存在部分成功部分失败的情况  Transaction\n事务\n优点：\n 原子性，要么全执行要么不执行 乐观锁  缺点：\n 命令会被分批发送给服务端，最后统一执行，性能是最低的(但还是远高于执行n次命令) 随着竞争激烈程度的上升，乐观锁会导致性能相应下降 在集群中，只有同属于一个哈希槽的键才能使用事务，多数客户端支持的不好  另外，因为Pipeline是基于redis自定义的RESP协议实现的，而Transaction是命令实现，所以给了我们组合使用的机会。相比直接使用事务会快上一点点，没有太大区别。\n总的来说，实现批量执行的核心肯定是Pipeline，请尽可能的使用。\n放上一组官方测试结果以供参考：\n# Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (with pipelining) $ ./redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -P 16 -q \u0026gt; SET: 552028.75 requests per second \u0026gt; GET: 707463.75 requests per second \u0026gt; LPUSH: 767459.75 requests per second \u0026gt; LPOP: 770119.38 requests per second # Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (without pipelining) $ ./redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -q \u0026gt; SET: 122556.53 requests per second \u0026gt; GET: 123601.76 requests per second \u0026gt; LPUSH: 136752.14 requests per second \u0026gt; LPOP: 132424.03 requests per second  减少阻塞 另一方面，针对每条命令，由于redis是单进程单线程的模式，命令是依次执行的，想象一下星巴克排队，只要有一个客人堵在那，后面的不管买多买少都只能排着\u0026hellip;\n可能造成阻塞的命令包括：\n del，这个删除是在前台阻塞式的删除，在redis4.0以后应该使用unlink后台非阻塞的标记删除 keys、hgetall、smembers，这类返回所有结果的命令都会占用大量资源，都应该用scan、hscan、sscan等命令替换 sinter/sunion/sdiff的结果如果会重复使用的话，用sinterstore/sunionstore/sdiffstore将结果保存起来 sort，可以先取到本地再排序 能用mget/mhset的情况下就不要用get/set 总之，所有时间复杂度大于O(log n)的操作都应该考虑有没有更低占用的实现  除了命令本身，造成阻塞的原因还有：\n CPU饱和：cpu占用率100%了 CPU竞争：和其他服务竞争资源 持久化带来的IO阻塞  fork阻塞：rdb/aof文件重写的时候fork出的子进程长时间不能完成，导致的主进程阻塞 AOF阻塞：数据变动剧烈的时候fsync持续写硬盘导致的 HugePage阻塞：如果linux内核里启用了transparent_hugepage，会对内存和延迟带来很大影响  内存交换：物理内存不够用了，部分数据被写到Linux的虚拟内存，也就是swap，但是内存和磁盘的读写速度起码差了5个量级 网络问题  这些就需要在使用过程中不断监测和发现了。\n策略 过期回收 随着时间增长，碎片化的无用key的数量也会持续上升，直到最终你的内存被垃圾Key占满。 所以一个好习惯是给不需要持久存储(redis本身就不是用来持久化的)的Key都加上过期时间。\n   命令 注释     EXPIRE \u0026lt;KEY\u0026gt; \u0026lt;TTL\u0026gt; 将键的生存时间设为 ttl 秒   PEXPIRE \u0026lt;KEY\u0026gt; \u0026lt;TTL\u0026gt; 将键的生存时间设为 ttl 毫秒   EXPIREAT \u0026lt;KEY\u0026gt; \u0026lt;timestamp\u0026gt; 将键的过期时间设为 timestamp 所指定的秒数时间戳   PEXPIREAT \u0026lt;KEY\u0026gt; \u0026lt;timestamp\u0026gt; 将键的过期时间设为 timestamp 所指定的毫秒数时间戳.    但是需要注意，过期键的内存空间默认并不会被立即回收。redis的内存回收策略主要是这两个：\n 被动删除，读/写过期键时触发删除； 主动删除，每隔100ms检查20个带过期时间的键，如果有超过四分之一的键过期，则重复上面步骤；  另外，设置maxmemory最大内存，可以在达到内存阈值的时候触发强制删除机制(配置项maxmemory-policy)：\n noeviction，禁止强制删除，默认策略； volatile-ttl，从带过期时间的键中删除最接近过期的； volatile-lru，从带过期时间的键中删除最近最久未使用的(Least Recently Used)； volatile-lfu，从带过期时间的键中删除最近最少使用的(Least Frequently Used)； volatile-random，从带过期时间的键中随机删除； allkeys-lru，从所有键中删除最近最久未使用的； allkeys-lfu，从所有键中删除最近最少使用的； allkeys-random，从带过期时间的键中随机删除；  持久化 redis数据落到硬盘依赖两种持久化机制：RDB和AOF。\n    RDB AOF     存储内容 数据 写操作日志   性能影响 小 大   恢复速度 高 低   存储空间 小 大   可读性 低 高   安全程度 较低，保存频率低 较高，保存频率高   默认开启 是 否   存储策略 save 900 1：九百秒内一次修改即保存\nsave 300 10：三百秒内十次修改即保存\nsave 60 10000：六十秒内一万次修改即保存\n允许自定义 always：逐条保存\nor\neverysec：每秒保存\nor\nno：系统自己决定什么时候保存    RDB的save策略配合大键有时候简直性能地狱。必要时请重写触发机制。\nAOF的日志文件会膨胀的非常厉害，所以会定期重写。如果文件变动过于剧烈，你会发现swap比内存更先被吃干净。\nredis4.0以后支持一个叫aof-use-rdb-preamble的参数，意思就是在重写AOF文件的时候，会把早期日志写成RDB格式，新增加的继续使用AOF。这样一来可以替高重写和恢复的速度。某种意义上有了这个就不必单独开启RDB持久化了。\n内存清理 在redis4.0之后，可以通过将配置里的activedefrag设置为yes开启自动清理，或者通过memory purge命令手动清理。\n","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"1c7fa721611ef9198301d69b0e985670","permalink":"https://szthanatos.github.io/topic/redis/improve-02/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/improve-02/","section":"topic","summary":"操作 批量操作 传统数据库也存在批量操作效率高于单次操作的情况，但是redis由于执行效率更高，批量操作带来的提升也更夸张。举个不是很恰当的例子","tags":null,"title":"优化指南-使用","type":"docs"},{"authors":null,"categories":null,"content":" 数据结构 不同数据类型对应的操作的时间复杂度也不一样，选择合适的数据类型可以降低很多时间成本：\nString    命令 时间复杂度     SET key value [EX seconds] [PX milliseconds] [NX|XX] O(1)   SETNX key value O(1)   SETEX key seconds value O(1)   PSETEX key milliseconds value O(1)   GET key O(1)   GETSET key value O(1)   STRLEN key O(1)   APPEND key value 平均O(1)   SETRANGE key offset value 短字符串平均O(1)/长字符串O(N)，N为value长度   GETRANGE key start end O(N)，N为返回值长度   INCR key O(1)   INCRBY key increment O(1)   INCRBYFLOAT key increment O(1)   DECR key O(1)   DECRBY key decrement O(1)   MSET key value [key value …] O(N)   MSETNX key value [key value …] O(N)   MGET key [key …] O(N)    List    命令 时间复杂度     LPUSH key value [value …] O(1)   LPUSHX key value O(1)   RPUSH key value [value …] O(1)   RPUSHX key value O(1)   LPOP key O(1)   RPOP key O(1)   RPOPLPUSH source destination O(1)   LREM key count value O(N)   LLEN key O(1)   LINDEX key index O(N)，N 为到达下标index过程中经过的元素数量   LINSERT key BEFORE|AFTER pivot value O(N)，N 为寻找pivot过程中经过的元素数量   LSET key index value 头尾元素O(1)，其他O(N)   LRANGE key start stop O(S+N)，S 为偏移量 start ， N 为指定区间内元素的数   LTRIM key start stop O(N)   BLPOP key [key …] timeout O(1)   BRPOP key [key …] timeout O(1)   BRPOPLPUSH source destination timeout O(1)    Hash    命令 时间复杂度     HSET hash field value O(1)   HSETNX hash field value O(1)   HGET hash field O(1)   HEXISTS hash field O(1)   HDEL key field [field …] O(N)   HLEN key O(1)   HSTRLEN key field O(1)   HINCRBY key field increment O(1)   HINCRBYFLOAT key field increment O(1)   HMSET key field value [field value …] O(N)   HMGET key field [field …] O(N)   HKEYS key O(N)   HVALS key O(N)   HGETALL key O(N)   HSCAN key cursor [MATCH pattern] [COUNT count] O(1)    Set    命令 时间复杂度     SADD key member [member …] O(N)   SISMEMBER key member O(1)   SPOP key O(1)   SRANDMEMBER key [count] 无conut时O(1)，有conut时O(N)   SREM key member [member …] O(N)   SMOVE source destination member O(1)   SCARD key O(1)   SMEMBERS key O(N)   SSCAN key cursor [MATCH pattern] [COUNT count] O(1)   SINTER key [key …] O(N*M)， N 为给定集合当中基数最小的集合， M 为给定集合的个数   SINTERSTORE destination key [key …] O(N*M)   SUNION key [key …] O(N)   SUNIONSTORE destination key [key …] O(N)   SDIFF key [key …] O(N)   SDIFFSTORE destination key [key …] O(N)    ZSet    命令 时间复杂度     ZADD key score member [[score member] [score member] …] O(M*log(N))，N 是有序集的基数， M 为成功添加的新成员的数量   ZSCORE key member O(1)   ZINCRBY key increment member O(log(N))   ZCARD key O(1)   ZCOUNT key min max O(log(N))   ZRANGE key start stop [WITHSCORES] O(log(N)+M)，N 为有序集的基数，而 M 为结果集的基数   ZREVRANGE key start stop [WITHSCORES] O(log(N)+M)   ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] O(log(N)+M)   ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] O(log(N)+M)   ZRANK key member O(log(N))   ZREVRANK key member O(log(N))   ZREM key member [member …] O(M*log(N))   ZREMRANGEBYRANK key start stop O(log(N)+M)   ZREMRANGEBYSCORE key min max O(log(N)+M)   ZRANGEBYLEX key min max [LIMIT offset count] O(log(N)+M)，N 为有序集合的元素数量， 而 M 则是命令返回的元素数量   ZLEXCOUNT key min max O(log(N))   ZREMRANGEBYLEX key min max O(log(N)+M)，N 为有序集合的元素数量， 而 M 则为被移除的元素数量   ZSCAN key cursor [MATCH pattern] [COUNT count] O(1)   ZUNIONSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] O(N)+O(M log(M))，N 为给定有序集基数的总和， M 为结果集的基数   ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] O(N*K)+O(M*log(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数    模拟类型 除了直接使用redis数据类型，其他的一些常见数据结构也可以用固定操作模拟出来：\n 堆栈：lpush + lpop = Stack 队列：lpush + rpop = Queue 有限集合：lpush + ltrim = Capped Collection 消息队列1：lpush + brpop = Message Queue  负载 redis基本的逻辑存储单位是键(Key)对象，键底层的编码方式会随着键的类型/大小而改变：\n   编码方式(C语言实现) 情况     String类型    int(long类型整数) long能存下的整数值   embstr(embstr类型的简单动态字符串SDS) \u0026lt;=32字节的字符串   raw(简单动态字符串SDS)    List类型    ziplist(压缩列表) 列表内元素不超过512个并且所有元素长度都小于64字节   linkedlist(双端链表)    Hash类型    ziplist 哈希内不超过512个键值对并且所有键值对的键和值的长度都小于64字节   hashtable(字典)    Set类型    intset(整数集合) 集合内元素不超过512个并且所有元素都是整数值   hashtable    ZSet类型    ziplist 有序集合内元素不超过128个并且所有元素的长度都小于64字节   skiplist(跳跃表和字典)     所以简单的来说，String长度小于32字节，其他复合类型元素个数不超过512个(ZSet不超过128个)并且元素小于64字节或者是整数(Set)的时候，是redis认为的一个key的合理值，超过这个范围redis也是允许的，但是关注点就放在存储而不是性能上了。\n大键会拖累存储性能。尤其是在时间复杂度不是O(1)的操作上，性能损失是线性(eg: LREM)甚至指数(eg: ZINTERSTORE)上升的。\n过小(零碎)的键也不合适，它是对性能的一种浪费，比如要存放用户: 用户信息，直接将每个用户存为一个String，相比用Hash把所有用户存储在一个键上，想要实现hgetall这样的操作既复杂，效率也更低。\n集群倾斜 \u0026amp; 热点问题 在集群中，redis是划分出16384个哈希槽，然后将哈希槽平均(也可以手动指定)分配到集群节点上。键会通过crc16算法计算并将结果对16384取余，由此将键映射到编号为0~16383的哈希槽中。\n大键会造成集群倾斜，也就是大键所在节点的内存可能被占满了，而其他节点还空着。极端情况下如果一个键所占空间超过了节点分配的内存，那这个集群可能会永远fail下去——虽然有大量内存空着，但是没有一个节点能放下这个键了。\n大键越多，分布越不均匀，在集群中就越容易出现热点问题(另一种角度的倾斜)，简单来说，就是\n 由于数据都集中在一个键 → 对数据的操作都集中在一个键 → 键位于某个哈希槽 → 哈希槽所在的节点读写压力非常大 → 集群其他节点都在划水  假设是3个master的集群，本来的处理能力可能是100000 q/s * 3，这样的情况下实际发挥出来的就只有100000 q/s了。\n针对大键\u0026amp;倾斜问题可以有以下措施：\n 将可能的大键进行拆分，比如将一个大List拆成List0~List9； 在集群配置中开启readonly以降低主节点读压力(详见《Redis集群相关命令》)； 根据实际情况，修改redis变更编码类型的阈值，比如设定list-max-ziplist-entries=1024让元素在1024以内的列表都用ziplist编码；   redis5中提供新的数据结构Stream，直接实现了Kafka那种支持多播的消息队列 ^   ","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"c46f6d305c2d6d0bebb6d5ee65dc7477","permalink":"https://szthanatos.github.io/topic/redis/improve-01/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/improve-01/","section":"topic","summary":"数据结构 不同数据类型对应的操作的时间复杂度也不一样，选择合适的数据类型可以降低很多时间成本： String 命令 时间复杂度 SET key value [EX seconds] [PX milliseconds] [NX|XX] O(1) SETNX key value O(1) SETEX key seconds","tags":null,"title":"优化指南-设计","type":"docs"},{"authors":null,"categories":null,"content":" 监控 为了发现前面所说的问题，需要开发/运维人员不断的监控redis运行情况。\nredis-cli 查询 部分信息无法通过redis命令直接获取，但是可以通过redis-cli [参数]获取：\n–-bigkeys\n后台scan出每种数据类型中较大的key\n--latency\n服务端响应延时\nslowlog命令 在客户端执行slowlog get [n]可以获取最慢的n条执行命令的记录\ninfo命令 返回服务器信息，性能监测的时候注意其中的几个部分：\nmemory：mem_fragmentation_ratio\n内存碎片率，used_memory_rss(系统分配内存总量)和used_memory(Redis分配器分配的内存总量)的比值。\n在1-1.5之间都是合理值，1.5则说明碎片过多需要清理了。\nstats：latest_fork_usec\n最近一次fork操作耗时\npersistence：aof_delayed_fsync\n被延迟的fsync调用数量\nclients：connected_clients，blocked_clients\n已连接客户端的数量和正在等待阻塞命令的客户端的数量\nmonitor命令 可以用来监测一个节点一段时间内执行的命令，从而统计出热点key。但是monitor自己也是有内存占用的，所以不能频繁、持续的使用。\n部署 网络 影响redis性能的最主要因素是网络。\n按官方基准测试来说，对于10kb以内的数据，redis的处理能力在100000q/s以上。\n那么假设每次set/get的4kb大小的字符串，这时占用的带宽就有3.2 Gbit/s ，千兆网卡(1 Gbit/s)就不够用了，得换万兆网卡(10 Gbit/s)才能满足需求，可见想跑满redis的CPU计算力对网络的要求是很夸张的。\n当然，这个例子比较极端，redis官方推荐的网络环境下每次传输的包最好不超过一个MTU(大约 1500 bytes)。\n如果完全抛开网络因素，客户端服务端都在单机上时，使用Unix域套接字(Unix domain sockets，也叫IPC(inter-precess communication) socket进程间通信套接字)替换默认的TCP/IP连接方式，能额外再有50%的吞吐量提升(不过在大量使用pipeline的情况下就没差这么多了)。\n启用Unix域套接字需要在配置文件中取消注释：\n# unixsocket路径 unixsocket /tmp/redis.sock # unixsocket权限 unixsocketperm 700  之后就可以在客户端使用指定方式连接了，以python客户端为例：\nimport redis redis_connect = redis.Redis(unix_socket_path='/tmp/redis.sock') pass  CPU redis更倾向于具有更大缓存而不是更多核的CPU，在多核的情况下，redis性能会受NUMA配置和进程所处位置的影响，指定客户端和服务器使用同一CPU的两个不同核心可以使从L3缓存获得的收益最大化。\n另外，redis在Inter和AMD的CPU上的表现也有差别，在某些情况下在AMD的CPU上性能可能只有Inter的一半。\n内存 只有在面对大于10KB的数据的时候，内存频率/带宽才会影响redis性能，所以一般不用去考虑。内存大小只会影响能存放的数据量。\n连接数 redis可以在60000多个连接时维持50000 q/s的性能，但是根据官方测试，具有30000个连接的redis实例只能处理100个连接实例可实现的吞吐量的一半。\n虚拟化 虚拟机中的redis性能肯定是低于实机上的，系统调用和中断上面浪费的太多。\n","date":1552892675,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552892675,"objectID":"cb0e09802a5324df0c8f044af9a753fd","permalink":"https://szthanatos.github.io/topic/redis/improve-03/","publishdate":"2019-03-18T15:04:35+08:00","relpermalink":"/topic/redis/improve-03/","section":"topic","summary":"监控 为了发现前面所说的问题，需要开发/运维人员不断的监控redis运行情况。 redis-cli 查询 部分信息无法通过redis命令直接获取，但是可以通过red","tags":null,"title":"优化指南-运维","type":"docs"},{"authors":[],"categories":["KG"],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n基本环境 底层数据库基于HBase，检索服务基于Elasticserach。\n系统运行服务大致如下：\n[root@xnode208 ~] jps 21584 GremlinServer 27857 DataNode 23218 Jps 3251 HMaster 27283 NameNode 21707 Console 17131 Elasticsearch 29503 SecondaryNameNode  安装 下载janusgraph0.22安装包并解压\nwget https://github.com/JanusGraph/janusgraph/releases/download/v0.2.2/janusgraph-0.2.2-hadoop2.zip unzip janusgraph-0.2.2-hadoop2.zip cd janusgraph-0.2.2-hadoop2  配置 在这里我们采用的是启动gremlin-server服务时，加载指定配置文件的方法创建图表，所以需要设置gremlin-server端以及图表的配置文件。\n 创建gremlin-server端配置文件janusgraph-0.2.2-hadoop2/conf/gremlin-server/socket-gremlin-server.yaml，这里我们复制gremlin服务默认的配置文件，在此基础上进行修改\ncp conf/gremlin-server/gremlin-server.yaml conf/gremlin-server/socket-gremlin-server.yaml  修改socket-gremlin-server.yaml：在配置文件中添加graphManager;并在graphs项中添加graph键及其值，一个键值代表一个图表，值表示对图表的设置(可添加多个图表，每一个图表都有自己的配置文件)，如：\ngraphManager: org.janusgraph.graphdb.management.JanusGraphManager graphs: { blablabla, graph: conf/gremlin-server/socket-jg-hbase_fyk-server-configraph.properties }  准备上述socket-gremlin-server.yaml中对图表进行设置的properties文件，conf/gremlin-server/socket-jg-hbase_fyk-server-configraph.properties文件内容如下：\ngremlin.graph=org.janusgraph.core.JanusGraphFactory graph.graphname=graph storage.backend=hbase # 设置我们本地启动的hbase作为底层数据库 storage.hostname=127.0.0.1 index.search.backend=elasticsearch # 设置Janus graph自带的es作为我们的检索服务 index.search.hostname=127.0.0.1 cache.db-cache = true cache.db-cache-clean-wait = 20 cache.db-cache-time = 180000 cache.db-cache-size = 0.5   基本用法 依次启动hbase,elasticsearch以及gremlin-server，最后进入gremlin.sh客户端对图表进行操作\n hbase\n[root@xnode208 ~] start-hbase.sh  elasticsearch.(注：Janusgraph自带的elastic search服务启动时为确保安全被禁止使用root用户)\n[zkr@xnode208 ~] cd /usr/local/janusgraph-0.2.2-hadoop2 [zkr@xnode208 elasticsearch] ./bin/elasticsearch  gremlin-server(启动成功后，会创建我们在配置文件中设计的图表)\n[zkr@xnode208 janusgraph0.2] ./bin/gremlin-server.sh ./conf/gremlin-server/socket-gremlin-server.yaml  gremlin.sh(进入gremlin交互式客户端)\n[root@xnode208 janusgraph0.2] ./bin/gremlin.sh gremlin\u0026gt;   加载诸神图 # 连接gremlin server gremlin\u0026gt; :remote connect tinkerpop.server conf/remote.yaml session ==\u0026gt;Configured localhost/127.0.0.1:8182-[f6db862e-752c-48db-839b-1b5b16f1786a] gremlin\u0026gt; :remote console ==\u0026gt;All scripts will now be sent to Gremlin Server - [localhost/127.0.0.1:8182]-[f6db862e-752c-48db-839b-1b5b16f1786a] - type ':remote console' to return to local mode # 加载诸神图到我们创建的空图表中 gremlin\u0026gt; GraphOfTheGodsFactory.load(graph) ==\u0026gt;null  示例数据描述了一部分希腊诸神以及他们居住的诸神殿的相关关系。\n   符号 含义     粗体键 带索引的键   星标粗体键 具有唯一值的带索引的键   带下划线的键 以顶点为核心的带索引的键   空心箭头边 不能有多个指向的唯一边   尾部划线的边 单向边    在JanusGraph中，实体以顶点表示，关系以边表示，顶点和边都可以具有属性。\n一些基本操作 增操作 # 添加顶点 v1 = graph.addVertex(label, 'student'); # 创建第一个顶点v1并增加标签 v2 = graph.addVertex(); # 创建第二个顶点没有标签 # 为顶点添加属性 v1.property('id', '1'); # 为顶点v1添加id属性，值为1 v3 = graph.addVertex(label,'girl','name','huahua'); # 创建第三个顶点并且增加标签，属性以及属性值 v4 = graph.addVertex(label,'boy','name','wuyanzu','age',18) # 创建第四个顶点添加标签以及多个属性属性值 # 添加边 t1 = v1.addEdge('friends', v2); # 为v1添加关系到v2,并定义这个关系为t1 t2 = v1.addEdge('boyfriend', v2); # 两个顶点之间可以增加多种关系 # 为边增加属性 t1.property('reason','cool'); # 为t1增加属性 v3.addEdge('boyfriend',v4,'reason','because the reason'); # v3添加关系到v4并且增加关系属性及属性值 # 提交修改 graph.tx().commit();  删操作 # 清空 g.V().drop(); # 删除所有点/图 g.E().drop(); # 删除所有边 graph1.close(); JanusGraphFactory.drop(graph1); # 清空图中的所有数据 # 删除顶点 pluto = g.V().has('name','pluto').next();g.V(pluto).drop().iterate(); # 删除name属性为\u0026quot;pluto\u0026quot;的顶点 g.V().has('keys','ll').drop().iterate(); # 删除keys属性为\u0026quot;ll\u0026quot;的顶点 g.V().hasLabel('student').has('name','ll').drop().iterate(); # 删除标签为student，并且顶点属性name的值为\u0026quot;ll\u0026quot;的顶点 # 删除边 g.E().has('uuu','because the reason').drop().iterate(); # 删除边属性uuu的属性值为because the reason的边 g.E().hasLabel('boyfriend').has('event','the reason').drop().iterate(); # 删除边标签为boyfriend并且边属性event的值为the reason的边 # 删除顶点标签以及顶点属性 g.V().hasLabel('girl').drop(); # 删除标签girl以及标签为girl的所有顶点 g.V().properties('name').drop(); # 删除顶点属性name # 删除边标签、边属性以及属性值 g.E().hasLabel('boyfriend').drop(); # 删除边标签boyfriend g.E().properties('uuu').drop(); # 删除边属性uuu g.E().hasLabel(\u0026quot;friend\u0026quot;).properties().drop(); # 删除边标签为friend的所有属性以及属性值 g.E().values('because the reason').drop(); # 删除边属性值为because the reason以及对应的属性 graph.tx().commit(); # 提交  查询 # 设置g=graph.traversal(),方便查询 gremlin\u0026gt; g = graph.traversal() ==\u0026gt;graphtraversalsource[standardjanusgraph[hbase:[127.0.0.1]], standard] # 顶点标签查询 g.V(); # 查看所有顶点id g.V().label(); # 查看所有顶点标签 g.V().hasLabel(\u0026quot;god\u0026quot;); # 查看所有标签为god的顶点id g.V().filter(label().is('god')); # 用filter查看所有标签为god的顶点id g.V().has('name','hercules'); # 查看属性为name,值为hercules的顶点 # 顶点属性及属性值查询 g.V().valueMap(); # 遍历每个顶点的属性及属性值(若没有展示空集) g.V().properties(); # 查看所有顶点的属性及属性值(不展示空) g.V().hasLabel(\u0026quot;god\u0026quot;).values(); # 查看所有顶点标签为god的属性值 g.V().hasLabel(\u0026quot;god\u0026quot;).properties(); # 查看顶点标签为god的所有顶点属性以及属性值 g.V().values('id'); # 查看顶点属性为id的属性值 g.V().properties('id') # 查看顶点属性为id的属性及属性值 # 边标签查询 g.E(); # 查看所有顶点之间的边 顶点id---\u0026gt;边---\u0026gt;顶点id g.E().label(); # 查看所有边的标签(关系) g.E().hasLabel(\u0026quot;battled\u0026quot;) # 查看标签为battled的所有边 g.E().filter(label().is('battled')); # 用filter查看标签为battled的所有边 g.E().has('time',12); # 查看属性time的值为12的所有边 # 边属性及属性值查询 g.E().valueMap(); # 遍历所有边属性及属性值 g.E().properties(); # 查看所有边属性及属性值 g.E().hasLabel(\u0026quot;battled\u0026quot;).values(); # 查看所有标签为battled的边属性值 g.E().hasLabel(\u0026quot;battled\u0026quot;).properties(); # 查看所有标签为battled的边属性以及属性值 g.E().values('reason'); # 查看边属性为reason的属性值 g.E().properties('reason'); # 查看边属性为reason的属性及属性值  ","date":1552830619,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1552830619,"objectID":"0fc099bb9b2b783e1e33cbd161d548d3","permalink":"https://szthanatos.github.io/post/janusgraph/","publishdate":"2019-03-17T21:50:19+08:00","relpermalink":"/post/janusgraph/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 基本环境 底层数据库基于HBase，检索服务基于Elasticserach。 系统运行服务大致如下： [root@xnode208 ~] jps 21584 GremlinServer 27857 DataNode 23218 Jps 3251 HMaster 27283 NameNode 21707 Console 17131 Elasticsearch 29503 SecondaryNameNode","tags":["graphdb","janusgraph","knowledge graph"],"title":"JanusGraph搭建及简单使用","type":"post"},{"authors":[],"categories":[],"content":" 理解Git没有比从三棵树开始更好的了。\n完整的话还是看git文档比较好，说的蛮清楚了。\n三棵树和正向流程    树 用途     HEAD 上一次提交的快照，下一次提交的父结点   Index 预期的下一次提交的快照   Working Directory 沙盒    git的核心工作就是管理这三棵树。git add就是把你工作目录(Working Directory)的修改提交到暂存区(Index)，git commit就是把暂存区的内容同步到仓库里作为一个快照，并移动HEAD指向新快照；额外说一下这个HEAD指针，每一次commit都相当于在仓库(Repository)里生成一个快照， 把N个快照想象成一个右进左出的队列(List)，再想象有一个指针，默认指向队首(最新快照)，告诉你当前到底用的是哪一个版本快照。\nreset 显然，git reset就是对上述行为的反向操作。\nreset的本质其实是移动HEAD指针指向哪个快照，而通过\n --soft——只改变指针指向的快照； --mixed——移动指针的同时也把快照内容同步到暂存区； --hard——三棵树全同步为指针指向的快照；  参数来递进的控制改变是发生在哪几颗树上。再强调一遍，reset的改变的是HEAD指针，而不是文件。即使git reset File的写法是有效的，但它的本质是git reset --mixed HEAD File的缩写，即将File从HEAD指向的快照复制到索引中。HEAD指针永远只能指向一个快照，但是快照是可以局部修改它里面的文件的。\nHEAD~表示前一个快照，HEAD~2表示前两个，依此类推。\ncheckout checkout的本质就有所不同，它关心的是分支(branch)，它的主要作用是让HEAD在不同分支间移动(默认三棵树都会更新)。\n还是拿刚才那个队列举例，分支相当于是平行的一条队列，现在把他放在你脑子里之前那个队列的上方， 由于HEAD指针只能指向一个快照，所以这个时候它可能会在两个队列间“跳动”，checkout就是控制指针上下移动的命令，而reset则是控制指针在当前队列左右(前后)移动。同样的，checkout后面也可以跟一个文件，和git reset --hard [branch] file可能会产生的效果一样。\n","date":1546668801,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546668801,"objectID":"174a4cfb6476bb134bc3eda05efdeeac","permalink":"https://szthanatos.github.io/post/git/git_trees/","publishdate":"2019-01-05T14:13:21+08:00","relpermalink":"/post/git/git_trees/","section":"post","summary":"理解Git没有比从三棵树开始更好的了。 完整的话还是看git文档比较好，说的蛮清楚了。 三棵树和正向流程 树 用途 HEAD 上一次提交的快照，下一次提交的父","tags":["Git"],"title":"Git三棵树和reset/checkout命令","type":"post"},{"authors":[],"categories":["Academic","Hugo"],"content":"  本文是对Academic文档-Writing content章节的个人翻译，基于个人理解，不保证绝对准确。\n原文见上方连接。\n  目录 Academic支持使用Markdown、LaTeX数学公式和Hugo代码段编写内容。 此外，可以使用HTML以实现高级样式。 本文概述最常见的格式选项。\n副标题 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6  强调 # 下划线内为斜体 Italics with _underscores_. # *内为粗体 Bold with **asterisks**. # 粗体和斜体可以组合 Combined emphasis with **asterisks and _underscores_**. # 双波浪符内为删除线 Strikethrough with ~~two tildes~~.  有序列表 1. First item 2. Another item  无序列表 我个人更习惯用 - * First item * Another item  图片 图片可以存放在你的媒体库static/img或你的页面文件夹。 使用以下任一方式即可引用图片：\n假设图片来自你的static/img媒体库：\n{{\u0026lt; figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  假设图片来自你的页面文件夹(比如content/post/hello/)\n{{\u0026lt; figure src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  带编号和标题的图片：\n{{\u0026lt; figure src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; numbered=\u0026quot;true\u0026quot; \u0026gt;}}  一般图片：\n![alternative text for search engines](/img/image.jpg)  图片集 为页面包增加一个图片集：\n 在页面包(也就是你的页面文件夹)内创建图片集文件夹； 将图片放入图片集文件夹； 粘贴{{\u0026lt; gallery album=\u0026quot;\u0026lt;ALBUM FOLDER\u0026gt;\u0026quot; \u0026gt;}}到文章中你想要它出现的地方，将album参数修改为你文件集的名称；  可选的，要为你的图片集添加标题的话，将下面的实例添加到你扉页的尾部:\n[[gallery_item]] album = \u0026quot;\u0026lt;ALBUM FOLDER\u0026gt;\u0026quot; image = \u0026quot;\u0026lt;IMAGE NAME\u0026gt;.jpg\u0026quot; caption = \u0026quot;Write your image caption here\u0026quot;  另外，想要在图片集中使用网络位置/媒体库中的图片；\n 将图片添加到static/img/文件夹； 在文章的扉页尾部声明图片引用：\n[[gallery_item]] album = \u0026quot;1\u0026quot; image = \u0026quot;my_image.jpg\u0026quot; caption = \u0026quot;Write your image caption here\u0026quot; [[gallery_item]] album = \u0026quot;1\u0026quot; image = \u0026quot;https://raw.githubusercontent.com/gcushen/hugo-academic/master/images/theme-dark.png\u0026quot; caption = \u0026quot;Dark theme\u0026quot;  在正文要显示的位置使用{{\u0026lt; gallery album=\u0026quot;1\u0026quot; \u0026gt;}}\n  视频 页面可以添加以下几种类型的视频。\n本地视频文件 要添加视频，将它放在static/img/媒体库或者页面文件夹内，使用以下任一方式即可引用。\n位于static/img/文件夹下的视频：\n{{\u0026lt; video library=\u0026quot;1\u0026quot; src=\u0026quot;my_video.mp4\u0026quot; controls=\u0026quot;yes\u0026quot; \u0026gt;}}  位于页面文件夹下的视频：\n{{\u0026lt; video src=\u0026quot;my_video.mp4\u0026quot; controls=\u0026quot;yes\u0026quot; \u0026gt;}}  Youtube {{\u0026lt; youtube w7Ft2ymGmfc \u0026gt;}}  Vimeo {{\u0026lt; vimeo 146022717 \u0026gt;}}  链接 [I'm a link](https://www.google.com) [A post]({{\u0026lt; ref \u0026quot;post/hi.md\u0026quot; \u0026gt;}}) [A publication]({{\u0026lt; ref \u0026quot;publication/hi.md\u0026quot; \u0026gt;}}) [A project]({{\u0026lt; ref \u0026quot;project/hi.md\u0026quot; \u0026gt;}}) [Another section]({{\u0026lt; relref \u0026quot;hi.md#who\u0026quot; \u0026gt;}})  想要链接到一个文件，比如PDF，首先将它放到static/files/文件夹下，然后使用下面方式链接：\n{{% staticref \u0026quot;files/cv.pdf\u0026quot; \u0026quot;newtab\u0026quot; %}}Download my CV{{% /staticref %}}  staticref的\u0026quot;newtab\u0026quot;参数将使链接在新页面打开。\n标签和分类 使用{{\u0026lt; list_tags \u0026gt;}}生成标签链接列表，使用{{\u0026lt; list_categories \u0026gt;}}生成分类链接列表。\nEmojis 可用Emojis见Emoji cheat sheet。 下面的这个示例在实际使用时需要把:和表情名之前的空格去掉：\nI : heart : Academic : smile :  I ❤️ Academic 😄\n段落引用 \u0026gt; This is a blockquote.   This is a blockquote.\n 高亮引用 This is a {{\u0026lt; hl \u0026gt;}}highlighted quote{{\u0026lt; /hl \u0026gt;}}.  This is a highlighted quote.\n脚注 I have more [^1] to say. [^1]: Footnote example.  嵌入文档 下面几种类型的文档可以被嵌入到页面中。\n要插入谷歌文档 (比如幻灯片)点击Google Docs中的 File \u0026gt; Publish to web \u0026gt; Embed 并复制src=\u0026quot;...\u0026quot;部分中的URL。 之后粘贴到下面代码中：\n{{\u0026lt; gdocs src=\u0026quot;https://docs.google.com/...\u0026quot; \u0026gt;}}  Speaker Deck {{\u0026lt; speakerdeck 4e8126e72d853c0060001f97 \u0026gt;}}  代码高亮 将语言的代码，比如python，作为参数放在三个反引号之后：(打出来```就会被解析，只能加空格了)\n` ` `python # Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var)) ` ` `  效果：\n# Example of code highlighting input_string_var = input(\u0026quot;Enter some data: \u0026quot;) print(\u0026quot;You entered: {}\u0026quot;.format(input_string_var))  高亮选项 Academic主题使用highlight.js作为高亮的来源，并且默认为所有页面启用。 并且，有一些更细粒度的选项可以控制highlight.js的显示效果。\n下表列出了highlight.js支持的一些选项，包含他们的类型和简短描述。 config.toml列中的\u0026rdquo;yes\u0026rdquo;表示允许在config.toml中全局设置， preamble列中的\u0026rdquo;yes\u0026rdquo;表示可以设定在特定页面中。\n   option type description config.toml preamble     highlight boolean 启用/禁用高亮 yes yes   highlight_languages slice 选择额外语言 yes yes   highlight_style string 选择高亮样式 yes no    highlight选项 highlight选项允许在全局或者特定页面启动/禁止语法高亮。 如果没有明确指定的话，默认会认为你设置了highlight = true。 也就是说，highlight.js的javascript/css文件会出现在每一个页面文件中。 如果你只希望那些真的需要使用的页面才有语法高亮， 你可以在config.toml中设置highlight = false， 之后在需要的页面的扉页覆盖为highlight = true。 相反，你也可以全局启用语法高亮，在不需要的页面中禁用。 下面给出一张展示不同全局和单独页面设置下，页面是否高亮。\n   config.toml page preamble highlighting enabled for page?     unset or true unset or true yes   unset or true false no   false unset or false no   false true yes    highlight_languages选项 highlight_languages选项允许你指定highlight.js支持的，但是不是默认支持的常见的语言。 比如，你想在所有页面高亮Go和clojure语言，那就在config.toml中设置highlight_languages = [\u0026quot;go\u0026quot;, \u0026quot;clojure\u0026quot;]。 另外，如果你想为页面只启用特定的语法高亮，那就去页面扉页设置highlight_languages。\n在config.toml和扉页设置的highlight_languages是累加的。 也就是说，如果config.toml里设置了highlight_languages = [\u0026quot;go\u0026quot;]，而扉页设置了highlight_languages = [\u0026quot;ocaml\u0026quot;]， 那么这个页面会包含两者的高亮文件。\n当你设置了highlight_languages之后，相应的高亮脚本会由cdnjs服务提供。 要查看支持的语言，访问cdnjs page页面并查找包含\u0026rdquo;languages\u0026rdquo;关键字的链接。\nhighlight_languages选项通过CDN提供了一种方便又容易的方式来满足附加语言的高亮需求。 如果cdnjs提供的默认的文件不能满足你的需求，你可以通过个性化指南中的方法来使用自己的javascript文件。\nhighlight_style选项 highlight_style选项允许你使用备选的高亮样式。 比如，如果你想使用solarized-dark样式，你可以在config.toml中设置highlight_style = \u0026quot;solarized-dark\u0026quot;。\n如果未设置highlight_style，默认会使用Academic提供的或者在你的static文件夹下的/css/highlight.min.css。 Academic提供的默认样式和github是一致的。\n如果设置了highlight_style，/css/highlight.min.css就会被忽略，相应的样式会由cdnjs服务提供。 要查看支持的样式列表，访问cdnjs page页面并查找包含\u0026rdquo;styles\u0026rdquo;关键字的链接。\n可以在highlight.js demo page上查看可用样式。\n 不是所有highlight.js demo page上列出的样式都在cdnjs服务上可用。 如果你想使用不是由cdnjs提供的样式，那么保持highlight_style未设置，然后将相应文件放到/static/css/highlight.min.css。    如果你不想更换Academic附带的样式，但是还是想由cdnjs提供服务，那么在config.toml中设置highlight_style = \u0026quot;github\u0026quot;。   只有在config.toml中设置的highlight_style才会生效，在扉页设置的highlight_style不会生效。\nTwitter tweet {{\u0026lt; tweet 666616452582129664 \u0026gt;}}  GitHub gist {{\u0026lt; gist USERNAME GIST-ID \u0026gt;}}  LATEX 数学公式 $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$   $$\\left [ – \\frac{\\hbar^2}{2 m} \\frac{\\partial^2}{\\partial x^2} + V \\right ] \\Psi = i \\hbar \\frac{\\partial}{\\partial t} \\Psi$$  另外，单行的数学公式可以只用单个$包裹：\nThis is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$  This is inline: $\\mathbf{y} = \\mathbf{X}\\boldsymbol\\beta + \\boldsymbol\\varepsilon$\n注意Markdown的特殊符号需要使用反斜杠转义，才能被识别为数学公式而非Markdown关键字。 比如*和_应该被替换为\\*和\\_。\n多行方程式 标准LaTeX的双反斜杠换行应该被替换为6个反斜杠：\n$$f(k;p\\_0^\\*) = \\begin{cases} p\\_0^\\* \u0026amp; \\text{if }k=1, \\\\\\\\\\\\ 1-p\\_0^\\* \u0026amp; \\text {if }k=0.\\end{cases}$$  $$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\n论文摘要 由于Hugo和Academic会尝试解析摘要中的TOML, Markdown, 以及LaTeX内容，论文的abstract和abstract_short部分应当遵循下面两个方针：\n LaTeX的反斜杠\\应该被转义为双反斜杠，也就是\\\\ LaTeX的下划线_应该被转义为双反斜杠加下划线，也就是\\\\_  因此，abstract = \u0026quot;${O(d_{\\max})}$\u0026quot;就会变成abstract = \u0026quot;${O(d\\\\_{\\\\max})}$\u0026quot;。\n表格 代码：\n| Command | Description | | --------------- | ------------------- | | `hugo` | Build your website. | | `hugo serve -w` | View your website. |  效果：\n   Command Description     hugo Build your website.   hugo serve -w View your website.    警报 在你为文章添加提示、注意项、警告时，警报是一个非常有用的功能。 尤其是对于教程性质的文章。 使用对应的短代码以在文章中显示警报：\n{{% alert note %}} Here's a tip or note... {{% /alert %}}  这会显示为如下 注意 项：\n Here\u0026rsquo;s a tip or note\u0026hellip;   {{% alert warning %}} Here's some important information... {{% /alert %}}  这会展示为如下 警告 项：\n Here\u0026rsquo;s some important information\u0026hellip;   目录 目录对于长文章或者教程/文档可能特别有用，在你Markdown正文的任何位置使用{{% toc %}}短代码自动生成目录。\n","date":1546318469,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546318469,"objectID":"99b7771e3814fdf15ef26819a895b7f2","permalink":"https://szthanatos.github.io/post/academic/trans_writing_content/","publishdate":"2019-01-01T12:54:29+08:00","relpermalink":"/post/academic/trans_writing_content/","section":"post","summary":"本文是对Academic文档-Writing content章节的个人翻译，基于个人理解，不保证绝对准确。 原文见上方连接。 目录 Academic","tags":["Translation","Academic","Hugo"],"title":"(翻译)Academic文档-内容编写","type":"post"},{"authors":[],"categories":["Academic","Hugo"],"content":"  本文是对Academic文档-Managing content章节的个人翻译，基于个人理解，不保证绝对准确。\n原文见上方连接。\n  目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n这是一个使用Academic框架管理你的文章的简短指南。 Academic提供的内容模板包括出版物、项目、宣讲、新闻/博客文章、以及小部件页。 之后，你可能同样对使用Markdown、LaTeX数学公式和代码段进行创作感兴趣。\n Hugo V0.49 版本在使用本指南中的hugo new命令时存在一个bug，请升级到V0.50及以上。   精选图片 要在文章页显示一个精选图片，简单的将名为featured.*(e.g. featured.jpg)的图片文件拖拽到文章文件夹即可。\n 如果你的页面在它所属的分类文件夹下没有自己的文件夹(页面包)， 你可以创建一个和你页面NAME.md同名的文件夹NAME，并将页面文件放入文件夹中，变为NAME/index.md。 这里有一个自动迁移工具。 使用页面包需要Academic v3+ 以及 Hugo v0.50以上。   想要为图片添加标题或者设置一个焦点以控制图片的裁剪？ 将下方的参数添加到扉页(也就是md文件+++括起来的部分)的底部以自定义图片的外观。 标题(caption)参数支持使用Markdown为图片添加标题或描述。 焦点(focal_point)参数确保图片自动缩放的时候主要内容始终可见。\n# Featured image # To use, add an image named `featured.jpg/png` to your page's folder. [image] # Caption (optional) caption = \u0026quot;Photo by [Academic](https://sourcethemes.com/academic/)\u0026quot; # Focal point (optional) # Options: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight focal_point = \u0026quot;Smart\u0026quot; # Show image only in page previews? preview_only = false  标题图片 将下面的header参数添加到扉页的末尾，以在页面顶部展示一个占据全部宽度的标题图片。 图片文件默认会从静态图片文件库static/img/读取(所以不必写全)，所以下面例子的图片文件的完整路径是static/img/header.png。 标题参数作用和精选图一致。\n[header] image = \u0026quot;header.png\u0026quot; caption = \u0026quot;Image credit: [**Academic**](https://github.com/gcushen/hugo-academic/)\u0026quot;  数学公式和代码 要在页面中启用LaTeX 渲染数学公式，在页面的扉页中应该申明math = true，如同示例网站的例子一样。 或者，在config.toml中设置math = true，以在全局范围内允许数学公式渲染。\n在config.toml中设置highlight = false以全局禁用代码高亮。你可以在需要代码高亮的页面的扉页单独设置highlight = true。 查看code-highlighting docs以获取更多细节。\n页面特性 将下述参数添加到页面扉页以管理页面特性：\nreading_time = false # 显示估计阅读时间 share = false # 显示分享按钮 profile = false # 显示作者信息 comments = false # 显示评论区  创建一个出版物 自动 先进的文献管理工具可以帮助你将你的出版物转化为开源的BibTeX格式。 如果你是新手的话我们推荐你使用流行的开源工具Zotero来管理你的文献。\n在你的文献管理工具中创建你自己的出版物列表并导出为*.bib格式的BibTeX文件。\n工具需要Python3环境，所以请先安装Python3。 同样，为了让你有机会检查Academic管理工具产生的改变，你需要备份你的站点，或者确保它已经处于Git的管理之中。\n打开你的终端或者命令提示符应用，安装Academic管理工具：\npip3 install -U academic  使用cd命令进入你的站点目录。\n之后，导入你的出版物：\nacademic import --bibtex \u0026lt;path_to_your/publications.bib\u0026gt;  这个工具尚处于测试阶段，目的是为了给你提供辅助。 所以在发布你的站点之前你应该检查publications文件夹下产生的内容。 你同样可以看看下一章节手动部分有关扉页参数的细节，以想办法增强展示效果。\n想要支持这个工具或者提供建议/反馈，请查看Academic admin tool项目主页。\n手动 另一种选择，使用命令手动的创建出版物：\nhugo new --kind publication publication/\u0026lt;my-publication\u0026gt;  \u0026lt;my-publication\u0026gt;是你得出版物的名称，使用-代替空格。\n之后，编辑content/publication/\u0026lt;my-publication\u0026gt;/index.md内含有你的出版物信息的参数。主要参数如下：\n title: 标题 date: 发布日期 (必须使用有效的TOML日期格式) publication_types: 使用图例来说明你出版物的类型, e.g. conference proceedings publication: 你的出版物发布在什么地方 - 允许使用Markdown以标注斜体或其他. abstract: 摘要  使用Markdown格式将你出版物的细节写到文档的正文部分(在+++部分之后)。 内容会出现在你的出版物页之上。\n要使访客能够阅读到你的作品，将作品的PDF链接填入url_pdf，或者将作品PDF文件放置到出版物目录并统一为相同命名，这样会自动生成PDF的链接。 举例，如果你的出版物说明位于publication/photons/index.md，将PDF文件重命名并放到publication/photons/photons.pdf。\n关联其它资源 使用url_链接以指向本地/网络内容。 要关联本地内容的话将之复制到出版物文件夹并使用例如url_code = \u0026quot;code.zip\u0026quot;的方式添加引用。\n你也可以将下面的代码块添加到扉页，以使用自定义链接按钮：\nurl_custom = [{name = \u0026quot;Custom Link 1\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}, {name = \u0026quot;Custom Link 2\u0026quot;, url = \u0026quot;http://example.org\u0026quot;}]   想要在扉页的参数中使用双引号或者反斜杠需要额外添加一个反斜杠，_例子懒得翻_，更多信息请参阅TOML文档。   创建博文 要创建一篇新文章：\nhugo new --kind post post/my-article-name  然后用你的完整标题和内容填充新生成的content/post/my-article-name.md文件。\nAcademic会自动生成内容摘要并显示在主页上。 如果你不满意自动生成的摘要内容，你可以在文章内容中放置\u0026lt;!--more--\u0026gt;以限定摘要的长度， 或者像这样：\nsummary = \u0026quot;Summary of my post.\u0026quot;  在扉页内添加summary参数以覆盖自动生成的摘要。\n要为特定的文章禁止评论，在扉页添加disable_comments = true参数。 要全局的禁止评论的话，在config.toml中设置disqusShortname = \u0026quot;\u0026quot;或者disable_comments = true。\n创建项目 要创建一个项目：\nhugo new --kind project project/my-project-name  之后编辑新生成的content/project/my-project-name.md文件。 在扉页将external_link = \u0026quot;http://external-project.com\u0026quot;设置成已经存在的项目网址， 或者也可以手动在正文中介绍项目的情况。\n创建演讲 要创建一个演讲：\nhugo new --kind talk talk/my-talk-name  然后用你的完整标题和内容填充新生成的content/talk/my-talk-name.md文件。 你会注意到演讲的很多参数和出版物是类似的。\n创建幻灯片 可以使用Markdown非常高效的创建幻灯片并通过你的网站分享给观众。 甚至还包括演讲者笔记。\n查看slides demo ——尽管你可以注意到这个幻灯片是由Hugo团队制作的，并且他们缩减了一些功能。 运行themes/academic/exampleSite/下的示例站点以查看完整的包含演讲者笔记的示例。\n查看themes/academic/exampleSite/content/slides/example-slides.md内的example slide deck以开始学习。\n在演讲/出版物页面使用url_slides参数来关联到幻灯片。 比如，url_slides = \u0026quot;slides/example-slides\u0026quot;可以关联到上面的示例站点。 在这里可以看到包含url_slides的完整扉页的示例。\n创建课程或文档 文档 是用来分享知识的。常见例子包括在线课程、教程、软件文档以及知识库。\n你现在阅读的这个页面(不是我翻译之后的这个)就是用_文档_的方式来展现Academic相关的。 同样，这里也有一个在线课程的例子。\n查看themes/academic/exampleSite/content/tutorial/的示例以学习如何开始。\n如果你是一名使用R语言的数据分析师/数据科学家(e.g. RStudio and RMarkdown)，我们推荐你阅读R boilerplate project on GitHub。\n创建小部件页面 你是否想利用Academic的小部件系统，创建一个和Academic主页类似的页面？\n在你的content文件夹下创建一个新的，以你的页面命名的文件夹。在这个例子中我们将创建content/tutorials/文件夹以创建我们的tutorials页。\n在新建的content/tutorials/文件夹下创建一个名为_index.md的文件，内容如下：\n+++ title = \u0026quot;Tutorials\u0026quot; # Add a page title. date = 2017-01-01T00:00:00 # Add today's date. widgets = true # Page type is a Widget Page. summary = \u0026quot;\u0026quot; # Add a page description. +++  将你的小部件放入content/tutorials/文件夹，可以通过复制content/home/下的小部件或者从Github上下载来实现。\n创建其他页面(e.g. 简历) 其他类型内容的话，可以创建自己的自定义页面。 例如，我们在content文件夹下创建一个cv.md简历页面。复制任意一个文章的扉页，根据需要进行调整，然后在下面编辑Markdown内容。 再之后，您可以使用[My CV]{{\u0026lt; ref \u0026quot;cv.md\u0026quot; \u0026gt;}}代码将简历添加到任何现有页面的内容上。\n或者，在上面的例子中，我们可以使用简历的PDF文件。为此，在static文件夹中创建名为files的文件夹，并将名为cv.pdf的PDF文件移动到该位置。 然后可以使用以下代码将PDF文件链接到你的任意内容中：{{% staticref \u0026quot;files/cv.pdf\u0026quot; %}}下载我的简历{{% /staticref %}}。\n管理列表页 档案(archive，我理解的就是列表)页或者说节点页，是列出你所有内容的特殊页面。 博客文章、出版物、演讲都会有列表页。 如果存在一个小部件放不下的内容的话，主页上的小部件会自动链接到列表页。 因此，如果你没有足够多的内容的话你可能不会看到自动生成的链接—— 不过你也可以在文章中用一般的Markdown链接格式，手动的链接他们。\n你可以通过将以下_index.md文件从示例站点复制到你的content/文件夹中的相同位置，来编辑标题并添加自己的内容（比如简介）：\n/themes/academic/exampleSite/content/post/_index.md /themes/academic/exampleSite/content/publication/_index.md /themes/academic/exampleSite/content/talk/_index.md  之后，根据需要编辑每个_index.md中的title参数，并在扉页之后添加任何内容。 你可能注意到_index.md文件略有不同，其中一些具有可用于关联内容类型的特殊选项。 例如，publication/_index.md包含用于设置出版物列表页面上显示的列表的引用样式的选项。\n移除内容 通常来说，要移除任意内容，简单的从你的content/post、content/publication、content/project或者content/talk文件夹中删除对应页面文件即可。\n查看站点更新 在你对站点做出修改之后，你可以通过执行hugo server并在浏览器中打开http://localhost:1313/ 来看到效果。\n部署站点 最后，你可以部署你的站点了。\n","date":1546318451,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546318451,"objectID":"e606c1cb482650d4c431e8646f99c1d8","permalink":"https://szthanatos.github.io/post/academic/trans_managing_content/","publishdate":"2019-01-01T12:54:11+08:00","relpermalink":"/post/academic/trans_managing_content/","section":"post","summary":"本文是对Academic文档-Managing content章节的个人翻译，基于个人理解，不保证绝对准确。 原文见上方连接。 目录 HAHAHUGOSHORTCODE-TOC0-HBHB 这是一个使用","tags":["Translation","Academic","Hugo"],"title":"(翻译)Academic文档-内容管理","type":"post"},{"authors":[],"categories":[],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n简介 Tmux是一个终端复用软件，默认的Linux终端一个会话只能干一件事，有了tmux就能在一个窗口同时管理多个前/后台程序了。\n安装tmux 基础软件，跳过\n基础概念 见图\n Session：输入tmux后就创建了一个会话，一个会话是一组窗体的集合； Window：会话中一个可见的窗口； Pane: 一个窗口可以分成多个窗格；  用win10任务视图(Win+Tab调出)的概念来类比，\nPane就是一个个应用窗口，在一个桌面上可以同时开多个(但是不能堆叠，)；\nWindow就是一组组桌面，同一时间你只能看到一个桌面\nSession就是一个用户，区别就是win10同一个账户只能登陆一次，tmux里相当于一个用户登陆N次。\n为了控制这些元素，tmux分为三种模式：\n 控制模式: （按下或者按住前缀(tmux-prefix)，默认ctrl+b, 下文用※ + X表示按下前缀之后按X，※※ + Y表示按住前缀的同时按Y）相当于各种热键； 命令模式: （输入tmux 后接命令，或者在tmux内输入※ + shift + :）也就是输入命令，但是执行的不是系统命令，而是tmux自身的命令； 一般模式: 正常打字；  配置 和zsh一样，得先配置才能用的舒坦。下面是我个人用的配置文件。\nCtrl+b被我替换为Ctrl+x，横竖分割窗格我分别设置为-和\\，刚好一横一竖嘛，并且启用了tpm管理tmux插件。\n#-- base --# # (可选)设置zsh为默认shell set -g default-shell /bin/zsh #-- settings --# set -g mouse on # 开启鼠标切换窗格，按住shift复制粘贴 set -g base-index 1 # 窗口编号从 1 开始计数 set -g renumber-windows on # 关掉某个窗口后，编号重排 set -g pane-base-index 1 # 窗格编号从 1 开始计数 set -g display-panes-time 5000 # PREFIX-Q 显示编号的驻留时长，单位 ms setw -g mode-keys vi # 进入复制模式的时候使用 vi 键位（默认是 EMACS） setw -g allow-rename off # 禁止活动进程修改窗口名 setw -g automatic-rename off # 禁止自动命名新窗口 set -g default-terminal \u0026quot;tmux-256color\u0026quot; # 开启256 colors支持 #-- bindkeys --# # 以下3行设置ctrl+x代替ctrl+b的快捷键 set -g prefix C-x unbind C-b bind C-x send-prefix # 设置tmux-prefix + \\垂直分割窗格 unbind % bind \\ split-window -h # 设置tmux-prefix + -水平分割窗格 unbind '\u0026quot;' bind - split-window -v # 设置ctrl+vim方式切换窗格 bind -n C-h select-pane -L bind -n C-j select-pane -D bind -n C-k select-pane -U bind -n C-l select-pane -R # plugins # tmux plugin manager 插件管理 set -g @plugin 'tmux-plugins/tpm' set -g @plugin 'tmux-plugins/tmux-sensible' # 保存布局插件，tmux-prefix + ctrl+s/tmux-prefix + ctrl+r保存/恢复 set -g @plugin 'tmux-plugins/tmux-resurrect' # 自动保存插件 set -g @plugin 'tmux-plugins/tmux-continuum' # tmux-resurrect配置 # 恢复shell的历史记录,只有无前台任务运行的窗格 才能被保存 set -g @resurrect-save-bash-history 'on' # 恢复窗格内容,目前使用该功能时，请确保tmux的default-command没有包含\u0026amp;\u0026amp; 或者||操作符， # 否则将导致bug。（查看default-command的值，请使用命令tmux show -g default-command。） set -g @resurrect-capture-pane-contents 'on' # 恢复vim会话 set -g @resurrect-strategy-vim 'session' # set -g @resurrect-save 'S' # set -g @resurrect-restore 'R' # tmux-continuum配置 # 开启自动恢复 set -g @continuum-restore 'on' # 设置备份间隔（分钟，0为不自动备份） set -g @continuum-save-interval '240' # 状态栏查看备份状态 # Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf) set -g status-right 'Continuum status: #{continuum_status}' run '/etc/.tmux/plugins/tpm/tpm'  具体配置步骤如下：\n 编辑.tmux.conf文件放到你的根目录下； 使用git clone https://github.com/tmux-plugins/tpm /etc/.tmux/plugins/tpm将tpm安装到etc目录下 (或者随你喜欢，我是个人和root共用一套配置，所以放个公共的地)； 输入tmux source-file ~/.tmux.conf载入配置； 进入tmux，输入※ + U查看tpm插件更新，弹出页面默认打开命令模式，直接输入all完成更新；  常用控制  注意，下列所有快捷键区分大小写。   会话    按键 说明     ※ + d 休眠   ※ + s 以菜单方式显示和选择会话   ※ + L 切换回上一次的会话    窗口    按键 说明     ※ + c 创建新窗口   ※ + n 选择下一个窗口   ※ + p 选择前一个窗口   ※ + l 最近一次活跃窗口之间进行切换   ※ + 0~9 选择几号窗口   ※ + , 重命名窗口   ※ + . 更改窗口的编号，但只能更改成未使用的编号，所以要交换窗口的话，得多次更改进行交换   ※ + \u0026amp; 关闭窗口   ※ + w 以菜单方式显示及选择窗口   ※ + f 在所有窗口中查找内容    窗格    按键 说明     ※ + z 最大化/还原当前窗格   ※ + \u0026ldquo; 模向分隔窗格，替换为了-   ※ + % 纵向分隔窗格，替换为了\\   ※ + o 跳到下一个分隔窗格   ※ + x 关闭窗格   ※ + ; 切换到最后一个使用的窗格   ※ + ↑/↓/←/→ 切换到上/下/左/右的窗格   ※※ + h/j/k/l 自定义配置，vim方式切换窗格   ※ + q 显示窗格编号，并在右上角显示窗格的长宽   ※ + 空格键 自动排布窗格，可多次执行尝试多种布局    tpm插件    按键 说明     ※ + S 自定义配置，保存当前布局   ※ + R 自定义配置，还原保存的布局    鼠标操作 鼠标按住窗格的分割线可以修改窗格大小；\n如果你用wsltty或者其他软件，发现右键/中键失效，记得按住修饰键(比如Shift)再试。\n","date":1546316825,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546316825,"objectID":"3da3e4593fc1e22e7ffd06cafeaba9bd","permalink":"https://szthanatos.github.io/post/tmux/","publishdate":"2019-01-01T12:27:05+08:00","relpermalink":"/post/tmux/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 简介 Tmux是一个终端复用软件，默认的Linux终端一个会话只能干一件事，有了tmux就能在一个窗口同时管理多个前/后台程序了。 安装t","tags":["Tmux"],"title":"Tmux in 10 minutes","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546300800,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://szthanatos.github.io/about/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"real me","tags":null,"title":"about","type":"widget_page"},{"authors":[],"categories":[],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\nDeploy key/SSH key(github) Deploy key是在项目主页-setting-Delpoy keys下进行添加，如果勾选Allow write access，则相当于具有对这个项目的读写权限(否则只能clone不能push)。作用范围是这个项目。\nSSH key是在你个人主页-Settings-SSH and GPG keys下进行添加。作用范围是你的账户下的所有项目。\n同一个公钥，只能作为整个账户的SSH key，或者一个项目的Deploy key。想为一台机器授予多个项目的读写权限的话，需要通过ssh-keygen生成多个密钥，分别作为不同项目的Deploy key。\n更换git协议 使用http/https协议连接仓库相比ssh即不够安全，也会存在push的时候必须输入用户名密码的问题。\n使用git remote -v可以查看项目使用的协议。\n如果是新建的项目，推荐在一开始就使用git@github.com:{USER}/{PROJECT}.git进行clone。这样默认都是用ssh了。\n如果是已有项目，使用git remote set-url {repository} {url}更改。\n$ git remote -v origin https://github.com/abc/bcd.git (fetch) origin https://github.com/abc/bcd.git (push) $ git remote set-url origin git@github.com:abc/bcd.git $ git remote -v origin git@github.com:abc/bcd.git (fetch) origin git@github.com:abc/bcd.git (push)  强制覆盖本地文件 啥都别说了，直接重来吧：\ngit fetch --all git reset --hard origin/master  撤销修改 add之前撤销 # 单个文件 git checkout FileName # 所有文件 git checkout .  commit之前撤销 # 取消暂存 git reset HEAD FileName # 撤销修改 git checkout FileName  push之前撤销 git reset [--hard|soft|mixed] [commit|HEAD]  删除历史提交记录 commit多了项目也会膨胀\u0026hellip;清了一干二净。\n# 用orphan参数创建全新的分支 git checkout --orphan {new_branch} # 添加所有文件 git add -A # 提交 git commit -am \u0026quot;commit message\u0026quot; # 删除原始分支 git branch -D {old_branch} # 交换分支 git branch -m {old_branch} # 强制提交变更 git push -f origin {old_branch}  忽略文件权限 文件在系统间转移的时候可能由于权限改变而使文件全都处于\u0026rdquo;modified\u0026rdquo;状态。（比如从linux到Windows，权限会从644变成755）可以以项目为单位设置忽略文件权限：\ngit config core.filemode false  ","date":1544751332,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544751332,"objectID":"41ca8042ced159c6adfa318d52fa28c9","permalink":"https://szthanatos.github.io/post/git/git_tips/","publishdate":"2018-12-14T09:35:32+08:00","relpermalink":"/post/git/git_tips/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB Deploy key/SSH key(github) Deploy key是在项目主页-setting-Delpoy keys下进行添加，如果勾选Allow write access，则相当于具有对这个项目的","tags":["Git"],"title":"Git Tips","type":"post"},{"authors":[],"categories":[],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\nHugo 安装/更新 Hugo是使用Go语言开发的静态站点生成器。不过无需准备Go语言环境，可以直接通过二进制编译包进行跨平台部署。\n以下均以Ubuntu18.0为例。\n安装/更新  前往Github页面下载最新版本，这里我们下载hugo_0.52_Linux-64bit.deb; 使用命令dpkg -i hugo_0.52_Linux-64bit.deb 安装hugo; 更新即重复上面两步，覆盖安装即可;  常用命令  hugo： 编译项目生成静态网站，默认位置在项目的public目录下 hugo server： 启动你的网站服务，可以通过浏览器访问http://127.0.0.1:1313/访问站点; hugo new {folder}/{name}.md: 创建新文章，使用markdown进行排版，一般默认放在post文件夹下；  基本没了，一般情况下用这三个命令就够了。\nAcademic 安装/更新 Academic是一个Hugo主题，从名字就可以知道这个主题比较学院派，适合科研/学术人员发布个人信息/介绍科研项目，当然，拿来做个人博客也是没问题的。\n通过Netlify Academic推荐使用第三方博客管理平台Netlify安装，如果你没有域名或者没想建站，只是想自己使用，那我建议不使用它的服务——请直接跳到下一部分，否则跟随网站引导完成安装;\n通过Git 安装  通过git安装的话，首先建议你在GitHub上fork成你自己的项目，默认的话，通过git clone https://github.com/sourcethemes/academic-kickstart.git My_Website将代码克隆到本地文件夹My_Website (当然，更推荐使用ssh协议，更安全，也免于push时输入密码，这里暂时按官方的来) ; 进入文件夹，初始化项目：git submodule update --init --recursive，完成安装;  自动更新 说是自动，还是需要手动执行一条命令：git submodule update --remote --merge;\n这么做的前提条件是你是install的，也就是git submodule update --init --recursive过的，而不是直接把academic给clone到themes文件夹。\n手动更新 如果是clone到themes文件夹的话要这么更新：\n cd themes/academic; 将origin仓库重命名为upstream：git remote rename origin upstream; 将更新下载到本地：git fetch upstream; 列出可用更新：git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master; 更新：git pull upstream;  部署到Github Pages 原理 网上介绍的办法很多，但核心其实就一句：\n将hugo命令生成的public文件夹上传到GitHub pages项目下。\npublic文件夹相当于编译完成的静态网站，你在本地打开其实就能看。换句话说，你每次手动将这个目录下的内容上传到你的GitHub page项目也是可以的。\n然后为了达到这个目的，Academic给出的做法是利用git submodule将你的GitHub page项目作为My_Website项目的子模块存放到public目录。那么当你更新你的文章之后，只提交public文件夹内的变更到GitHub page项目即可。\n官方教程(缩减版) 原教程看这里；\n 在GitHub上创建两个项目，一个是fork 的academic-kickstart，也就是你前面clone到本地的My_Website，另一个即是以你用户名/组织名开头、以.github.io结尾的GitHub page项目。 在My_Website目录下执行git submodule update --init --recursive将子模块更新到最新状态； 将config.toml中的baseurl设置为你的GitHub page地址； (实质) 删除public文件夹(如果有的话)，将GitHub page项目添加为子模块：git submodule add -f -b master https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git public;\n 这时候你的My_Website项目实际上有两个子模块：作为主题依赖的themes/academic和作为网站的\u0026lt;USERNAME\u0026gt;.github.io；\n有意思的是一般是子模块themes/academic更新了之后，你更新主项目My_Website的依赖；\n而你更新主项目My_Website的文章之后，再会手动的更新子模块\u0026lt;USERNAME\u0026gt;.github.io，刚好反过来。\n 新增/编辑文章后，更新academic-kickstart项目：\ngit add . git commit -m \u0026quot;Initial commit\u0026quot; git push -u origin master  更新GitHub page项目：\nhugo cd public git add . git commit -m \u0026quot;Build website\u0026quot; git push origin master   实际上只有第六步是更新GitHub page，每次重复执行这一部分就行(如果你不把文章保存到academic-kickstart的话)。\n脚本 Hugo官方把上面步骤打包到了一个脚本：\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [ $# -eq 1 ] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd ..  实际上我们干脆连第五步也放进去呗：\n#!/bin/bash # Receive args. if [ $1 = \u0026quot;push\u0026quot; ]; then if [ $# -eq 1 ]; then TIME_NOW=$(date +%T\\ %F) MSG=\u0026quot;Change something nobody knows at ${TIME_NOW}...\u0026quot; EDITED_FILE=\u0026quot;.\u0026quot; elif [ $# -eq 2 ]; then MSG=\u0026quot;$2\u0026quot; EDITED_FILE=\u0026quot;.\u0026quot; elif [ $# -gt 2 ]; then MSG=\u0026quot;$2\u0026quot; shift 2 EDITED_FILE=\u0026quot;$*\u0026quot; else echo \u0026quot;WTF?\u0026quot; fi echo \u0026quot;\\033[0;32m --------------------------- Deploying to GitHub Page... --------------------------- \\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026quot;$MSG\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd .. echo \u0026quot;\\033[0;32m ----------------------------- Updating content to GitHub... ----------------------------- \\033[0m\u0026quot; # Add changes to git. git add $EDITED_FILE # Commit changes. git commit -m \u0026quot;$MSG\u0026quot; # Push source and build repos. git push origin master elif [ $1 = \u0026quot;pull\u0026quot; ]; then # Update main repo. git pull # Update submodule. git submodule update echo \u0026quot;Synchronize finish.\u0026quot; else echo \u0026quot;Determine What you wanna do.\u0026quot; fi  将脚本保存为deploy.sh，放到项目根目录下，完成修改后执行./deploy.sh + pull/push一键从服务器同步/提交+部署。\n参数的第一个是你要执行的动作，从远程服务器down到本地的话就是./deploy.sh pull，不用接别的。\n如果是要将更新上传到服务器并部署，那就执行./deploy.sh push + commit message，提交消息可以不写(但最好还是写一下)：\n./deploy.sh push \u0026quot;{Your optional commit message}\u0026quot;。\n如果修改了多个文件，只想提交其中的一部分文件以保持commit的纯净，那就在mesaage后面附加你要提交的文件路径(不超过10个\u0026hellip;)：\n./deploy.sh push \u0026quot;{Your optional commit message}\u0026quot; path1 path2...。\n个性化配置 项目目录结构大体如下：\n content目录： 网站内容，home是你的主页的小控件，post是默认文章存放位置 public目录： 生成的静态页面 resouces目录： JS资源存放位置 static目录： 静态资源存放位置 themes目录： 主题文件所在目录 config.toml: 全局配置文件  config.toml主要配置项解释    配置项 说明     baseurl 你的站点的url，不设置这个你的文章/资源可能相互引用不到   title 网站标题   defaultContentLanguage 默认语言，中文的话填zh，在文件末尾还有一处配置要同时修改才行   hasCJKLanguage 是否有中/日/韩语   defaultContentLanguageInSubdir 目录是否允许用默认语言，true就对了   highlight_languages 语法高亮，支持的语言可以去highlight.js查到   [[menu.main]] 这部分是你主页上标题栏显示的内容，url默认和你content/home下的文件名对应   Languages 添加中文支持的话，把[languages.zh]部分解除注释，languageCode写\u0026quot;zh-cn\u0026quot;，添加其他语种的话，相同格式再写一组[languages.XX]即可，支持的语言代码可以在themes\\academic\\i18n查看    修改网站logo 默认的logo是Academic的蓝色学位帽，想替换的话将你想用的logo保存为 icon.png(默认32*32像素，大了也没关系) 和icon-192.png(192*192像素)，并放到项目的static/img目录下\n给文章添加精选图 这个图片只能添加一个，名字必须是featured.*(后缀jpg/png都行)，而且必须和文章放在同一个文件夹下。\n所以一般做法是把文章aaa.md改名为index.md并新建一个aaa目录，再和featured.png图片一起扔进去。\n显示的效果是在文章列表页，文章右侧有一个缩略图；打开文章，标题默认会居左，右边是精选图：\n给文章添加头部背景 这个是文章头部的横跨整个页面的大图，也就是文章头部这个黑底白字的大图。\n这个的图片可以放到static/img目录下，不过需要在你文件的+++的部分添加如下代码：\n[header] image = \u0026quot;img名称\u0026quot; caption = \u0026quot;标题说明\u0026quot;  顺便一提，文章内引用static/img下存储的图像的话，路径大致如此![example](/img/image_abc.png)\n目录 使用{{% toc %}}加在文章的任何你想要的地方以自动生成目录\n注意/警告标识 被{{% alert note %}}和{{% /alert %}}包裹起来的内容即为注意项：\n 注意内容blabla   被{{% alert warning %}}和{{% /alert %}}包裹起来的内容即为警告项：\n 警告内容blabla   消除短代码效果 Hugo是基于Go的Template，所以所有以{{% %}}或者{{\u0026lt; \u0026gt;}}包裹的内容都会被解析为短代码块，而无法直接显示其代码。 那么我是怎么解决的呢，分情况：\n单行代码 你看到的{{% toc %}}实际是由`{`和`{% toc %}}`组成的。\n而上面打出的`其实是双反引号 空格 反引号 空格 双反引号，就不再嵌套了。。。\n代码块 {{\u0026lt; figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; \u0026gt;}}  的本质是将\u0026lt;\u0026gt;或者%%内的内容用/**/注释掉：\n{{\u0026lt;/* figure library=\u0026quot;1\u0026quot; src=\u0026quot;image.jpg\u0026quot; title=\u0026quot;A caption\u0026quot; */\u0026gt;}}\n 谁知道Markdown的代码块怎么嵌套\u0026hellip; 比如外层一个markdown的代码块， 里面要显示包含反引号格式的python代码块\u0026hellip;   修改模板 比如你看到我每个文章结尾都有一个CC4.0协议的标志，这个肯定不是一篇篇手动添加的，实际上我是自己写了一个License的Widget，插入到文章的模板里面实现的。\n 不要直接修改theme里面的内容，否则更新主题的时候会非常尴尬。   正确的做法是在项目根目录建立layouts文件夹，将你想修改的模板从themes/academic/layouts拷贝过来再修改。\n现在Academic主题的layouts大概是这样的：\n _default: 默认文章相关模板； docs: 文档相关模板; home: 主页相关模板; partials: 小部件相关模板，页面头部/脚注/摘要等等的都在这;  额外的有一个widgets文件夹，里面是主页的widget的模板；  project: 项目相关模板; publication: 出版物相关模板; section: 摘要相关模板; shortcodes: Academic提供的额外效果模板，你写的所有{{%%}}的内容效果都出自这里; slides: 幻灯片相关模板; talk: 宣讲相关模板;  继续用我自己做例子，我新建了layouts/partials/license.html，把CC协议相关内容存了进去， 接着，复制主题目录下的layouts/_default/single.html到对应位置，在合适地方插入一句{{ partial \u0026quot;license.html\u0026quot; . }}，表明我要在这里使用名为license.html的partial。 再之后就是你们看到的效果了。\n","date":1544344482,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544344482,"objectID":"698f7fbd0cc48ca529327ed5a4c640db","permalink":"https://szthanatos.github.io/post/academic/academic_in_practice/","publishdate":"2018-12-09T16:34:42+08:00","relpermalink":"/post/academic/academic_in_practice/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB Hugo 安装/更新 Hugo是使用Go语言开发的静态站点生成器。不过无需准备Go语言环境，可以直接通过二进制编译包进行跨平台部署。 以下均以Ub","tags":["Hugo"],"title":"Academic实现Github Page个人博客","type":"post"},{"authors":[],"categories":["DataBase"],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n简介 本指南是对在HBase进行字段设计而提供的指导性准则和建议。总体标准、设计方式参照Google 开源项目风格指南以及现有项目经验。所有条目均为个人总结，并不是一份官方标准性质的指南 。\nHBase是建立在Hadoop文件系统（HDFS）之上的分布式、面向列的数据库。\n一般原则  无论是表或者是列或者其他，都应该使用名词或者动宾短语以代表一类对象; 尽量避免使用(尤其是单独使用)例如int、join、select等常见保留词; HBase在性能和效率上更擅长处理“高而瘦”的表，而非“矮而胖”的表——以Excel类比，HBase应该尽可能设计成只有很少的列(瘦)而有非常多行(高)的模式;  命名空间(NameSpace) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 不建议用连接符（下划线）拼接多个单词，简单语义的可采用单个单词，复杂语义的可采用多个单词的首字母拼接; 长度尽量限制在4~8字符之间; 命名空间一般可与项目名称、组织机构名称等保持一致; 一般情况下如果不指定命名空间，表会被放在默认(default)命名空间下;  示例 ZKR XJ917  表(Table) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须大写，并且首字符必须为英文字符，可用连接符拼接多个单词; 长度尽量限制在8~16字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合; 无需以TABLE结尾;  示例 USER_INFO WEIBO_USER_FANS  行键(Rowkey) 命名规范  采用英文单词、阿拉伯数字、非转义字符组合形式，不要求大小写，但首字符必须是英文字符或数字;  示例 123456-654321 dftf3a3l3rv3qr s.taobo.com/faefavc  注意 慎重将时间戳直接放入行键中 对于同一条数据，HBase本身提供时间戳(TimeStamp)以在同一个RowKey下保存不同版本数据; 对于整体，存放旧数据的区域随着时间戳增大可能不再写入，而存放新数据的区域始终保持高负荷，这样降低了HBase整体的读写能力。\n一个推荐的方式是使用反向时间戳。\n权衡hash和string的效果 哈希化(一般特指单项哈希)的Rowkey能很好的避免热点问题，但是也会同时丢失直接使用String的RowKey的天然聚类和排序的能力。\n列族(ColumnFamily) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 长度尽量限制在1~6字符之间，过长的列族名称将占用更多的存储空间,它们不应该像在典型的 RDBMS 中一样具有自我记录和描述性;  示例 DATA D1 # data1 WA # web args  注意 列族的数量应控制在1-3个 HBase 表不应该被设计成模拟RDBMS表，列族的数量在满足需求的情况下应该尽可能少。在存储时，一个列族会存储成一个StoreFile，多个列族对应的多个文件在分裂时会对服务器造成更大的压力。\n列(Qualifier) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须小写，并且首字符必须为英文字符，不能是数字，可用连接符拼接多个单词; 所有列名都应该是名词或者以is开头的动宾短语(表示判断)，不应该使用其他词性单词; 允许使用前缀，不允许使用后缀; 长度尽量限制在1~16字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合;  示例 user_name is_str sound_type  ","date":1544343567,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544343567,"objectID":"bcc2384e562b7caba94eeba86a28363e","permalink":"https://szthanatos.github.io/post/hbase_design/","publishdate":"2018-12-09T16:19:27+08:00","relpermalink":"/post/hbase_design/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 简介 本指南是对在HBase进行字段设计而提供的指导性准则和建议。总体标准、设计方式参照Google 开源项目风格指南以及现有项目经验。所","tags":["HBase"],"title":"hbase表设计风格指南","type":"post"},{"authors":[],"categories":[],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n简介 Palantir是全球第一大大数据公司。曾经的全球四大独角兽之一（其它三家是Uber，Airbnb和小米）。中文名帕兰提尔，源于《指环王》中邪恶巫师萨鲁曼使用的可穿越时空、洞悉世间一切的水晶球(Palantiri)。主要客户为政府机构和金融机构。\n最出名的案例是以大数据技术帮助美国军方成功定位和击毙基地组织首脑本·拉登，以及协助多家银行追回了纳斯达克前主席麦道夫Bernie Madoff的庞氏骗局中所隐藏起来的数十亿美元巨款。\n最新情况  2018年10月29日，Palantir正在建立ICE的案例管理软件 —— AL DIA News\n 2018年10月23日，亚马逊、微软、Palantir等科技公司在特朗普的移民法案中起到重要作用 —— Common Dreams\n 2018年10月19日，Palantir或明年上市，估值达410亿美元 —— MAYA KOSOFF\n 2018年09月14日，美国陆军决议中止对Palantir2.06亿美元的采购合同 —— LAW 360\n 2018年03月14日，雷神、Palantir 拿下美国陆军8.76亿美元合同 —— reuters\n 2018年03月02日，传Palantir在新奥尔良秘密测试犯罪预测技术，最神秘的独角兽再陷隐私风波 —— 猎云网\n Palantir发布2017年度报告 重点提到在哈维飓风的救援以及灾后重建工作，以及帮助世界粮食计划署运输食品以对抗饥饿的工作中所起到的作用。\n  创始人 Peter Thiel 斯坦福本科及法学院JD的高材生，《从0到1》的作者。创立了Clarium Capital、Founders Fund、Valar Ventures、、Mithril Capital Management等多支基金。Paypal创始人之一并出任 CEO。2002年paypal被收购之后，以投资人身份投资包括Facebook、Asana、Quora、LinkedIn、Yelp、Yammer在内的诸多当今一线公司。号称硅谷创投教父。\nAlex Karp (CEO) 哈佛本科毕业，斯坦福法学JD学位，德国法兰克福大学新古典社会理论方向博士学位，师从本世纪最伟大的哲学家之一哈贝马斯。早年继承家产后成为硅谷著名投资人，并在伦敦创立Caedmon Group基金管理投资。目前坚持保持单身，热爱气功、游泳以及与员工讲马克思还有带领员工在硅谷打太极。Peter Thiel在斯坦福的室友。\nJoe Lonsdale 斯坦福计算机系毕业。除Palantir外，还曾创办另外两家高科技公司，和硅谷最大的面向亚洲的风投基金Formation8、 8vc。管理着5000亿美元财富。此外，还是《福布斯》评选出的12位行业未来之星之一，还被美国媒体评为硅谷排名第二的天使投资人。\nStephen Cohen 毕业于斯坦福计算机系的高级工程师。\nNathan Gettings 来自于PayPal的的高级工程师。在PayPal负责风险和研发的总监，曾以开发了反欺诈的系统而闻名于世。\n发展历程  2004年Palantir公司创立于加利福尼亚州帕洛阿尔托。创业初期Palantir并不被人看好，融资过程也是屡屡受阻，包括红杉资本，凯鹏华盈两大VC基金都不看好Palantir的发展。经过多次奔走博弈，最终，Palantir赢得了CIA的创投基金的2轮投资，从而走上了发展的正轨。 2004到2009年，Palantir主要业务还是服务于美国政府部门，提供情报分析，防欺诈、反恐等服务。 2010年，Palantir开始提供企业服务，实现业务多元化。 2010年7月，当时已经拥有250位工程师的Palantir完成9000万美元的D轮融资，估值达到7.35亿美元。 2011年5月6日，融资5000万美元，累计融资额达到了1.75亿美元。 2011年10月7日，融资7000万美元，估值25亿美元。 2013年9月29日，融资1.96亿美元，估值60亿美元。 2013年12月，Palantir新一轮融资1.075亿美元，同时估值达到90亿美元。此时Palantir的年收入已经超过4.5亿美元。 2014年11月，Palantir再拿到5亿美元投资，企业用户突破14000家，估值达到了150亿美元。 2015年年底，Palantir获得8.8亿美元的融资，市值达到200亿美元。成为继 Uber、小米、Airbnb 之后，全球估值第四高的创业公司。（截至2018年11月最后一笔融资） 2016年2月，收购Kimono Labs 2016年5月，Buzzfeed爆料,数司百名员工离职，多个重要客户不再续约。 2016年8月，Palantir收购数据可视化公司Silk。 2018年10月，Palantir预备明年下半年上市，公司估值或将达410亿美元   产品内容 官方主页： Home | Palantir 产品线 目前Palantir仅保留两条产品线：\n Palantir Gotham 一个集成，管理，保护和分析多来源的企业数据的复合平台。命名来源于蝙蝠侠所在的哥谭市。作为后端，Gotham平台可用于集成许多不同的数据源，以进行安全的协作分析；也可以存储企业的各类建模分析数据，充当企业知识库。而在前端, Gotham平台提供了一套针对语义，时间，地理空间和全文分析的分析工具集合。为Gotham提供支撑的子产品包括：\n PHOENIX 支持PB级的数万亿条记录进行亚秒级查询的集群数据库； RAPTOR 提供对外部数据源进行联合查询,并实时加入数据库的检索工具； SEARCH 提供对系统中结构化和非结构化数据的全文检索的搜索引擎； HORIZON 允许用户在数十亿个对象中查询并在约10秒内收到结果的,类Spark设计的内存数据库； DYNAMIC ONTOLOGY 高度灵活和动态的数据建模工具； REVISIONING DATABASE RevDB是Gotham平台的持久化数据管理工具，类似Zookeeper之于Hadoop； ATLASDB 作为RevDB的具体数据存储单元，结合了NoSQL数据存储的简单性和可扩展性与传统SQL数据库的事务安全性和一致性； NEXUS PEERING 分布式系统平台，上面的各个组件都建立在这个平台之上；  Palantir Foundry ：数据集成/分析平台，将后端的数据存储和前端的数据分析打通，让任何人都能连接到不同数据源轻松进行建模分析。\n  解决方案 Palantir面向以下领域直接提供解决方案：\n 汽车制造业 网络安全 金融合规 企业内部信息安全 商业情报分析 法律诉讼 并购支持 收入最大化 数据组织 国土防卫 欧盟通用数据保护监管 保险分析 公共执法 制造业 医药研发 航空业  ","date":1544000961,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544000961,"objectID":"3a0a3ff6504fdcc30a1757e8d02e8c1f","permalink":"https://szthanatos.github.io/post/palantir_intro/","publishdate":"2018-12-05T17:09:21+08:00","relpermalink":"/post/palantir_intro/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 简介 Palantir是全球第一大大数据公司。曾经的全球四大独角兽之一（其它三家是Uber，Airbnb和小米）。中文名帕兰提尔，源于《","tags":[],"title":"Palantir一分钟印象","type":"post"},{"authors":[],"categories":["Python"],"content":" 添加ppa源：\n# 死蛇的源 sudo add-apt-repository ppa:deadsnakes/ppa # 或者，jonathonf的源 sudo add-apt-repository ppa:jonathonf/python-3.x  如果提示没有add-apt-repository的话执行：\napt install software-properties-common  更新源并安装python3.x，3.x以你要安装的版本号为准：\nsudo apt update sudo apt install python3.x # 可选 sudo apt install python3.x-dev sudo apt install python3.x-venv  安装pip:\nwget https://bootstrap.pypa.io/get-pip.py sudo python3.x get-pip.py  查看python和pip版本：\n# 也可以用-V python --version python3 --version pip --version pip3 --version  如果关联版本不正确，备份usr/bin的软链接，重建软链接：\n# 设置默认python3对应python版本 sudo ln -s /usr/bin/python3.x /usr/bin/python3 # 设置默认pip3使用pip版本 sudo ln -s /usr/local/bin/pip3.x /usr/bin/pip3  注意 python默认安装位置在/usr/bin下，pip默认安装位置在/usr/local/bin下\n pip初始化设置：\nmkdir ~/.pip touch ~/.pip/pip.conf # python3.6/pip18之后无需配置这个 echo [list]\u0026gt;\u0026gt;~/.pip/pip.conf echo format=columns\u0026gt;\u0026gt;~/.pip/pip.conf # 设置默认pip源为清华大学开源镜像 echo [global]\u0026gt;\u0026gt;~/.pip/pip.conf echo index-url = https://pypi.tuna.tsinghua.edu.cn/simple\u0026gt;\u0026gt;~/.pip/pip.conf  (可选)一键升级所有过期的包：\nsudo pip freeze --local | grep -v '^\\-e' | cut -d = -f 1 | xargs pip install -U   ","date":1543651144,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543651144,"objectID":"c5010c0959e1966312b2fb992ff8040e","permalink":"https://szthanatos.github.io/post/python/python_install_on_ubuntu/","publishdate":"2018-12-01T15:59:04+08:00","relpermalink":"/post/python/python_install_on_ubuntu/","section":"post","summary":"添加ppa源： # 死蛇的源 sudo add-apt-repository ppa:deadsnakes/ppa # 或者，jonathonf的源 sudo add-apt-repository ppa:jonathonf/python-3.x 如果提示没有add-apt-repository的话执行： apt install software-properties-common 更新源并安","tags":["Ubuntu"],"title":"Ubuntu安装最新版本Python","type":"post"},{"authors":[],"categories":[],"content":" 这是我第四次，也可能是我最后一次博客迁移(flag已立←_←)。\n从大学时代开始，找个地方写点什么的蠢动心思就没消停过，但是也都消磨在了无关文字的地方。有一个Geek圈子的说法，yak-shaving，剪牦牛毛，放我身上非常合适——本来只是想写点什么，却发现不知道写哪好，就开始研究市面上的博客服务，又发现都不太好用不如自己搭，又开始研究自建网站，自建网站的过程中又发现自己需要一个服务器，又开始折腾主机\u0026hellip;折腾个人域名\u0026hellip;折腾Linux\u0026hellip;折腾LAMP环境\u0026hellip;——总之折腾到最后，走马观花的东西很多，写出来的东西寥寥无几。\nyak-shaving的得失不提，到了现在的这个阶段，折腾的心思已经熄了很多，但是已经写出来的东西零零散散还是会难以忍受。也有一部分内容已经过时，或者回头再看理解已经完全不同\u0026hellip;总而言之，借此机会，旧的内容安置妥当，咱们就此别过。未来的文章，短时间内也无虞搬迁之苦，踏踏实实的呆在实验室档案柜吧。\n以后笔记只分两部分存储：未经整理的内容继续保存在OneNote里，相对完整的东西再放到这里来。\n旧的博客文章大概200篇不到，但是想到要挨个过一遍还得翻新到Hugo的模板\u0026hellip;..就感觉\u0026hellip;\u0026hellip;啊，还是鸽了吧\u0026hellip;\u0026hellip;（不过自己立的flag哭着也要做完的）\n说回个人博客。\n上一个博客的灵感是万智牌（和长者），为自己设定的身份是掌握了东方神秘膜法的旅法师\u0026hellip;所以取名叫做\u0026rdquo;黑膜法师营地\u0026rdquo;，不过旅法师对决之后也已经好久没玩了。\n至于现在博客的设定，起源于最近重温守望者。看到罗夏(罗夏帅爆!)就想到老爷，看到笑匠就想到小丑(罗夏：致命玩笑←_←)，看到法老王\u0026hellip;唔\u0026hellip;蝙蝠侠对抗的智商爆表而且精神正常的反派\u0026hellip;阿卡姆疯人院:\u0026ldquo;外面的都是神经病啊，不要放进来！\u0026rdquo;。\n脑洞扩展到DCEU，嗯，超人，嗯，卢瑟，嗯，巴别塔\u0026hellip;老爷不会只靠定情小氪石的，一定有后备方案，嗯，Lex Wayne，就这么定了。\n顺理成章，细节设定就是严肃的考(wan)证(geng)啦。\nKryptonite Lab 氪石实验室，没什么好说的，名字都是Lex Wayne了肯定患有氪石狂热啦(雾！)，什么住在全是氪石的实验室啦，爱嚼氪石口香糖啦，肯定都是基本设定啦(大雾！)。\n42这个倒和DCEU没关——《银河系漫游指南》里宇宙的终极答案啊！十六进制的ASCII码 *，'theAnswertoLifetheUniverseandEverythingis'问题本身的长度，感觉没有更赞的了1。已经想好了，如果以后完善Lab的设定，里面的超算肯定叫深思(Deep Thought)。\nWayne Manor B3, 1007 Mountain Drive, Gotham, NJ 12345, USA 一段一段说，\nWayne Manor B3 地下三层取自这个蝙蝠洞的设计图：放大可以看到地下从上往下数分别是\n -1 Main Level -2 Additional Hangar Aeras -3 Sub Level 1 \u0026hellip;   Sub Level 1放的就是Labs/Workshops/Library。\n1007 Mountain Drive, Gotham 韦恩庄园所在的1007 Mountain Drive这个地址来源于92-95年的蝙蝠侠动画Batman: The Animated Series第一季中的The Demon's Quest故事，应该也是目前蝙蝠侠相关作品中唯一正面出现的庄园地址。\n具体坐落在哥谭的什么位置可以参考1999年Eliot R. Brown制作的地图：而更新一点的设定可以参考诺兰的黑暗骑士的周边《黑暗骑士手册》：总之，都在右上角啦←_←。\nNJ 12345, USA NJ是新泽西的缩写，虽然哥谭给人的印象就是纽约（早于黑暗骑士的电影给人的感觉可能更像芝加哥），但新泽西的设定可以追溯到1974年的DC漫画惊奇世界(详见维基)，NJ 12345也是出自93年的Batman: Shadow of the Bat里的那个驾驶证：72 Faxcol Dr Gotham City, NJ 12345。\n其他彩蛋 其他的设定零零碎碎的，以后也会往里面填充更多内容啦。\nStar War 比如我个人介绍的Python Knight \u0026amp; Go Padawan，这里的Knight显然和黑暗骑士什么的无关——Jedi！星战好像已经是老年人爱好了\u0026hellip;但当年真的迷过一段时间，桌面都是拿星战的设定集原画做的\u0026hellip;\n另一方面是一时想不到DCEU里面和等级相关的设定了\u0026hellip;星战就很明确啊， youngling是幼徒，Padawan是学徒，Knight是武士，Master是大师，简单明了~\n再有就是，Kryptonitesaber什么的想想就很带感啊\u0026hellip;以后绝对要补充这方面设定的！\n嗯\u0026hellip;上面都是写给自己看的，\n陌生人，欢迎翻阅氪石实验室42号档案柜。  《蜘蛛侠: 平行宇宙》也是42的梗，大家真的是很爱42啊\u0026hellip; ^   ","date":1543636824,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1543636824,"objectID":"89a5c36beed57ab8d9a8e0a7113e33dd","permalink":"https://szthanatos.github.io/post/0x00/","publishdate":"2018-12-01T12:00:24+08:00","relpermalink":"/post/0x00/","section":"post","summary":"这是我第四次，也可能是我最后一次博客迁移(flag已立←_←)。 从大学时代开始，找个地方写点什么的蠢动心思就没消停过，但是也都消磨在了无关文","tags":[],"title":"欢迎来到氪石实验室","type":"post"},{"authors":[],"categories":["Python"],"content":" 目录 HAHAHUGOSHORTCODE-TOC0-HBHB\n 这是写给我组里的人看的，顺手粘过来   什么是单元测试  单元测试(Unit Testing)又称为模块测试，是针对程序模块（软件设计的最小单位）来进行正确性检验的测试工作。程序单元是应用的最小可测试部件。在过程化编程中，一个单元就是单个程序、函数、过程等；对于面向对象编程，最小单元就是方法，包括基类（超类）、抽象类、或者派生类（子类）中的方法。\n 一句话概括，单元测试也就是校验代码中具体的类(甚至函数)的输出值是否符合预期。\n为什么要写单元测试  “可能出错的事情最终一定会出错”\n——墨菲定律\n 代码随着时间的累计而增长，出现意想不到的问题的可能性也在指数级上升。代码的正确与否不应该靠人来保证，因为人是会犯错并且一定犯错的。如果每次新功能上线时不能回答“所有功能都测试过了么”的问题，那么最终整个项目的可靠性都将被摧毁。单元测试的意义就在于让你能够回答这个问题，并且，回答的更自动化。\n怎么写单元测试 原生测试框架unittest/unittest2 在python语境中，官方提供unittest标准库完成单元测试。\n基础 需要理解的概念有如下四个：\n test fixture：单元测试所需上下文环境，比如临时数据库/网络连接等； test case：一个独立的单元测试最小单位； test suite：test case的集合； test runner：执行并输出单元测试的程序；  详细定义请自行查阅官网文档。\n官方单元测试用例如下，我们对upper(将string转换为大写)、isupper(判断string是否全部为大写)、split(对string按空格切分为list)函数的功能进行校验\nimport unittest class TestStringMethods(unittest.TestCase): def test_upper(self): self.assertEqual('foo'.upper(), 'FOO') def test_isupper(self): self.assertTrue('FOO'.isupper()) self.assertFalse('Foo'.isupper()) def test_split(self): s = 'hello world' self.assertEqual(s.split(), ['hello', 'world']) # check that s.split fails when the separator is not a string with self.assertRaises(TypeError): s.split(2) if __name__ == '__main__': unittest.main()  断言 可以从上面的例子看出，单元测试判断结果是否符合预期的主要方式是通过断言(assert) 实现。 以下是常见断言：\n   Method Checks that     assertEqual(a, b) a == b   assertNotEqual(a, b) a != b   assertGreater(a, b) a \u0026gt; b   assertGreaterEqual(a, b) a \u0026gt;= b   assertLess(a, b) a \u0026lt; b   assertLessEqual(a, b) a \u0026lt;= b   assertAlmostEqual(a, b) round(a-b, 7) == 0   assertNotAlmostEqual(a, b) round(a-b, 7) != 0   assertRegex(s, r) r.search(s)   assertNotRegex(s, r) not r.search(s)   assertTrue(x) bool(x) is True   assertFalse(x) bool(x) is False   assertIs(a, b) a is b   assertIsNot(a, b) a is not b   assertIsNone(x) x is None   assertIsNotNone(x) x is not None   assertIn(a, b) a in b   assertNotIn(a, b) a not in b   assertIsInstance(a, b) isinstance(a, b)   assertNotIsInstance(a, b) not isinstance(a, b)    setUp 和 tearDown test fixture是通过setUp 和tearDown 来具体实现的。\nsetUp()方法： 在执行每个测试用例(test case)之前被执行，除了unittest.SkipTest和AssertionError以外的任何异常都会当做是error并终止当前测试用例；\ntearDown()方法： 执行了setUp()方法后，执行tearDown()方法(进行清理)。对异常的处理和setUp()类似；\nsetUpClass(cls)与tearDownClass(cls)类： 可以将setUp和tearDown定义在基类中避免重复定义，定义setUpClass(cls)与tearDownClass(cls)类时必须加上classmethod装饰符；\n对上面的例子进行简单的改造以演示setUp和tearDown的效果：\nimport unittest class TestStringMethods(unittest.TestCase): def setUp(self): print '1. setUp here' def tearDown(self): print '2. tearDown here' def test_upper(self): self.assertEqual('foo'.upper(), 'FOO') ...  执行后效果如下：\ntest_isupper (mytest.TestStringMethods) ... 1. setUp here 1. tearDown here ok  缺点 基本的一个单元测试可以用这四步概括：\n 新建单元测试脚本 导入单元测试依赖 继承单元测试类 实现单元测试方法  而这个过程非常不pythonic：\n 必须新建单独的测试文件 测试必须继承自unittest类，即使再简单的测试 断言只能使用unittest的Assertion 最最关键和难以忍受的：unitunit内的命名规则和pep 8相悖  造成这些问题的原因一言以蔽之：python的测试框架是完全仿照Java实现的。\n第三方测试框架py.test 实际上，通过使用py.test，我们可以非常pythonic的实现单元测试：\n# content of test_sample.py def inc(x): return x + 1 def test_answer(): assert inc(3) == 5  直接在测试文件所在目录执行py.test得到如下结果：\n$ pytest =========================== test session starts ============================ platform linux -- Python 3.x.y, pytest-3.x.y, py-1.x.y, pluggy-0.x.y rootdir: $REGENDOC_TMPDIR, inifile: collected 1 item test_sample.py F [100%] ================================= FAILURES ================================= _______________________________ test_answer ________________________________ def test_answer(): \u0026gt; assert inc(3) == 5 E assert 4 == 5 E + where 4 = inc(3) test_sample.py:6: AssertionError ========================= 1 failed in 0.12 seconds =========================  就是这么简单，更进一步的，py.test支持自动生成对指定目录下所有测试文件的统一测试脚本，更具体的用法参见pytest文档\n总的来说，py.test具有如下特点：\n 非常容易上手，入门简单，文档丰富，文档中有很多实例可以参考 能够支持简单的单元测试和复杂的功能测试 支持参数化 执行测试过程中可以将某些测试跳过，或者对某些预期失败的 case 标记成失败 支持重复执行失败的 case 支持运行由 nose , unittest 编写的测试 case 具有很多第三方插件，并且可以自定义扩展 方便的和持续集成工具集成  单元测试标准 业界通常使用代码覆盖(率)来评判测试的好坏。\n代码覆盖指标 单独的一两个测试完全无法体现测试的优势。而对所有可能的情况编写单元测试既不现实也无必要。所以明确测试覆盖哪些指标非常重要。我们在此指定以下四个指标必须被覆盖：\n 函数覆盖（Function Coverage）\n每一个函数都必须被测试；\n 语句覆盖（Statement Coverage）\n被测代码中每个可执行语句都应该被执行测试。例如\ndef foo(x:int, y:int): z = 0 if x\u0026gt;0 and y \u0026gt;0: z = x return z  中，如果测试为assertEqualst(0, foo(2,-1))，则if内的代码就没有被覆盖到；\n 决策覆盖（Decision Coverage）\n指每一个逻辑分支都应该被测试覆盖。类似上面的例子，如果想要达到决策覆盖，我们起码应该执行两次测试：\n assertEquals(2, foo(2, 2)) # 决策1 assertEqualst(0, foo(2,-1)) # 决策2  条件覆盖（Condition Coverage）\n每一个逻辑分支的每一个条件都应该被覆盖。条件覆盖不需要满足条件表达式所有的排列组合，而只需将每个条件表达式的结果为true/false的情况进行测试就可以了。依旧使用上面的例子，如果想要达到条件覆盖，我们应该执行至少三次测试：\n assertEquals(2, foo(2, 2)) # 决策1条件true assertEqualst(0, foo(2,-1)) # 决策2(没有条件) assertEquals(0, foo(-1, -1)) # 决策1条件false  如果没有第三个测试，那么只能达到决策覆盖，不能达到条件覆盖。\n  代码覆盖率 在满足代码覆盖指标的基础上，只有保证一定的代码覆盖率才能保证测试的完整。满足代码覆盖指标相当于是“质”，而代码覆盖率则是保证“量”。目前要求代码覆盖率不应该低于75%\n我们选定coverage.py来统计代码覆盖率。由于主要使用py.test，需要额外安装pytest-cov插件。安装过程非常简单，对照文档直接pip安装即可，不多介绍。\n完成安装后，使用py.test的时候增加\u0026ndash;cov=myproj参数即可。 效果如下：\n-------------------- coverage: ... --------------------- Name Stmts Miss Cover ---------------------------------------- myproj/__init__ 2 0 100% myproj/myproj 257 13 94% myproj/feature4286 94 7 92% ---------------------------------------- TOTAL 353 20 94%  详细用法可参照官方文档\n小结 总结一下，通过对单元测试的必要性、编写方法、评判标准等一系列的介绍，确立了以下三点：\n 使用py.test+unittest编写单元测试，使用coverage统计、分析单元测试编写情况； 单元测试应覆盖最基本的四项指标(函数覆盖、语句覆盖、分支覆盖、条件覆盖)； 在覆盖基本指标的基础上，需要达到75%的代码覆盖率；  ","date":1534733390,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1534733390,"objectID":"1d163cc095fb33531a2d24b7b49de76d","permalink":"https://szthanatos.github.io/post/python/unit_testing/","publishdate":"2018-08-20T10:49:50+08:00","relpermalink":"/post/python/unit_testing/","section":"post","summary":"目录 HAHAHUGOSHORTCODE-TOC0-HBHB 这是写给我组里的人看的，顺手粘过来 什么是单元测试 单元测试(Unit Testing)又称为模块测试，是针对程序模块（软件设计的最小单位）","tags":["unit testing"],"title":"python单元测试标准及实现","type":"post"},{"authors":null,"categories":null,"content":" 报错信息  MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk.\n 原因 绝大多数情况是写磁盘写满了，并且redis默认stop-writes-on-bgsave-error配置为yes，无法正确的存储rdb文件的时候也就拒绝客户端的请求了。\n解决办法 解决rdb保存问题 有重要数据的时候不能直接清空重来，先检查磁盘空间是否足够，然后指定一个新的rdb文件，重新bgsave：\n# 1. 更改工作目录位置 CONFIG SET dir /tmp/some/directory/other/than/var # 2. 设置rdb文件名 CONFIG SET dbfilename temp.rdb # 3. 保存新的rdb文件 BGSAVE  以上修改会在重启redis后失效，根据实际情况处理吧。\n(临时)解决无法写入问题 关闭rdb保存失败拒绝写入的功能：\nconfig set stop-writes-on-bgsave-error no  ","date":1526614970,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1526614970,"objectID":"08add09b98ee534a2bfcf229304afe6c","permalink":"https://szthanatos.github.io/topic/redis/error-persist_on_disk/","publishdate":"2018-05-18T11:42:50+08:00","relpermalink":"/topic/redis/error-persist_on_disk/","section":"topic","summary":"报错信息 MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. 原因 绝大多数情况是写磁盘写满了，并且redis默认stop-writes-on-bgsave-e","tags":null,"title":"解决 not able to persist on disk","type":"docs"},{"authors":[],"categories":["Python"],"content":"遇到一个报错：\n PicklingError: Can't pickle \u0026lt;type 'instancemethod'\u0026gt;: attribute lookup __builtin__.instancemethod failed\n 当时的情况是想写一个多进程的解析代码，爬虫爬到的内容给扔过来就不管了，差不多这个意思：\n# !/usr/bin/env python # -*- coding: utf-8 -*- from concurrent.futures import ProcessPoolExecutor class PageProcess(object): def __init__(self, worker): self.max_worker = worker def single_process(self, page): pass def multi_process(self, page_list): with ProcessPoolExecutor(max_workers=self.max_worker) as pp: result = pp.map(self.single_process, page_list)  这个错误是这么造成的：\n 在类中使用进程池； 进程池使用Queue管理任务队列； Queue要求传递的内容必须都是可以被序列化的；  那么问题来了，哪些类型是可以被序列化的呢？\n根据官方文档，可序列化的类型包括：\n   类型 原文     布尔型和空值 None, True, and False   数字类型中的整数，浮点数和复数 integers, floating point numbers, complex numbers   字符串类型和二进制类型(字节流，字节数组) strings, bytes, bytearrays   只包含可序列化对象的元组、集合、列表、字典 tuples, lists, sets, and dictionaries containing only picklable objects1   模块中最顶层声明的非匿名函数 functions defined at the top level of a module (using def, not lambda)   模块中最顶层声明的内置函数 built-in functions defined at the top level of a module   模块中最顶层声明的类 classes that are defined at the top level of a module   __getstate__的结果或__dict__是可序列化的这样的类的实例 instances of such classes whose __dict__ or the result of calling __getstate__() is picklable    破案了，上面代码中，我们的进程池要序列化的是类中的函数，就不符合最顶层定义的函数的要求。\n所以最直接的解决办法也很简单，把要并行的函数抽外面去就行了：\n# !/usr/bin/env python # -*- coding: utf-8 -*- from concurrent.futures import ProcessPoolExecutor def single_process(page): pass class PageProcess(object): def __init__(self, worker): self.max_worker = worker def multi_process(self, page_list): with ProcessPoolExecutor(max_workers=self.max_worker) as pp: result = pp.map(single_process, page_list)   英文这种语序/标点我老是搞不懂，这个containing only picklable objects到底是指dictionaries还是前面全部，就当是全部吧 ^   ","date":1521533775,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1521533775,"objectID":"e887903f65e926a617e00a75eb54bd97","permalink":"https://szthanatos.github.io/post/python/pickled/","publishdate":"2018-03-20T16:16:15+08:00","relpermalink":"/post/python/pickled/","section":"post","summary":"遇到一个报错： PicklingError: Can't pickle \u0026lt;type 'instancemethod'\u0026gt;: attribute lookup __builtin__.instancemethod failed 当时的情况是想写一个多进程的解析代码，爬虫爬到的内容给扔过来就不管了，差不多这个意思： # !/usr/bin/env python # -*- coding: utf-8 -*- from concurrent.futures import","tags":["PicklingError","序列化","多进程"],"title":"可序列化类型和多进程PicklingError","type":"post"},{"authors":[],"categories":["Python"],"content":" 对列表的去重很简单，set()一下再list()回来就可以了，但是如果要保留原始列表的顺序呢？\n举例，对[\u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;]这个列表进行原序去重，得到结果应该是['b', 'c', 'a']。\n有下面这几种写法：\n二次排序 也就是对去重结果再按原列表sort一次：\ndef sort_1(list_in): return sorted(list(set(list_in)), key=list_in.index)  匿名函数 使用匿名函数将列表里不重复的元素累加到一个新列表中：\ndef sort_2(list_in): return reduce(lambda x, y: x if y in x else x + [y], [[], ] + list_in)  借用字典 有序字典 使用OrderedDict排序：\ndef sort_3(list_in): return list(collections.OrderedDict.fromkeys(list_in).keys())  defaultdict 类似的,我们使用defaultdict进行排序：\ndef sort_4(list_in): return list(collections.defaultdict.fromkeys(list_in).keys())  直接使用dict 在python3.6之前， dict的key的顺序并不保证一定是插入顺序，所以只有在python3.6之后才可以直接用dict实现这个操作；\ndef sort_5(list_in): return list(dict.fromkeys(list_in).keys())  完整性能测试代码如下：\n# !/usr/bin/env python # encoding: utf-8 from timeit import repeat from functools import reduce from collections import defaultdict, OrderedDict example = [\u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;] def sort_1(list_in): return sorted(list(set(list_in)), key=list_in.index) def sort_2(list_in): return reduce(lambda x, y: x if y in x else x + [y], [[], ] + list_in) def sort_3(list_in): return list(OrderedDict.fromkeys(list_in).keys()) def sort_4(list_in): return list(defaultdict.fromkeys(list_in).keys()) def sort_5(list_in): return list(dict.fromkeys(list_in).keys()) if __name__ == '__main__': # time usage: t5\u0026lt; t4 \u0026lt; t3 \u0026lt; t2 \u0026lt; t1 result = {} for i in range(1, 6): result['sort_{}'.format(i)] = repeat('sort_{}(example)'.format(i), 'from __main__ import sort_{}, example'.format(i), number=1000000, repeat=5) for k, v in result.items(): avg_v = round(sum(v) / len(v), 3) print(k, avg_v)  在我的苏菲婆上的结果仅供参考：\n   排序 平均时间     sort_1 1.477   sort_2 1.305   sort_3 0.957   sort_4 0.734   sort_5 0.698    可见，python3.6之后dict是最好的原序去重办法，3.6之前用defaultdict吧。\n","date":1504260537,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1504260537,"objectID":"2b07ecde73ceab87a018956f5781a7b9","permalink":"https://szthanatos.github.io/post/python/unique_list_ordered/","publishdate":"2017-09-01T18:08:57+08:00","relpermalink":"/post/python/unique_list_ordered/","section":"post","summary":"对列表的去重很简单，set()一下再list()回来就可以了，但是如果要保留原始列表的顺序呢？ 举例，对[\u0026quot;b\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;c\u0026quot;,","tags":["list","benchmark"],"title":"列表原序去重性能测试","type":"post"}]