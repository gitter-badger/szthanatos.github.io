[{"authors":null,"categories":[],"content":" github Deploy key/SSH key Deploy key是在项目主页-setting-Delpoy keys下进行添加，如果勾选Allow write access，则相当于具有对这个项目的读写权限(否则只能clone不能push)。作用范围是这个项目。\nSSH key是在你个人主页-Settings-SSH and GPG keys下进行添加。作用范围是你的账户下的所有项目。\n同一个公钥，只能作为整个账户的SSH key，或者一个项目的Deploy key。想为一台机器授予多个项目的读写权限的话，需要通过ssh-keygen生成多个密钥，分别作为不同项目的Deploy key。\n更换git协议 使用http/https协议连接仓库相比ssh即不够安全，也会存在push的时候必须输入用户名密码的问题。\n使用git remote -v可以查看项目使用的协议。\n如果是新建的项目，推荐在一开始就使用git@github.com:{USER}/{PROJECT}.git进行clone。这样默认都是用ssh了。\n如果是已有项目，使用git remote set-url {repository} {url}更改。\n$ git remote -v origin https://github.com/abc/bcd.git (fetch) origin https://github.com/abc/bcd.git (push) $ git remote set-url origin git@github.com:abc/bcd.git $ git remote -v origin git@github.com:abc/bcd.git (fetch) origin git@github.com:abc/bcd.git (push)  ","date":1544751332,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544751332,"objectID":"0eb7cd8b339258266b0028a9265b5a3e","permalink":"https://szthanatos.github.io/post/git_tips/","publishdate":"2018-12-14T09:35:32+08:00","relpermalink":"/post/git_tips/","section":"post","summary":"github Deploy key/SSH key Deploy key是在项目主页-setting-Delpoy keys下进行添加，如果勾选Allow write access，则相当于具有对这个项目的读写","tags":[],"title":"Git_tips","type":"post"},{"authors":null,"categories":[],"content":"  Hugo 安装/更新  安装/更新 常用命令  Academic 安装/更新  通过Netlify 通过Git 安装 更新  部署到Github Pages  原理 官方教程(缩减版) 脚本  个性化配置  config.toml主要配置项解释 修改网站logo 给文章添加精选图 给文章添加头部背景   Hugo 安装/更新 Hugo是使用Go语言开发的静态站点生成器。不过无需准备Go语言环境，可以直接通过二进制编译包进行跨平台部署。\n以下均以Ubuntu18.0为例。\n安装/更新  前往Github页面下载最新版本，这里我们下载hugo_0.52_Linux-64bit.deb; 使用命令dpkg -i hugo_0.52_Linux-64bit.deb 安装hugo; 更新即重复上面两步，覆盖安装即可;  常用命令  hugo： 编译项目生成静态网站，默认位置在项目的public目录下 hugo server： 启动你的网站服务，可以通过浏览器访问http://127.0.0.1:1313/访问站点; hugo new {folder}/{name}.md: 创建新文章，使用markdown进行排版，一般默认放在post文件夹下；  基本没了，一般情况下用这三个命令就够了。\nAcademic 安装/更新 Academic是一个Hugo主题，从名字就可以知道这个主题比较学院派，适合科研/学术人员发布个人信息/介绍科研项目，当然，拿来做个人博客也是没问题的。\n通过Netlify  Academic推荐使用第三方博客管理平台Netlify安装，如果你没有域名或者没想建站，只是想自己使用，那我建议不使用它的服务——请直接跳到下一部分，否则跟随网站引导完成安装; 通过Netlify安装的Academic使用一句命令即可更新：git submodule update --remote --merge;  通过Git 安装  通过git安装的话，首先建议你在GitHub上fork成你自己的项目，默认的话，通过git clone https://github.com/sourcethemes/academic-kickstart.git My_Website将代码克隆到本地文件夹My_Website (当然，更推荐使用ssh协议，更安全，也免于push时输入密码，这里暂时按官方的来) ; 进入文件夹，初始化项目：git submodule update --init --recursive，完成安装;  更新  cd themes/academic; 将origin仓库重命名为upstream：git remote rename origin upstream; 将更新下载到本地：git fetch upstream; 列出可用更新：git log --pretty=oneline --abbrev-commit --decorate HEAD..upstream/master; 更新：git pull upstream;  部署到Github Pages 原理 网上介绍的办法很多，但核心其实就一句：\n将hugo命令生成的public文件夹上传到GitHub pages项目下。\npublic文件夹相当于编译完成的静态网站，你在本地打开其实就能看。换句话说，你每次手动将这个目录下的内容上传到你的GitHub page项目也是可以的。\n然后为了达到这个目的，官网给出的做法是利用git submodule命令将你的GitHub page项目作为My_Website项目的子模块存放到public目录。那么当你更新你的文章之后，只提交public文件夹内的变更到GitHub page项目即可。\n官方教程(缩减版)  原教程看这； 在GitHub上创建两个项目，一个是fork 的academic-kickstart，也就是你前面clone到本地的My_Website，另一个即是以你用户名/组织名开头、以.github.io结尾的GitHub page项目。 在My_Website目录下执行git submodule update --init --recursive更新子模块； 将config.toml中的baseurl设置为你的GitHub page地址； (实质) 删除public文件夹(如果有的话)，将GitHub page项目clone进去：git submodule add -f -b master https://github.com/\u0026lt;USERNAME\u0026gt;/\u0026lt;USERNAME\u0026gt;.github.io.git public; 新增/编辑文章后，更新academic-kickstart项目：\ngit add . git commit -m \u0026quot;Initial commit\u0026quot; git push -u origin master  更新GitHub page项目：\nhugo cd public git add . git commit -m \u0026quot;Build website\u0026quot; git push origin master   实际上只有第六步是更新GitHub page，每次重复执行这一部分就行(如果你不把文章保存到academic-kickstart的话)。\n脚本 Hugo官方把上面步骤打包到了一个脚本：\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [ $# -eq 1 ] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd ..  实际上我们干脆连第五步也放进去呗：\n#!/bin/bash echo -e \u0026quot;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026quot; # Build the project. hugo # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Add changes to git. git add . # Commit changes. msg=\u0026quot;rebuilding site `date`\u0026quot; if [ $# -eq 1 ] then msg=\u0026quot;$1\u0026quot; fi git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026quot;$msg\u0026quot; # Push source and build repos. git push origin master # Come Back up to the Project Root cd ..  将脚本保存为deploy.sh，放到项目根目录下，完成修改后执行./deploy.sh \u0026quot;{Your optional commit message\u0026quot;}一键更新/部署。\n个性化配置 项目目录结构大体如下：\n content目录： 网站内容，home是你的主页的小控件，post是默认文章存放位置 public目录： 生成的静态页面 resouces目录： JS资源存放位置 static目录： 静态资源存放位置 themes目录： 主题文件所在目录 config.toml: 全局配置文件  config.toml主要配置项解释    配置项 说明     baseurl 你的站点的url，不设置这个你的文章/资源可能相互引用不到   title 网站标题   defaultContentLanguage 默认语言，中文的话填zh，在文件末尾还有一处配置要同时修改才行   hasCJKLanguage 是否有中/日/韩语   defaultContentLanguageInSubdir 目录是否允许用默认语言，true就对了   highlight_languages 语法高亮，支持的语言可以去highlight.js查到   [[menu.main]] 这部分是你主页上标题栏显示的内容，url默认和你content/home下的文件名对应   Languages 添加中文支持的话，把[languages.zh]部分解除注释，languageCode写\u0026quot;zh-cn\u0026quot;，添加其他语种的话，相同格式再写一组[languages.XX]即可，支持的语言代码可以在themes\\academic\\i18n查看    修改网站logo 默认的logo是Academic的蓝色学位帽，想替换的话将你想用的logo保存为 icon.png(默认32*32像素，大了也没关系) 和icon-192.png(192*192像素)，并放到项目的static/img目录下\n给文章添加精选图 这个图片只能添加一个，名字必须是featured.*(后缀jpg/png都行)，而且必须和文章放在同一个文件夹下。\n所以一般做法是把文章aaa.md改名为index.md并新建一个aaa目录，再和featured.png图片一起扔进去。\n显示的效果是在文章列表页，文章右侧有一个缩略图；打开文章，标题默认会居左，右边是精选图：\n给文章添加头部背景 这个是文章头部的横跨整个页面的大图，也就是文章头部这个黑底白字的大图。\n这个的图片可以放到static/img目录下，不过需要在你文件的+++的部分添加如下代码：\n[header] image = \u0026quot;img名称\u0026quot; caption = \u0026quot;标题说明\u0026quot;  顺便一提，文章内引用static/img下存储的图像的话，路径大致如此![example](/img/image_abc.png)\n","date":1544344482,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544344482,"objectID":"d168744249454b6a38f7466215004c76","permalink":"https://szthanatos.github.io/post/academic/","publishdate":"2018-12-09T16:34:42+08:00","relpermalink":"/post/academic/","section":"post","summary":"Hugo 安装/更新 安装/更新 常用命令 Academic 安装/更新 通过Netlify 通过Git 安装 更新 部署到Github Pages 原理 官方教程(缩减版) 脚本 个性化配置 con","tags":["Hugo"],"title":"Academic实现Github Page个人博客","type":"post"},{"authors":null,"categories":["DataBase"],"content":"  简介 一般原则 命名空间(NameSpace)  命名规范 示例  表(Table)  命名规范 示例  行键(Rowkey)  命名规范 示例 注意 慎重将时间戳直接放入行键中 权衡hash和string的效果  列族(ColumnFamily)  命名规范 示例 注意 列族的数量应控制在1-3个  列(Qualifier)  命名规范 示例   简介 本指南是对在HBase进行字段设计而提供的指导性准则和建议。总体标准、设计方式参照Google 开源项目风格指南以及现有项目经验。所有条目均为个人总结，并不是一份官方标准性质的指南 。\nHBase是建立在Hadoop文件系统（HDFS）之上的分布式、面向列的数据库。\n一般原则  无论是表或者是列或者其他，都应该使用名词或者动宾短语以代表一类对象; 尽量避免使用(尤其是单独使用)例如int、join、select等常见保留词; HBase在性能和效率上更擅长处理“高而瘦”的表，而非“矮而胖”的表——以Excel类比，HBase应该尽可能设计成只有很少的列(瘦)而有非常多行(高)的模式;  命名空间(NameSpace) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 不建议用连接符（下划线）拼接多个单词，简单语义的可采用单个单词，复杂语义的可采用多个单词的首字母拼接; 长度尽量限制在4~8字符之间; 命名空间一般可与项目名称、组织机构名称等保持一致; 一般情况下如果不指定命名空间，表会被放在默认(default)命名空间下;  示例 ZKR XJ917  表(Table) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须大写，并且首字符必须为英文字符，可用连接符拼接多个单词; 长度尽量限制在8~16字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合; 无需以TABLE结尾;  示例 USER_INFO WEIBO_USER_FANS  行键(Rowkey) 命名规范  采用英文单词、阿拉伯数字、非转义字符组合形式，不要求大小写，但首字符必须是英文字符或数字;  示例 123456-654321 dftf3a3l3rv3qr s.taobo.com/faefavc  注意 慎重将时间戳直接放入行键中 对于同一条数据，HBase本身提供时间戳(TimeStamp)以在同一个RowKey下保存不同版本数据; 对于整体，存放旧数据的区域随着时间戳增大可能不再写入，而存放新数据的区域始终保持高负荷，这样降低了HBase整体的读写能力。\n一个推荐的方式是使用反向时间戳。\n权衡hash和string的效果 哈希化(一般特指单项哈希)的Rowkey能很好的避免热点问题，但是也会同时丢失直接使用String的RowKey的天然聚类和排序的能力。\n列族(ColumnFamily) 命名规范  采用英文单词、阿拉伯数字的组合形式，其中，单词必须大写，并且首字符必须为英文字符，不能是数字; 长度尽量限制在1~6字符之间，过长的列族名称将占用更多的存储空间,它们不应该像在典型的 RDBMS 中一样具有自我记录和描述性;  示例 DATA D1 # data1 WA # web args  注意 列族的数量应控制在1-3个 HBase 表不应该被设计成模拟RDBMS表，列族的数量在满足需求的情况下应该尽可能少。在存储时，一个列族会存储成一个StoreFile，多个列族对应的多个文件在分裂时会对服务器造成更大的压力。\n列(Qualifier) 命名规范  采用英文单词、阿拉伯数字、连接符（_）的组合形式，其中，单词必须小写，并且首字符必须为英文字符，不能是数字，可用连接符拼接多个单词; 所有列名都应该是名词或者以is开头的动宾短语(表示判断)，不应该使用其他词性单词; 允许使用前缀，不允许使用后缀; 长度尽量限制在1~16字符之间; 尽量采用具有明确意义的英文单词，而不建议采用汉字的拼音字母或者拼音首字母组合;  示例 user_name is_str sound_type  ","date":1544343567,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544343567,"objectID":"bcc2384e562b7caba94eeba86a28363e","permalink":"https://szthanatos.github.io/post/hbase_design/","publishdate":"2018-12-09T16:19:27+08:00","relpermalink":"/post/hbase_design/","section":"post","summary":"简介 一般原则 命名空间(NameSpace) 命名规范 示例 表(Table) 命名规范 示例 行键(Rowkey) 命名规范 示例 注意 慎重将时间戳直接放入行","tags":["HBase"],"title":"hbase表设计风格指南","type":"post"},{"authors":null,"categories":["Kafka"],"content":" 目录  Kafka -01- 安装配置 Kafka -02- 滚动升级  ","date":1544342132,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544342132,"objectID":"f7789c1a8a8297abd616d0ac27988d8b","permalink":"https://szthanatos.github.io/topic/kafka_intro/","publishdate":"2018-12-09T15:55:32+08:00","relpermalink":"/topic/kafka_intro/","section":"topic","summary":"目录 Kafka -01- 安装配置 Kafka -02- 滚动升级","tags":["Kafka","Intro"],"title":"手把手教你用Kafka","type":"topic"},{"authors":null,"categories":["Docker"],"content":" 目录  Docker -01- 基本概念 Docker -02- 进阶生态  ","date":1544342124,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544342124,"objectID":"0068e4c0136d7791cc60e75dca94f3ed","permalink":"https://szthanatos.github.io/topic/docker_intro/","publishdate":"2018-12-09T15:55:24+08:00","relpermalink":"/topic/docker_intro/","section":"topic","summary":"目录 Docker -01- 基本概念 Docker -02- 进阶生态","tags":["Docker","Intro"],"title":"Docker从入门到哪都不去","type":"topic"},{"authors":null,"categories":["Kafka"],"content":"  环境说明 可能存在的风险  轻微警报 严重警报  升级步骤（滚动升级） 替代方案（离线升级） Kafka2.0官方升级指南  环境说明     版本号 发布日期     当前版本 0.11.0.1 2017-09-14   最新版本 2.0 2018-07-30    配置文件路径： \u0026gt; /home/tools/kafka_2.12-0.11.0.1/config/\n目标需求： 在Kafka集群不停机不停止服务的情况下进行升级改造。\n可能存在的风险 轻微警报  consumer可能出现偏移量提交失败而造成重复消费 broker提示\u0026rsquo;NotLeaderForPartitionException\u0026rsquo;异常 由于节点下线，可能造成临时性能问题   严重警报 严格按照步骤升级，暂未捕捉到严重问题相关信息\n升级步骤（滚动升级）  限定通讯协议版本：\n配置broker上的server.properties文件：\ninter.broker.protocol.version = 0.11.0  依次更新代码并重启borker：\n一次关闭一个broker，更新源码，重启\n 更新通讯协议版本：\n完成所有broker节点的源码更新后,升级协议（方法同上）：\ninter.broker.protocol.version = 2.0  再次依次重启broker：\n同上，一次重启一个\n  ps： 如果修改过消息格式版本(log.message.format.version)，则需要在上面步骤中，同步配置：\nlog.message.format.version=当前版本/要升级的版本  替代方案（离线升级） 关闭所有broker，更新代码并重新启动。默认情况下，自动以新协议开始。\nKafka2.0官方升级指南 upgrade\n","date":1544339992,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544339992,"objectID":"a931fa71fab3bdbb98c2ddfee90d29e8","permalink":"https://szthanatos.github.io/post/kafka/update/","publishdate":"2018-12-09T15:19:52+08:00","relpermalink":"/post/kafka/update/","section":"post","summary":"环境说明 可能存在的风险 轻微警报 严重警报 升级步骤（滚动升级） 替代方案（离线升级） Kafka2.0官方升级指南 环境说明 版本号 发布日期 当前版本 0.11.0.1 2017-09-14","tags":["Kafka","Intro"],"title":"Kafka -02- 滚动升级","type":"post"},{"authors":null,"categories":["Kafka"],"content":"  环境说明 安装步骤  0. 环境准备 1. 下载安装 2. 配置集群参数 3. 配置日志参数 4. 配置JVM参数 5. 配置Linux参数  Kafka2.0官方安装指南  环境说明    当前版本 发布日期 下载地址     2.0 2018-07-30 官方2.0.0镜像    安装步骤 注意： 文中以 {} 包裹起来的内容需要自己替换，并非直接使用\n0. 环境准备    基础环境 说明     Java Java版本应该在8(jdk1.8)或以上，以更好的支持G1回收   硬件参数 CPU: 英特尔至强E5-2650 v4 * 2 (共计24核)\nMem: DDR4内存-32GB * 8\nSto: 2000GB * 8 raid 0   文件路径 /home/tools/kafka_2.11-2.0.0/   数据存放位置 /home/sdb/kafka-logs,/home/sdc/kafka-logs,\n/home/sdd/kafka-logs,/home/sde/kafka-logs,\n/home/sdf/kafka-logs,/home/sdg/kafka-logs,\n/home/sdh/kafka-logs,/home/sdi/kafka-logs   zookeeper集群位置 10.10.20.83:2181,10.10.20.84:2181,10.10.20.85:2181    1. 下载安装 下载最新版本Kafka，解压到指定目录，无需其他操作即完成安装。\ntar -xzf kafka_2.11-2.0.0.tgz -C /home/tools cd kafka_2.11-2.0.0  2. 配置集群参数 修改config/server.properties\n基本参数如下：\n# broker唯一id，值为不重复正整数 broker.id={n: int} # 服务监听地址 listeners=PLAINTEXT://{your.host}:9092 # 日志存放位置列表，以逗号隔开 log.dirs={data.storage.list} # zookeeper地址列表，以逗号隔开 zookeeper.connect={zookeeper.server.list}  优化参数配置如下：\n# 消息处理线程数，建议数量为cpu核数加1 num.network.threads=25 # 磁盘IO的线程数,建议为cpu核数2倍，最大不超过3倍 num.io.threads=48 # 拉取线程数，影响follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大 num.replica.fetchers=2 # 分区数量配置，根据业务情况修改 num.partitions=16 # 消息日志备份数，默认是1 default.replication.factor=2 # 刷盘(写入文件到磁盘)间隔消息数，建议设为10000 log.flush.interval.messages=10000 # 刷盘间隔毫秒数，建议1秒(1000) log.flush.interval.ms=1000 # 日志保留小时数 log.retention.hours=48 # 段文件大小，过小会产生很多小文件降低性能，过大会影响快速回收磁盘空间以及Kafka重启后的载入速度 og.segment.bytes=1073741824 # 最大字节数，默认1M，可以调到5M以上 replica.fetch.max.bytes=5242880 # 可接受数据大小，受限于java int类型的取值范围,超出后会报OOM异常 socket.request.max.bytes=2147483600 # 日志传输时候的压缩格式，可选择lz4, snappy, gzip,不压缩。建议打开压缩，可以提高传输性能 compression.type=snappy # 是否允许通过管理工具删除topic，默认是false delete.topic.enable=true # 是否允许程序自动创建Topic auto.create.topics.enable=false  3. 配置日志参数 修改config/log4j.properties的jog4j参数，提高Kafka操作日志（和数据日志区分）的日志级别，以降低日志输出相关资源占用。具体可更改配置如下：\n# Kafka2.0默认只有controller是TRACE级别，可以改为INFO，其他INFO级别可以适当提升为WARN # zookeeper日志级别， log4j.logger.org.I0Itec.zkclient.ZkClient=INFO log4j.logger.org.apache.zookeeper=INFO # 主日志级别 log4j.logger.kafka=INFO log4j.logger.org.apache.kafka=INFO # request日志级别，只有当需要调试时才有必要输出 log4j.logger.kafka.request.logger=WARN, requestAppender log4j.additivity.kafka.request.logger=false # 需要调试时解除以下三行注释，并将RequestChannel$设为TRACE # log4j.logger.kafka.network.Processor=TRACE, requestAppender # log4j.logger.kafka.server.KafkaApis=TRACE, requestAppender # log4j.additivity.kafka.server.KafkaApis=false log4j.logger.kafka.network.RequestChannel$=WARN, requestAppender log4j.additivity.kafka.network.RequestChannel$=false # controller日志级别，默认为TRACE log4j.logger.kafka.controller=INFO, controllerAppender log4j.additivity.kafka.controller=false # 日志清理的日志级别 log4j.logger.kafka.log.LogCleaner=INFO, cleanerAppender log4j.additivity.kafka.log.LogCleaner=false log4j.logger.state.change.logger=TRACE, stateChangeAppender log4j.additivity.state.change.logger=false # 登陆认证的日志级别 log4j.logger.kafka.authorizer.logger=INFO, authorizerAppender log4j.additivity.kafka.authorizer.logger=false  4. 配置JVM参数 Warning：谨慎调试\n在bin/kafka-server-start.sh文件中调整参数如下：\n# 在base_dir之后配置参数 base_dir=$(dirname $0) export KAFKA_HEAP_OPTS=\u0026quot;-Xms6g -Xmx6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80\u0026quot;  ps： 虽然看起来很激进，但是以上配置参照的是LinkIn高峰时期最繁忙的集群:\n60 brokers 50k partitions (replication factor 2) 800k messages/sec in 300 MB/sec inbound, 1 GB/sec+ outbound  这个配置的集群实现了90%的GC中断时间不超过21毫秒，每秒钟新生代GC次数不超过一次\nps2： 上述环境的Java版本为JDK 1.8 u5\n5. 配置Linux参数 Warning：谨慎调试\n# 调整系统所有进程一共可以打开的最大文件数： echo 'fs.file-max = 1024000' \u0026gt;\u0026gt; /etc/sysctl.conf  以及/etc/security/limits.conf末尾增加：\n# 设置当前user以及由它启动的进程的资源限制 {user} soft nofile 1024000 {user} hard nofile 1024000  增大socket buffer size，以提高吞吐性能\necho 212992 \u0026gt;\u0026gt; /proc/sys/net/core/wmem_max echo 212992 \u0026gt;\u0026gt; /proc/sys/net/core/rmem_max  Kafka2.0官方安装指南 Quick Start\n","date":1544062186,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544062186,"objectID":"660b676a7a82179bdd4c600eb93a06f3","permalink":"https://szthanatos.github.io/post/kafka/install/","publishdate":"2018-12-06T10:09:46+08:00","relpermalink":"/post/kafka/install/","section":"post","summary":"环境说明 安装步骤 0. 环境准备 1. 下载安装 2. 配置集群参数 3. 配置日志参数 4. 配置JVM参数 5. 配置Linux参数 Kafka2.0官方安装指南 环境说明 当前","tags":["Kafka","Intro"],"title":"Kafka -01- 安装配置","type":"post"},{"authors":null,"categories":["Docker"],"content":"","date":1544061966,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544061966,"objectID":"fa7e4dfb0522837f4414b1694a73913e","permalink":"https://szthanatos.github.io/post/docker/ecology/","publishdate":"2018-12-06T10:06:06+08:00","relpermalink":"/post/docker/ecology/","section":"post","summary":"","tags":["Docker","Intro"],"title":"Docker -02- 进阶生态","type":"post"},{"authors":null,"categories":["Docker"],"content":"  Docker简介  什么是Docker Docker特点 为什么要使用Docker  基本概念  镜像 容器 仓库 生命周期  安装配置  准备工作  系统要求 卸载旧版本  使用脚本安装（非生产环境） 使用 yum 安装 离线安装 启动 Docker CE 建立 Docker 用户组 测试 Docker 是否安装正确 镜像加速 常用Docker操作  使用镜像  基本操作 Dockerfile  容器操作  容器启停 数据管理  方式1：数据卷（推荐） 方式2：绑定主机目录 区别  使用网络  端口映射 容器互联   延申  容器编排 Nvidia Docker   Docker简介 什么是Docker Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，并于2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护，后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。\nDocker 最初是在 Ubuntu 12.04 上以Go 语言 进行开发实现的, Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持(换句话说不支持CentOS6.5以下)。\nDocker 是一种 容器化技术 ，类似虚拟机的概念，但不同的是传统虚拟机是在虚拟硬件的基础上，完整模拟一整个操作系统，而Docker是以单个应用（容器）为单位进行虚拟。\nDocker特点 Docker具有以下特点：\n 文件系统隔离 ：每个进程容器运行在完全独立的根文件系统里。 资源隔离 ：可以使用cgroup为每个进程容器分配不同的系统资源，例如CPU和内存。 网络隔离 ：每个进程容器运行在自己的网络命名空间里，拥有自己的虚拟接口和IP地址。 写时复制 ：采用写时复制方式创建根文件系统，这让部署变得极其快捷，并且节省内存和硬盘空间。 日志记录 ：Docker将会收集和记录每个进程容器的标准流（stdout/stderr/stdin），用于实时检索或批量检索。 变更管理 ：容器文件系统的变更可以提交到新的映像中，并可重复使用以创建更多的容器。无需使用模板或手动配置。 交互式Shell ：Docker可以分配一个虚拟终端并关联到任何容器的标准输入上，例如运行一个一次性交互shell。  为什么要使用Docker    特性 容器 虚拟机     启动 秒级 分钟级   硬盘使用 一般为 MB 一般为 GB   性能 接近原生 弱于原生   系统支持量 单机支持上千个容器 一般几十个     更高效的利用系统资源 ：由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 ：Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。 一致的运行环境 ： Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 ：对DevOps人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合 持续集成(Continuous Integration) 系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment)系统进行自动部署。 更轻松的迁移 ：由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。  基本概念 Docker 包括三个基本概念 - 镜像（Image） - 容器（Container） - 仓库（Repository）\n理解了这三个概念，就理解了 Docker 的整个生命周期。\n镜像 操作系统分为内核和用户空间。对于 Linux 而言，内核启动后，会挂载 root 文件系统为其提供用户空间支持。而 Docker 镜像（Image），就相当于是一个 root 文件系统。比如官方镜像 ubuntu:16.04 就包含了完整的一套 Ubuntu 16.04 最小系统的 root 文件系统。\nDocker 镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。\n严格来说，镜像并非是像一个 ISO 那样的打包文件，镜像只是一个虚拟的概念，其实际体现并非由一个文件组成，而是由一组文件系统组成，或者说，由多层文件系统联合组成。\n镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。\n分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n容器 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的 类 和 实例 一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。\n容器的实质是进程 ，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。因此容器可以拥有自己的 root 文件系统、自己的网络配置、自己的进程空间，甚至自己的用户 ID 空间。容器内的进程是运行在一个隔离的环境里，使用起来，就好像是在一个独立于宿主的系统下操作一样。这种特性使得容器封装的应用比直接在宿主运行更加安全。也因为这种隔离的特性，很多人初学 Docker 时常常会混淆容器和虚拟机。\n前面讲过镜像使用的是分层存储，容器也是如此。 每一个容器运行时，是以镜像为基础层，在其上创建一个当前容器的存储层， 我们可以称这个为容器运行时读写而准备的存储层为 容器存储层 。\n容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此， 任何保存于容器存储层的信息都会随容器删除而丢失 。\n按照 Docker 最佳实践的要求，容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。 所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录 ，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。\n数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此，使用数据卷后，容器删除或者重新运行之后，数据却不会丢失。\n仓库 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker提供注册服务器(Docker Registry)来实现这样的服务。\n一个Docker Registry中可以包含多个 仓库 （Repository）；每个仓库可以包含多个 标签 （Tag）；每个标签对应一个镜像。\n通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本。我们可以通过 \u0026lt;仓库名\u0026gt;:\u0026lt;标签\u0026gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。\n以 Ubuntu 镜像 为例，ubuntu 是仓库的名字，其内包含有不同的版本标签，如，14.04, 16.04。我们可以通过 ubuntu:14.04，或者 ubuntu:16.04 来具体指定所需哪个版本的镜像。如果忽略了标签，比如 ubuntu，那将视为 ubuntu:latest。\n仓库名经常以 两段式路径 形式出现，比如 jwilder/nginx-proxy，前者往往意味着 Docker Registry 多用户环境下的用户名，后者则往往是对应的软件名。但这并非绝对，取决于所使用的具体 Docker Registry 的软件或服务。\n类似git 和GitHub，官方提供Docker Hub，作为默认的 Registry。用户也可以在本地搭建私有 Docker Registry。Docker 官方提供了 Docker Registry 镜像，可以直接使用做为私有 Registry 服务。\n生命周期 结合上面的概念，这里有一张图比较好的概括了整个Docker工作的生命周期（以及主要命令）。 安装配置 这里仅以CentOS 安装 Docker CE 举例说明。详见Docker 官方 CentOS 安装文档\n准备工作 系统要求 Docker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10。 CentOS 7 满足最低内核的要求，但由于内核版本比较低，部分功能（如 overlay2 存储层驱动）无法使用，并且部分功能可能不太稳定。\n 警告：切勿在没有配置 Docker YUM 源的情况下直接使用 yum 命令安装 Docker.\n 卸载旧版本 旧版本的 Docker 称为 docker 或者 docker-engine，使用以下命令卸载旧版本：\nsudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine  使用脚本安装（非生产环境） 对于个人测试，可以使用这个脚本自动化安装Docker：\ncurl -fsSL get.docker.com -o get-docker.sh sh get-docker.sh  但是，需要注意， 这个脚本可能扰乱你的系统配置、安装及大量的（你可能用不到的）依赖，并且只能安装最新（可能未经充分测试的）版本的Docker ， 所以不推荐在生产环境中使用。\n使用 yum 安装 安装依赖包：\nsudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2  添加 yum 软件源：\n# 中国科学技术大学开源软件镜像源 sudo yum-config-manager \\ --add-repo \\ https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo # 官方源 # sudo yum-config-manager \\ # --add-repo \\ # https://download.docker.com/linux/centos/docker-ce.repo  更新 yum 软件源缓存，并安装 docker-ce。\nsudo yum makecache fast sudo yum install docker-ce  离线安装 以docker-ce-18.03.1为例：\n 在https://download.docker.com/linux/centos/7/x86_64/stable/Packages/这里找到对应rpm包 执行安装命令：rpm -ivh docker-ce-18.03.1.ce-1.el7.centos.x86_64.rpm 由于安装环境不同，可能会发现缺少一些相关依赖包（eg: libcgroup、libtool-ltdl、container-selinux）前往 https://pkgs.org/ 或 https://buildlogs.centos.org/ 下载对应依赖包，依次安装即可  启动 Docker CE sudo systemctl enable docker sudo systemctl start docker  建立 Docker 用户组 默认情况下，docker命令需要root权限，为了避免每次输入命令都要加sudo，可以将用户加入 docker 用户组：\nsudo groupadd docker sudo usermod -aG docker $USER  退出当前终端并重新登录，进行如下测试。\n测试 Docker 是否安装正确 执行\ndocker run hello-world  Docker会从官方仓库下载hello-world镜像并启动，如果一切正常的话会看到类似如下提示：\nUnable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world ca4f61b1923c: Pull complete Digest: sha256:be0cd392e45be79ffeffa6b05338b98ebb16c87b255f48e297ec7f98e123905c Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026quot;hello-world\u0026quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/ For more examples and ideas, visit: https://docs.docker.com/engine/userguide/  镜像加速 鉴于国内网络问题，建议使用Docker中国或者其他国内镜像源。\n修改（或新增）/etc/docker/daemon.json文件，添加:\n{ \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://registry.docker-cn.com\u0026quot;] }  之后重启Docker使配置生效。\n常用Docker操作 # 查看docker版本 docker version # 显示docker系统的信息 docker info # 日志信息 docker logs # 故障检查 service docker status # 启动关闭docker sudo service docker start|stop  使用镜像 基本操作 以redis为例，我们从Docker Hub上获取官方镜像到本地：\ndocker pull redis  ps1：由于redis是官方源（Official），否则应该写完整的两段式仓库名 \u0026lt;用户名\u0026gt;/\u0026lt;软件名\u0026gt;，例如bitnami/redis。\nps2：此处没有指定镜像版本，默认会拉取redis:lastest镜像，指定版本应该写成例如：redis:5.0-rc5\n查看已经下载的镜像：\ndocker image ls # 会有类似如下显示 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB ......  更细节的显示可以使用docker image ls --format \u0026quot;{{.ID}}: {{.Repository}}\u0026quot;直接列出镜像ID和仓库名,\n或者使用docker image ls --format \u0026quot;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}\u0026quot; 以表格等距显示.\n如果要删除某个镜像的话，可以使用docker image rm {IMAGE ID}|{REPOSITORY}命令，不要过先确保没有容器在使用这个镜像。\nDockerfile 除了引用制作好的镜像，我们也可以基于现有镜像定制新的镜像。定制所用的脚本文件就是 Dockerfile。\nDockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction) ，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。\n我们新建一个空白文件，命名为 dockerfile，再文件中写入如下内容：\nFROM redis RUN mkdir redis WORKDIR redis COPY ./redis.conf /etc/ CMD [\u0026quot;redis-server\u0026quot;, \u0026quot;/etc/redis.conf\u0026quot;]  我们依次解释上面每一行：\n FROM 就是指定 基础镜像 ,一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。如果不以任何镜像为基础，那应该用FROM scratch作为起始指令。 RUN 是Dockerfile的核心指令，用于执行一条命令，由于Dockerfile 每一条指令都会新建一层，所以应该尽量将执行的内容写在一行（多行内容可以通过在末尾加\\以表示未结束），它有两种写法：  shell 格式：RUN \u0026lt;命令\u0026gt;，就像直接在命令行中输入的命令一样。 exec 格式：RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]，这更像是函数调用中的格式。  WORKDIR 表示指定当前工作目录，相当于cd命令。 COPY 即复制文件到容器中，在这里是把redis.conf文件复制到容器的/etc目录下。 CMD 是启动程序的命令，写法和RUN相同，一般推荐使用exec格式。  常用Docker指令列表如下：\n   指令 含义 用法     FROM 指定基础镜像 FROM \u0026lt;基础镜像\u0026gt;   RUN 执行指令 RUN [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]   COPY 复制文件 COPY [\u0026quot;\u0026lt;源路径1\u0026gt;\u0026quot;,... \u0026quot;\u0026lt;目标路径\u0026gt;\u0026quot;]   ADD 更高级的复制文件 ADD \u0026quot;\u0026lt;压缩文件\u0026gt;\u0026quot;   CMD 容器启动命令 CMD [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;...]   ENTRYPOINT 入口点 ENTRYPOINT [\u0026quot;可执行文件\u0026quot;, \u0026quot;参数1\u0026quot;, \u0026quot;参数2\u0026quot;]   ENV 设置环境变量 ENV \u0026lt;key1\u0026gt;=\u0026lt;value1\u0026gt; \u0026lt;key2\u0026gt;=\u0026lt;value2\u0026gt;...   ARG 构建参数 ARG \u0026lt;参数名\u0026gt;[=\u0026lt;默认值\u0026gt;]   VOLUME 定义匿名卷 VOLUME [\u0026quot;\u0026lt;路径1\u0026gt;\u0026quot;, \u0026quot;\u0026lt;路径2\u0026gt;\u0026quot;...]   EXPOSE 暴露端口 EXPOSE \u0026lt;端口1\u0026gt; [\u0026lt;端口2\u0026gt;...]   WORKDIR 指定工作目录 WORKDIR \u0026lt;工作目录路径\u0026gt;   USER 指定当前用户 USER \u0026lt;用户名\u0026gt;   HEALTHCHECK 健康检查 `HEALTHCHECK NONE   ONBUILD 构建下级镜像 ONBUILD \u0026lt;其它指令\u0026gt;   MAINTAINER 指定作者 ONBUILD \u0026lt;作者\u0026gt;    更多指令及用法请参照官方文档\n如上，我们完成了一个使用自己配置文件的redis镜像的准备工作，之后依据这个Dockerfile进行构建：\ndocker build -t redis_test:v0.1 . # 会有类似如下输出： Sending build context to Docker daemon 2.048 kB Step 1 : FROM redis ... ... Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c  docker build的用法为：\ndocker build [选项] \u0026lt;上下文路径/URL/-\u0026gt;  最后，可以使用docker push将你自己构建的镜像上传到仓库中，详细用法见官方文档 push\n容器操作 容器启停 我们可以用这样的方式从之前的镜像启动一个容器：\ndocker run -d --name some-redis redis  docker run的用法为docker run [选项] 镜像 [命令] [参数...]，其中：\n--name 指定容器的名称， -d 指定后台运行，其他常用参数包括-i 交互式操作，-t 使用终端（it一般同时使用），--rm 容器退出后随之将其删除，完整参数列表可以通过--help或者在线文档 docker run查看\n由于我们是在后台运行，使用docker container ls来查看容器相关情况，如果要查看停止的进程，后面需要增加参数-a：\ndocker container ls # 会看到类似如下内容 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77b2dc01fe0f redis:v2 redis-server redis.conf 'while tr 2 minutes ago Up 1 minute agitated_wright  使用docker container stop来结束容器的运行：\ndocker container stop 77b2dc01fe0f  类似的，使用docker container start | restart | stop可以控制容器的启停， 使用docker container rm 来删除指定容器。\n数据管理 之前提到过，随着容器的销毁，容器内的数据也会一同丢失。为了保存数据，Docker提供了两种方式（还有一种tmpfs mountsb不常用到）：\n方式1：数据卷（推荐） 数据卷 volume 是一个可供一个或多个容器使用的特殊目录，它不依赖于Unix文件系统，也拥有独立于容器的生命周期。\n创建一个数据卷:\ndocker volume create my-vol  查看数据卷及具体信息：\n# 查看所有的数据卷 docker volume ls # 会看到类似如下内容 local my-vol # ----------------------------------- # 查看具体卷的信息 docker volume inspect my-vol # 会看到类似如下内容 [ { \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Labels\u0026quot;: {}, \u0026quot;Mountpoint\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Options\u0026quot;: {}, \u0026quot;Scope\u0026quot;: \u0026quot;local\u0026quot; } ]  在用 docker run 的时候，增加 --mount 参数来使用数据卷,还是以启动redis为例，这里我们启动redis并且开启aof持久化：\ndocker run -d \\ --name redis \\ --mount source=my-vol,target=/data \\ # -v my-vol:/data \\ redis \\ redis-server --appendonly yes  在这里redis产生的数据（/data目录下）被挂载到数据卷my-vol中。\n我们也可以使用-v或者--volume语法，但是官方建议尽量使用--mount。\n同样使用inspect语法，我们可以查看redis容器的信息：\ndocker inspect redis # 会看到类似如下内容 \u0026quot;Mounts\u0026quot;: [ { \u0026quot;Type\u0026quot;: \u0026quot;volume\u0026quot;, \u0026quot;Name\u0026quot;: \u0026quot;my-vol\u0026quot;, \u0026quot;Source\u0026quot;: \u0026quot;/var/lib/docker/volumes/my-vol/_data\u0026quot;, \u0026quot;Destination\u0026quot;: \u0026quot;/data\u0026quot;, \u0026quot;Driver\u0026quot;: \u0026quot;local\u0026quot;, \u0026quot;Mode\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;RW\u0026quot;: true, \u0026quot;Propagation\u0026quot;: \u0026quot;\u0026quot; } ],  方式2：绑定主机目录 我们也可以直接将容器的数据挂载 bind mount到宿主机的目录或文件 （而非由Docker创建的数据卷）,以当前目录$(pwd)为例：\ndocker run -d \\ --name redis \\ --mount type=bind,source=\u0026quot;$(pwd)\u0026quot;/target,target=/data \\ redis \\ redis-server --appendonly yes  挂载单独文件的方法类似。\n需要注意，本地目录必须存在，否则会报错。\n区别 Volumes是由Docker创建和管理，存储在宿主机固定位置（在linux上是/var/lib/docker/volumes/）。 非Docker应用程序不能改动这一位置的数据。 一个数据卷可以同时被挂载到几个容器中。即使没有正在运行的容器使用这个数据卷，它依然不会清除。可以通过docker volume prune清除不再使用的数据卷。\nBind mounts的数据可以存放在宿主机的任何地方。 非Docker应用程序可以改变这些数据。\n使用网络 端口映射 docker run的时候使用-P(\u0026ndash;publish-all)参数，随机映射一个 49000~49900 的端口到内部容器开放的网络端口。\n或者使用-p ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort(\u0026ndash;publish)来指定具体端口映射：\ndocker run -d \\ --name some-redis \\ -p 6379:6379 \\ -p 127.0.0.1::16379/udp -p 127.0.0.1:80:80 redis  这里我们分别将容器的6379端口映射到宿主机 任意ip的6379端口 ，容器的16379 udp端口映射到宿主机的 任意端口 ，容器的80端口映射到宿主机 对应的80端口 。\n使用docker port 可以查看对应容器的全部端口映射。\n容器互联 简单的容器互联可以通过--link 实现，但是 官方未来可能会删除这个参数 ，所以不展开。\n最新的方式是搭建docker网络实现容器互联，先创建一个新的 Docker 网络：\ndocker network create -d bridge my-net  这里的-d 参数指定网络类型，常用的只有bridge，其他的可能会在Swarm用到,如果不知道Swarm是什么就不用在意。\n以redis客户端/服务端为例，分别在启动的时候将之加入my-net网络：\ndocker run -d \\ --name redis-server \\ --network my-net \\ redis docker run -it \\ --rm \\ --name redis-client \\ --network my-net \\ redis redis-cli -h redis-server  可以看到成功进入redis-cli客户端，我们可以尝试info/keys *或者其他命令查看redis服务端运行情况。\n延申 容器编排 面临一组容器配合使用的情况，例如一个包括负载均衡——网站后台——数据库的Web系统，我们可以使用Docker提供的Compose完成统一配置管理。它将提供相同功能的容器定义为服务service——以方便复用；将完整的容器组合组成项目project以方便统一管理。所有的配置通过一个yml文件即可实现。\nNvidia Docker 对使用GPU的容器，Docker提供Nvidia Docker以发挥GPU的运算性能。\n基本要求如下：\n GNU/Linux x86_64 with kernel version \u0026gt; 3.10 Docker \u0026gt;= 1.12 NVIDIA GPU with Architecture \u0026gt; Fermi (2.1) NVIDIA drivers ~= 361.93 (untested on older versions)  详细安装使用见官方项目Wiki\n","date":1544019442,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544019442,"objectID":"a01c5b0c84bcdd4e9799acafd41e7bbe","permalink":"https://szthanatos.github.io/post/docker/basis/","publishdate":"2018-12-05T22:17:22+08:00","relpermalink":"/post/docker/basis/","section":"post","summary":"Docker简介 什么是Docker Docker特点 为什么要使用Docker 基本概念 镜像 容器 仓库 生命周期 安装配置 准备工作 系统要求 卸载旧版本 使用","tags":["Docker","Intro"],"title":"Docker -01- 基本概念","type":"post"},{"authors":null,"categories":[],"content":" 简介 Palantir是全球第一大大数据公司。曾经的全球四大独角兽之一（其它三家是Uber，Airbnb和小米）。中文名帕兰提尔，源于《指环王》中邪恶巫师萨鲁曼使用的可穿越时空、洞悉世间一切的水晶球(Palantiri)。主要客户为政府机构和金融机构。\n最出名的案例是以大数据技术帮助美国军方成功定位和击毙基地组织首脑本·拉登，以及协助多家银行追回了纳斯达克前主席麦道夫Bernie Madoff的庞氏骗局中所隐藏起来的数十亿美元巨款。\n最新情况  2018年10月29日，Palantir正在建立ICE的案例管理软件 —— AL DIA News\n 2018年10月23日，亚马逊、微软、Palantir等科技公司在特朗普的移民法案中起到重要作用 —— Common Dreams\n 2018年10月19日，Palantir或明年上市，估值达410亿美元 —— MAYA KOSOFF\n 2018年09月14日，美国陆军决议中止对Palantir2.06亿美元的采购合同 —— LAW 360\n 2018年03月14日，雷神、Palantir 拿下美国陆军8.76亿美元合同 —— reuters\n 2018年03月02日，传Palantir在新奥尔良秘密测试犯罪预测技术，最神秘的独角兽再陷隐私风波 —— 猎云网\n Palantir发布2017年度报告 重点提到在哈维飓风的救援以及灾后重建工作，以及帮助世界粮食计划署运输食品以对抗饥饿的工作中所起到的作用。\n  创始人 Peter Thiel 斯坦福本科及法学院JD的高材生，《从0到1》的作者。创立了Clarium Capital、Founders Fund、Valar Ventures、、Mithril Capital Management等多支基金。Paypal创始人之一并出任 CEO。2002年paypal被收购之后，以投资人身份投资包括Facebook、Asana、Quora、LinkedIn、Yelp、Yammer在内的诸多当今一线公司。号称硅谷创投教父。\nAlex Karp (CEO) 哈佛本科毕业，斯坦福法学JD学位，德国法兰克福大学新古典社会理论方向博士学位，师从本世纪最伟大的哲学家之一哈贝马斯。早年继承家产后成为硅谷著名投资人，并在伦敦创立Caedmon Group基金管理投资。目前坚持保持单身，热爱气功、游泳以及与员工讲马克思还有带领员工在硅谷打太极。Peter Thiel在斯坦福的室友。\nJoe Lonsdale 斯坦福计算机系毕业。除Palantir外，还曾创办另外两家高科技公司，和硅谷最大的面向亚洲的风投基金Formation8、 8vc。管理着5000亿美元财富。此外，还是《福布斯》评选出的12位行业未来之星之一，还被美国媒体评为硅谷排名第二的天使投资人。\nStephen Cohen 毕业于斯坦福计算机系的高级工程师。\nNathan Gettings 来自于PayPal的的高级工程师。在PayPal负责风险和研发的总监，曾以开发了反欺诈的系统而闻名于世。\n发展历程  2004年Palantir公司创立于加利福尼亚州帕洛阿尔托。创业初期Palantir并不被人看好，融资过程也是屡屡受阻，包括红杉资本，凯鹏华盈两大VC基金都不看好Palantir的发展。经过多次奔走博弈，最终，Palantir赢得了CIA的创投基金的2轮投资，从而走上了发展的正轨。 2004到2009年，Palantir主要业务还是服务于美国政府部门，提供情报分析，防欺诈、反恐等服务。 2010年，Palantir开始提供企业服务，实现业务多元化。 2010年7月，当时已经拥有250位工程师的Palantir完成9000万美元的D轮融资，估值达到7.35亿美元。 2011年5月6日，融资5000万美元，累计融资额达到了1.75亿美元。 2011年10月7日，融资7000万美元，估值25亿美元。 2013年9月29日，融资1.96亿美元，估值60亿美元。 2013年12月，Palantir新一轮融资1.075亿美元，同时估值达到90亿美元。此时Palantir的年收入已经超过4.5亿美元。 2014年11月，Palantir再拿到5亿美元投资，企业用户突破14000家，估值达到了150亿美元。 2015年年底，Palantir获得8.8亿美元的融资，市值达到200亿美元。成为继 Uber、小米、Airbnb 之后，全球估值第四高的创业公司。（截至2018年11月最后一笔融资） 2016年2月，收购Kimono Labs 2016年5月，Buzzfeed爆料,数司百名员工离职，多个重要客户不再续约。 2016年8月，Palantir收购数据可视化公司Silk。 2018年10月，Palantir预备明年下半年上市，公司估值或将达410亿美元   产品内容 官方主页： Home | Palantir 产品线 目前Palantir仅保留两条产品线：\n Palantir Gotham 一个集成，管理，保护和分析多来源的企业数据的复合平台。命名来源于蝙蝠侠所在的哥谭市。作为后端，Gotham平台可用于集成许多不同的数据源，以进行安全的协作分析；也可以存储企业的各类建模分析数据，充当企业知识库。而在前端, Gotham平台提供了一套针对语义，时间，地理空间和全文分析的分析工具集合。为Gotham提供支撑的子产品包括：\n PHOENIX 支持PB级的数万亿条记录进行亚秒级查询的集群数据库； RAPTOR 提供对外部数据源进行联合查询,并实时加入数据库的检索工具； SEARCH 提供对系统中结构化和非结构化数据的全文检索的搜索引擎； HORIZON 允许用户在数十亿个对象中查询并在约10秒内收到结果的,类Spark设计的内存数据库； DYNAMIC ONTOLOGY 高度灵活和动态的数据建模工具； REVISIONING DATABASE RevDB是Gotham平台的持久化数据管理工具，类似Zookeeper之于Hadoop； ATLASDB 作为RevDB的具体数据存储单元，结合了NoSQL数据存储的简单性和可扩展性与传统SQL数据库的事务安全性和一致性； NEXUS PEERING 分布式系统平台，上面的各个组件都建立在这个平台之上；  Palantir Foundry ：数据集成/分析平台，将后端的数据存储和前端的数据分析打通，让任何人都能连接到不同数据源轻松进行建模分析。\n  解决方案 Palantir面向以下领域直接提供解决方案：\n 汽车制造业 网络安全 金融合规 企业内部信息安全 商业情报分析 法律诉讼 并购支持 收入最大化 数据组织 国土防卫 欧盟通用数据保护监管 保险分析 公共执法 制造业 医药研发 航空业  ","date":1544000961,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544000961,"objectID":"3a0a3ff6504fdcc30a1757e8d02e8c1f","permalink":"https://szthanatos.github.io/post/palantir_intro/","publishdate":"2018-12-05T17:09:21+08:00","relpermalink":"/post/palantir_intro/","section":"post","summary":"简介 Palantir是全球第一大大数据公司。曾经的全球四大独角兽之一（其它三家是Uber，Airbnb和小米）。中文名帕兰提尔，源于《指环王","tags":[],"title":"Palantir一分钟印象","type":"post"}]